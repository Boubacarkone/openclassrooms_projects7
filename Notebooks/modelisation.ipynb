{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f587b6e3",
   "metadata": {},
   "source": [
    "# Notebook de modélisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc7eada",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b7748da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T16:34:27.947104Z",
     "start_time": "2023-03-22T16:34:27.915280Z"
    }
   },
   "outputs": [],
   "source": [
    "#Auto chargement des imports option2\n",
    "import autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffbac196",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T16:34:44.435926Z",
     "start_time": "2023-03-22T16:34:31.349649Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import seaborn as sns\n",
    "sns.set(style=\"ticks\") #white, dark, whitegrid, darkgrid, ticks\n",
    "# directory reach\n",
    "PROJECT_ROOT = os.path.dirname(os.path.abspath(''))\n",
    "sys.path.append(PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a86ec9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T16:34:44.510236Z",
     "start_time": "2023-03-22T16:34:44.441414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64e9770c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T16:34:47.820960Z",
     "start_time": "2023-03-22T16:34:44.513160Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.utils import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c8aca54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T16:35:14.104537Z",
     "start_time": "2023-03-22T16:34:51.851094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>...</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Refused_MIN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Sent proposal_MIN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Sent proposal_MAX</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Signed_MAX</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Signed_SUM</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_MIN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_MAX</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_MEAN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_SUM</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_VAR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100002</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>-9461</td>\n",
       "      <td>-637.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100003</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>0.003542</td>\n",
       "      <td>-16765</td>\n",
       "      <td>-1188.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100004</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>0.010030</td>\n",
       "      <td>-19046</td>\n",
       "      <td>-225.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100006</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>0.008020</td>\n",
       "      <td>-19005</td>\n",
       "      <td>-3040.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100007</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>0.028660</td>\n",
       "      <td>-19932</td>\n",
       "      <td>-3038.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 375 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            TARGET  CODE_GENDER  FLAG_OWN_CAR  FLAG_OWN_REALTY  CNT_CHILDREN  \\\n",
       "SK_ID_CURR                                                                     \n",
       "100002         1.0            0             0                0             0   \n",
       "100003         0.0            1             0                1             0   \n",
       "100004         0.0            0             1                0             0   \n",
       "100006         0.0            1             0                0             0   \n",
       "100007         0.0            0             0                0             0   \n",
       "\n",
       "            AMT_CREDIT  AMT_ANNUITY  REGION_POPULATION_RELATIVE  DAYS_BIRTH  \\\n",
       "SK_ID_CURR                                                                    \n",
       "100002        406597.5      24700.5                    0.018800       -9461   \n",
       "100003       1293502.5      35698.5                    0.003542      -16765   \n",
       "100004        135000.0       6750.0                    0.010030      -19046   \n",
       "100006        312682.5      29686.5                    0.008020      -19005   \n",
       "100007        513000.0      21865.5                    0.028660      -19932   \n",
       "\n",
       "            DAYS_EMPLOYED  ...  CC_NAME_CONTRACT_STATUS_Refused_MIN  \\\n",
       "SK_ID_CURR                 ...                                        \n",
       "100002             -637.0  ...                                  NaN   \n",
       "100003            -1188.0  ...                                  NaN   \n",
       "100004             -225.0  ...                                  NaN   \n",
       "100006            -3040.0  ...                                  0.0   \n",
       "100007            -3038.0  ...                                  NaN   \n",
       "\n",
       "            CC_NAME_CONTRACT_STATUS_Sent proposal_MIN  \\\n",
       "SK_ID_CURR                                              \n",
       "100002                                            NaN   \n",
       "100003                                            NaN   \n",
       "100004                                            NaN   \n",
       "100006                                            0.0   \n",
       "100007                                            NaN   \n",
       "\n",
       "            CC_NAME_CONTRACT_STATUS_Sent proposal_MAX  \\\n",
       "SK_ID_CURR                                              \n",
       "100002                                            NaN   \n",
       "100003                                            NaN   \n",
       "100004                                            NaN   \n",
       "100006                                            0.0   \n",
       "100007                                            NaN   \n",
       "\n",
       "            CC_NAME_CONTRACT_STATUS_Signed_MAX  \\\n",
       "SK_ID_CURR                                       \n",
       "100002                                     NaN   \n",
       "100003                                     NaN   \n",
       "100004                                     NaN   \n",
       "100006                                     0.0   \n",
       "100007                                     NaN   \n",
       "\n",
       "            CC_NAME_CONTRACT_STATUS_Signed_SUM  \\\n",
       "SK_ID_CURR                                       \n",
       "100002                                     NaN   \n",
       "100003                                     NaN   \n",
       "100004                                     NaN   \n",
       "100006                                     0.0   \n",
       "100007                                     NaN   \n",
       "\n",
       "            CC_NAME_CONTRACT_STATUS_nan_MIN  CC_NAME_CONTRACT_STATUS_nan_MAX  \\\n",
       "SK_ID_CURR                                                                     \n",
       "100002                                  NaN                              NaN   \n",
       "100003                                  NaN                              NaN   \n",
       "100004                                  NaN                              NaN   \n",
       "100006                                  0.0                              0.0   \n",
       "100007                                  NaN                              NaN   \n",
       "\n",
       "            CC_NAME_CONTRACT_STATUS_nan_MEAN  CC_NAME_CONTRACT_STATUS_nan_SUM  \\\n",
       "SK_ID_CURR                                                                      \n",
       "100002                                   NaN                              NaN   \n",
       "100003                                   NaN                              NaN   \n",
       "100004                                   NaN                              NaN   \n",
       "100006                                   0.0                              0.0   \n",
       "100007                                   NaN                              NaN   \n",
       "\n",
       "            CC_NAME_CONTRACT_STATUS_nan_VAR  \n",
       "SK_ID_CURR                                   \n",
       "100002                                  NaN  \n",
       "100003                                  NaN  \n",
       "100004                                  NaN  \n",
       "100006                                  0.0  \n",
       "100007                                  NaN  \n",
       "\n",
       "[5 rows x 375 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(Path(PROJECT_ROOT + '/data/data_pre_processed_final_v0.csv'), index_col=[0])\n",
    "#data = pd.read_csv(Path(PROJECT_ROOT + '/data/data_pre_processed_final.csv'), index_col=[0])\n",
    "data.set_index('SK_ID_CURR', inplace=True)\n",
    "data.head()\n",
    "#data/data_pre_processed_final_v0.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82da04b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T16:35:14.185254Z",
     "start_time": "2023-03-22T16:35:14.109663Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356251, 375)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa3b9eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50bba820",
   "metadata": {},
   "source": [
    "# Score métier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e001c20",
   "metadata": {},
   "source": [
    "**La famille des F-beta scores**\n",
    "\n",
    "Le F1-score appartient à la famille plus large des F-beta scores. Dans le cas du F1-score, les erreurs (FN+FP) faites par le modèle sont pondérées par un facteur 1⁄2. Le F1-score accorde ainsi la même importance à la precision et au recall, et donc aux faux positifs et aux faux négatifs.\n",
    "\n",
    "\n",
    "Le F-beta score permet de varier la pondération de ces termes :\n",
    "\n",
    "\\begin{equation*}\n",
    "\\text{F}_\\beta\\text{-score} = (1 + \\beta^2) \\cdot \\frac{\\mathrm{precision} \\cdot \\mathrm{recall}}{(\\beta^2 \\cdot \\mathrm{precision}) + \\mathrm{recall}}\n",
    "\\end{equation*}\n",
    "\n",
    "Ce qui s’écrit également :\n",
    "\n",
    "\\begin{equation*}\n",
    "\\text{F}_\\beta \\text{-score} = \\frac{TP}{TP+\\frac{1}{1+\\beta^2}(\\beta^2 FN+FP)}\n",
    "\\end{equation*}\n",
    "\n",
    "Résumons :\n",
    "\n",
    "- Pour $\\beta \\geq 1$, on accorde plus d’importance au recall (autrement dit aux faux négatifs).\n",
    "- Pour $\\beta \\leq 1$, on accorde plus d’importance à la precision (autrement dit aux faux positifs).\n",
    "- Pour $\\beta = 1$, on retrouve le F1-score, qui accorde autant d’importance à la precision qu’au recall.\n",
    "\n",
    "Choix d'une valeur de $\\beta$ pour le score métier:\n",
    "\n",
    "- Supposons que nous voulons donner 10 fois plus d'importance au recall qu'à la precision alors:\n",
    "\n",
    "  $$\\beta = \\sqrt{10} \\approx 3.1622776601683795 \\Longrightarrow 2.4025FN + 0.2403FP$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f207d8b",
   "metadata": {},
   "source": [
    "# Gestion du déséquibre de class\n",
    "\n",
    "## Comparaison des méthodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b54a5798",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T16:35:15.144596Z",
     "start_time": "2023-03-22T16:35:14.189041Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9.1\n"
     ]
    }
   ],
   "source": [
    "import imblearn\n",
    "from imblearn import FunctionSampler\n",
    "from imblearn.over_sampling import ADASYN, SMOTE, RandomOverSampler\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, roc_auc_score, roc_curve, f1_score\n",
    "from sklearn.metrics import RocCurveDisplay, auc, roc_curve, fbeta_score, ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, FunctionTransformer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print(imblearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaf4148d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T16:35:17.939838Z",
     "start_time": "2023-03-22T16:35:17.851693Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca3e1486",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T16:35:20.001857Z",
     "start_time": "2023-03-22T16:35:19.936738Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_infite(df):\n",
    "    return df[np.isfinite(df).all(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b27285",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T18:41:17.995761Z",
     "start_time": "2023-02-28T18:41:16.620012Z"
    }
   },
   "outputs": [],
   "source": [
    "#Reduction des données pour tester les méthodes d'équilibrage\n",
    "nb_class_1 = int(len(data[data.TARGET == 1])*10/100)\n",
    "nb_class_0 = int(len(data[data.TARGET == 0])*10/100)\n",
    "print(f\"10% des la classe 0 : {nb_class_0}\\n10% de la classe 1 : {nb_class_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4da59118",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T18:41:19.303813Z",
     "start_time": "2023-02-28T18:41:18.029000Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.concat([\n",
    "        data[data.TARGET == 0].sample(nb_class_0), \n",
    "        data[data.TARGET == 1].sample(nb_class_1)\n",
    "    ], ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd2fc658",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T18:41:19.511426Z",
     "start_time": "2023-02-28T18:41:19.313023Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    28268\n",
       "1.0     2482\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.TARGET.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4979c71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T18:41:19.854254Z",
     "start_time": "2023-02-28T18:41:19.519220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (30750, 212), test shape: (0, 212)\n"
     ]
    }
   ],
   "source": [
    "# Separation des données\n",
    "train_df = df[df['TARGET'].notnull()]\n",
    "test_df = df[df['TARGET'].isnull()]\n",
    "print(\"Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "242fe09a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T18:41:20.149104Z",
     "start_time": "2023-02-28T18:41:19.862249Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/pandas/core/frame.py:5176: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().fillna(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imputation\n",
    "train_df.fillna(0, inplace=True)\n",
    "test_df.fillna(0, inplace=True)\n",
    "train_df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98628d53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T18:41:20.441955Z",
     "start_time": "2023-02-28T18:41:20.158071Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = remove_infite(train_df)\n",
    "test_df = remove_infite(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3caff89d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T18:41:20.598191Z",
     "start_time": "2023-02-28T18:41:20.455033Z"
    }
   },
   "outputs": [],
   "source": [
    "y = train_df['TARGET']\n",
    "del train_df['TARGET']\n",
    "del test_df['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf248084",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T18:41:21.199251Z",
     "start_time": "2023-02-28T18:41:20.612918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le lebal positive minoritaire est la class : 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_distribution = pd.Series(y).value_counts(normalize=True)\n",
    "ax = class_distribution.plot.barh()\n",
    "ax.set_title(\"Class distribution\")\n",
    "pos_label = class_distribution.idxmin()\n",
    "plt.tight_layout()\n",
    "print(f\"Le lebal positive minoritaire est la class : {pos_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30122b4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T18:41:21.346359Z",
     "start_time": "2023-02-28T18:41:21.212837Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "pipeline = [\n",
    "    make_pipeline(FunctionSampler(), classifier),\n",
    "    make_pipeline(RandomOverSampler(random_state=42), classifier),\n",
    "    make_pipeline(ADASYN(random_state=42), classifier),\n",
    "    make_pipeline(SMOTE(random_state=42), classifier),\n",
    "    make_pipeline(RandomForestClassifier(random_state=42, class_weight='balanced'))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a057ef3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T16:26:17.087321Z",
     "start_time": "2023-03-09T16:26:17.013629Z"
    }
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcf452e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T18:41:21.840732Z",
     "start_time": "2023-02-28T18:41:21.550997Z"
    }
   },
   "outputs": [],
   "source": [
    "X = train_df.values\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a01ea789",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T18:52:13.904246Z",
     "start_time": "2023-02-28T18:41:21.847856Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d7ffa03b6f94a17a29747842dfb1464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp = []\n",
    "for model in tqdm(pipeline):\n",
    "    # compute the mean fpr/tpr to get the mean ROC curve\n",
    "    mean_tpr, mean_fpr = 0.0, np.linspace(0, 1, 100)\n",
    "    for train, test in cv.split(X, y):\n",
    "        \n",
    "        model.fit(X[train], y[train])\n",
    "        y_proba = model.predict_proba(X[test])\n",
    "\n",
    "        pos_label_idx = np.flatnonzero(model.classes_ == pos_label)[0]\n",
    "        fpr, tpr, thresholds = roc_curve(\n",
    "            y[test], y_proba[:, pos_label_idx], pos_label=pos_label\n",
    "        )\n",
    "        mean_tpr += np.interp(mean_fpr, fpr, tpr)\n",
    "        mean_tpr[0] = 0.0\n",
    "\n",
    "    mean_tpr /= cv.get_n_splits(X, y)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "\n",
    "    # Create a display that we will reuse to make the aggregated plots for\n",
    "    # all methods\n",
    "    disp.append(\n",
    "        RocCurveDisplay(\n",
    "            fpr=mean_fpr,\n",
    "            tpr=mean_tpr,\n",
    "            roc_auc=mean_auc,\n",
    "            estimator_name=f\"{model[0].__class__.__name__}\",\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a99ac9f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T18:52:14.663546Z",
     "start_time": "2023-02-28T18:52:13.907641Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmkAAAJ+CAYAAADoopfxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAEAAElEQVR4nOzddXgU1/7H8fdq3F2JwQR39+LWUlpq1N1u29vbX+XW21vvrbtCvdBboaVIKVJaILjDEFyixGWTtfn9sRuakASChCTk+3qePk12zsycs1nIhzNHdJqmIYQQQgghmhd9U1dACCGEEELUJiFNCCGEEKIZkpAmhBBCCNEMSUgTQgghhGiGJKQJIYQQQjRDEtKEEEIIIZohY1NXQIiWRlEUA3A3cAWuP0Nm4GfgMVVVK5uybtUpivIR8I2qqgub6P6jgQ+BbGCoqqqWpqhHU1AU5QkgVFXVOxVF+RW4T1XVbU1cLQAURbkRMKuq+k71ep7G9S4G7lRVddgZqqIQwk1CmhAn710gCBihqmqRoig+wJfAR8BVTVqzalRVvbGJq3AZ8KGqqv9p4no0KVVVxzd1HY4xCNjS1JUQQpyYhDQhToKiKAnANCBKVdViAFVVyxRFuRUY6C4TALwNdAM0YC7wb1VV7YqiVACvACMBX+AJYCrQGcgAJrmvZweeB8YBPu7zv3cHwneBtkAIUAJcoaqqqijKEiAfSHWXuQh4C/gReNNdPxuwB7hOVdVSRVEmA4/jGvpQAtyrquoqdw9LAhAFtAEOA1eqqpp5zPthcrdnBOAA0oB/ArcCkwGLoigBqqr+3zHn1bovsBbYB0xWVXWtu9y3wBJVVd9VFOVhd5v07nK3q6qacWy7VVV985h7TQEeAZzuOv6fqqp/KIrSD3gR8HC38zdVVW9w/4wXAb8BPXH9PfkYcIv7HmuAy4F4YCkwD+gL6HD1KC075v77gItx/byfcb//nQATcIuqqn8pihIGfAokA3lAFrBFVdUnjrnWdKAc1+clApjtLj8JiARuVFV1kaIoZuAFYChgANYDd7l/TucDoxRFqerZTFUUZbH7PcgGLlNVNVNRlI64Pj8huD7H/1VV9TN3PZ7C9ecgD0ivVr9BuD4PBvc5z6mq+j+EEKdExqQJcXJ6AlurAloVVVWzqv0yegPXL6/OQC+gK3Cf+5gHkKWqah9gBq7et3uADkAAcIG7nAEoV1W1J3AJ8In7F/k4oFBV1f6qqrYDVgPVH1UVqKra4Zig0h8YBnR1X28P0EVRlFTgPeAiVVW74goiPymK4u8+bzAwVVXVVKAMV/A61iNAtLuNXXH9nfKSqqov4QoQr9YR0Oq8L64w+glwnbtcEK4w+5WiKFe7388+qqp2A351v3fHa3eVl3AFul7Ao+73AlyPrB9TVbUvrvf/fEVRerqPJQJz3OesAF7HFcw6ut+Xfu5y8cBSd50eBL51B9f69MUVdrrjCmXPul9/A9fnqj2u0D7gONfoAZwHDAH+BZSqqjrAXccH3WUeBOxAT/d7nAE8r6rqD/z9c3nbXTYJuMT9cy4AblQUxegu96aqql1wfe6eVRSlv6IoF+AKy93c9QyoVrcngVfcn7Pr3fUUQpwiCWlCnBwnJ/5zMw54S1VVzT1G7T33a1WqwtxuYLOqqodVVXUCe4HgauXeAlBVdROwGRiiqup3wHRFUf6hKMrruAKHb7VzavTiuG3G3culKMrTwP9UVV2O6xfo76qq7nHfZxGQgyuIgqsHqyqMrj+mbtXb+p6qqjZ3G948pq11Od59PwEucfcEXQ7MVlW1CJiIKxitURRlA/APQDlBu6t8A/zgHqMXhKv3DOAaIFBRlH8D7wBe/P1e2nCNMwTXz2m5qqrFqqpW4Ao8Ve9FgaqqX7nbMRfX+9zlOHXZr6rqBvfX66pdZzzwgfs6mcB3x7nGz+73OwtXeJ5XrZ5V15uIK/Cvd79fk3EF0br8pqpqrvvrjUA40A7wVFX1e3edMnB9bsfiCs7fq6paoqqqHdfPrMpM4G1FUb7E9fP893HaIYQ4AQlpQpycNKC9oih+1V9UFCVGUZQ5iqJ44fpzVX1TXD2uR1tVqk8usB3nXvZjruFQFOU24GNcj7y+Ar7G9ZitSumxF1FVtZC/e/McuHp7bufvR1LVVa9r9YH+2jH3qXLsNY5ta13qva+qqvtxhZeJuHrUPqp2zguqqnZz91r1wv142a0UQFGUaEVRNlT7L1pV1YdxjcNaA1wL/OE+5w9c4WgH8BSuR7pVbbSqqlq9jvX9nOzHfK/H9R7Xp7731E7N9/d41zh2ckpddTMAd1d7v/rgeuRal+rnV9XpRJ+N6nU9+h6oqvo+rh7P34AxwCZFUTzrbYkQ4rgkpAlxEtw9Cl/ievzoD+D+/ztAnnsG43zgTkVRdIqieAA34/qldbKudl+/B66xUEtx/eKbrqrqx4CKayyS4XgXURRlIvA7rt6gJ4DPgN7u18YoipLkLnceEIcriDbUPOA2RVFMiqLogTs4cVtPdN8PgQcAH1VV/3K/Nh/XY7iqR7FPAZ8fe2FVVTOqgok7nOS4x4R5q6r6HnA7rke9Ee734AF3b1EskMIJ3ss6hCmKMtbdjkm4As/mk7wGwBzgBvd1QoALqR2STkbVZ9Ds/rl8CDznPmbnxEF6B2Bzj+dDUZRoXI84f8M1xnKqoiiB7msfnSyjKMpyoLuqqtNxfe4DcY2VE0KcAglpQpy824FtwHL3o6Q09/dVsynvwvXIaLP7PxXXgPGTNVBRlHW4HiddqqpqAfAycIuiKJtwPeJbhytcHM9cYCuwRVGUNbjGET3pXhLiduB7RVG24JqoMMn9eLGh/oNrkPsGYDuuX/53H++EBtx3Nq5JC9XHnH0E/AKsVBRlK65HiteeqHLux3H34BrXtg6YBVyvqmo2rtCyzl2HB4G/OPF7eawK4CpFUTYCD+Oa9HC8XrD6/BPXAP7NuB4r7sfVW3qqnsY1uWI9rs+mDtf4NXB9Hm5VFOWh+k5WVdWG6xHp3e7P2kLgKVVVF6uq+iuuz+QaXJ/96p+X+4GnFEVZDyzB9TnbdxrtEKJV02na6fxjTQjRGBRF0YAwVVWPNHVdRN3cs0C3qKrqe6KyDbjW7cB6VVVXuHtflwGPu8e5CSFaKVmCQwghmt424E33QslmYJYENCGE9KQJIYQQQjRDMiZNCCGEEKIZksedQrQg7pXed6mq+pmiKI8BG1VV/cm9Ev0WVVVfPkP3uRbX4qh73S/pAH9cY6Vudq8Xdibu8wvwnXs24OleKwH32nPHHJqtqupjp3v9E9x7AtC36j7uZScexrWUSNWSFl8AL6qqqrl3SXjLve7dmarDrUCgqqrPH7Nv6qdAgKqqz5+pewkhzg4JaUK0IMeEjfNwjWVqLMtUVZ1Y9Y07ePyJaxHY9xvxvqfD4l5642zrjXshWUVRdLi24toJ9FdVtcK9rMYcXIvlPtoYFXAvMVJF9k0V4hwgIU2IZsK9nMe/VFX9XVGUy3H1gASpqmpxr5a/Fte2QltwLYraC3hJUZSqJR8GuNepinCXuUJV1bJj7tEO176ifrj2atyAa3mPhvSMheDaAijffa2JuFaUN+NacmSGqqqPKooyjPr3qIzGtR1WNK5lJsKr1W0wri2cvAEr8IiqqvPcvXpVe3a2AQ7h6iW6E9fK+K+oqvrfE1W+rv1C1b/3Ke3vrtNGVVWvPM4+obX2AcW1uOytgEFRlCJgAdAemFC1HIeqqnmKolyFa2mRY+v1b1y7A3jh2hrrPlVVf3Bvn/Ux4ImrN+4jVVXfOc7rTwCh7vd1Mu59U3HtShCqquqdiqLE4NrJIt79c/lGVdVn3b2Qy3Ato5IADFWP2adVCHH2yZg0IZqP7/l7S6WxuPZRHOzumRkP/FBV0L3v4hpcm4VXvR6Da8uedrgWZ51Sxz1uwhWm+uFaEywRmFBPfQa7V+3foShKLq4tf15WVXWWu07/Aq5x72/ZD3hIUZRQ97n17VH5NrBSVdWOuNaTS4WjC7h+h2uV/C64euu+UBQlsaouuIJQF1wL316Ga7Pw8cB/3IuqAngds+PAGvf1T7RPaRtci7BeqRx/n9Ba+4Cqqprmvva37t0NegFpx66XpqpquqqqNRb6VRSlDa6f2TB3ux/GtVAvuALgz+59MMcDQ9ztrO/1qvvUu28qrgWAP3Gf2wcYqSjKJe5jscDTqqq2k4AmRPMgIU2I5uMHYJw7AA0GXgFG4QpAu917NR7Pj6qqlrvDwRaq9VJV8wCQqyjK/cC7uHqP6lvna5k7pHTAtSdnCK7FYHFvmTQJ6KkoyuPuuupw9QRB/XtUjgSmu6+xC1jkfr0vrrF2ae5jW3EtLjvMfXy1qqoH1b/3OF3g/no3rh4lb3c5S/UdB9xhCk68T+lK98K3cPx9QuvbB7S6huzvirse+3HtLDFNUZTncQXRqp/HD8D9iqJ8jytw3+Vuc32vH5eiKD7AUOBpd7tW4upR6+YuYse1mbwQopmQkCZEM6Gq6mZcjw7PB9JxbfA92v19QwaY17UH47G+xrVdz37gVVwBqq5y1evlVFX1KVyP/abD0V/464Ee7mv8n/v+Vdeqb4/KY+tVFYxOtFdkQ/arPJ4TXb/0mLJ17hN6nH1Aq1sJ9HaveXaUoii9FUX5/JjXeuAKRv64HpO+gPv9UVX1F6Atrh7M7sBmRVFi63u9ge+BDhhQrW39+LuXs7JaUBVCNAMS0oRoXn7AtU3SAlVVd+AaAzYN16PQYzVkD8ZjjcG1vc+37u/70vD9Ku8ARiuKcgGukOCPa9zYz7h6vDwacK15uEIiiqLEA8Pdr6/AtS1SH/exjsAQXFsLnQkns09pnfuEKopirGcfUA+q/SxUVV2Ba+/LV9yTLXDvFfomf8+WrTIEWKOq6iu49madjPs9VBTlK1zjBb9x36sYSK7v9RO9AaqqFuMKkPe6rx+Iq7fyghOdK4RoGhLShGhefsA1Tqtq7NJvQKaqqgfrKDsbeE5RlGtO4vr/xvW4bjOuGZpLaeB+laqq7sbV0/MqrpmLvwA7FEXZjuvR57YGXOsOoIP7nI9xTVzAvf3VVFyr7m8GvgKuU1V150m07Xh1P5l9SuvcJ/Q4+4BW4npsO0ZRlDfd17gIV6/VWve+nr/j2pPz8WPu9TUQ6n4/tuHq0QtWFMUP1/6b09znp+H6bPxxnNcb4gqgn/s9TgO+VlX1ywaeK4Q4y2THASGEEEKIZkh60oQQQgghmiEJaUIIIYQQzZCENCGEEEKIZkhCmhBCCCFEMyQhTQghhBCiGZKQJoQQQgjRDElIE0IIIYRohiSkCSGEEEI0QxLShBBCCCGaIWNjXty9991yYKKqqvuOOdYN1/Yr/ri2NLlVNvcVQgghhHBptJ40RVH6An8C7eop8gVwp6qq7XDtcXdTY9VFCCGEEKKlaczHnTfh2kw549gDiqK0AbxUVV3pfmk6rs2VhRBCCCEEjfi4U1XVGwEURanrcDSQWe37TCC2roKKogQCgce8bAB8gG3yiFQIIYQQ56JGHZN2HHpAq/a9DnDWU/Ye4PF6jiUC+05wL+0Ex4UQQgghTkiz26jI2El+uoqjKBNbySEOJ49h9ZJKygpsNcq2y5jPf1b8jK+/Hys3bdadyv2aKqQdAqKqfR9JHY9F3V7D9Ti0ulhg2RmvlRBCCCGEm+aw47RbyS90sGfddtL/XMlBezg2uy9FsaUcjC7EtOcnopxdsGq+xEd50H6QD/4zvsecGsMHV71Lcs8ep3z/JglpqqruVxSlQlGUgaqq/gVcBcytp2whUFj9tXoeoQohhBBCnDLN6cByeA97N25hX+ZOMpw7yAyJQ1vZG52mw9OUgC6knDLfA5SZzdgOpBB2xEmfwm1EFWWT8n+vceBAOhu7debmW2897fqc1ZCmKMqvwGOqqq4BpgEfupfpWAe8cTbrIoQQQojWTdM0nOXF7M+wsi89l11/ppFtDULTTJT6R7A/dR/RZgf+nfPwtKWw9VAJ7941BU+DjhXfzMW5exH6zIMYfX2JGDeKveomrrnpJqKiorjqmmvw8vI6rfo1ekhTVTWh2tfjq329EejT2PcXQgghhKhSeOgQu9dsIfNABpiXs8PXm/y9vfEqCiI0IJSEeCdFoSV0jEnGY0sCW9aWYHc48fMuoU/HCCqsThxZB+G7GfjERBN1602EDx/Gmo0buebKK4mKimLWrFmnHdCg6cakCSGEEEI0OqfVQmZWJVvWHyZ9nUp+qRkAhz6YHT088DJCl/52BsSnkJVpol18IB0SQ9ibUcTcRauYMDCR3oFWvDYsx1h8mGD/HuDflk7PPoV/+/bo9HrS0tK4slpAi4iIOCN1l5AmhBBCiHOG5nSQu2Mbm1emE6utZ3/xbnaETaZokzdxkb60S7KyxGMHStsEhnrfRNZBM2mbclg8VwXgkpHt6JAYQqy/gWcHmsme/w3F27ZT7uFB5NjRR+8T0LHj0a937dpFdHQ0M2fOPGMBDUCnaS1vhQpFURKAvUDisdtN1aHlNVAIIYQQDaZpTkqKK9m4eC1bVu4i1xYKQGbyWvJCsjBpZoYl9uOG3pdxpNBCeLA3mqZx/dMLyCuuILVNMP06RdE73ovYhEh0BgP7pn/G4R9+wiM8nKiJ44gYMQKjr0+N+1oslqOPNSsqKvD09Kyviqe0BIeENCGEEEK0KI6KMir2baFszwYq9m7E1nk8X/7kOhbia6UosoD9AfvontKOblGd0JeGsmZbPmlbMnFqMP2xMRj0Ojav341/QSYc3k/xtu0Ub99Bx6ceJ7BLZyyZWdgKC/FT2qHT196gKS0tjZtvvpkPP/yQPn1OOMS+Ra2TJoQQQgjRIJqmodPp0Bw29k5/ml37bey1JlBpdlLc0ZNtWXPxS4jlnglX0D6pDcWVpfiYvFi85jCvv7+FUssB/AwOBoXa6dA5AU3TKN2zj+In7qcY0BkMeCckEHfpVDwjXY8rvaIi8YqKrLM+VWPQoqOjadOmTaO1W0KaEEIIIZoVzW6j4tAOLPu3ULF/K3pvf4o7XMPa5fvZvaM3Tk2HzaOc/MCD2DxNjI7vT79hPSjNM/PaN+s4f3AyfpEQtC2Ny0q2ElqaA0eyQYWo4AkYDX3wjo8j8cbr8G3bFp/EBAweHg2qW/WAdqbHoB1LQpoQQgghmo2832dQvHY+Nqudw7Z4kuKNFAaFsmTVCioOmukzJJnkTsHMy13A1Dbj8dOimP/HLj76bAkhhRnoTSYOKVeSGO2PY8l8ojQNv3Zt8R1zHr5tU/BrmwKA3mgketLEk6rbzp07z1pAAxmTJoQQQogm4LRasOzdRPmudVj2byH2pldw6oxs+mU+anoZe494YbdDSdd09nvsxIiJCannMa3r5KPXODhnHsu/+JlISw5GzQk6HQHdu9Hp8UcAsJWUYPT1Rac7pSFhtTgcDl566SWuu+66kw1oMiZNCCGEEM1bxeF0CpZ+jeXAVnDY0Zm98ErsQt7hI3zy4WYqK5x4eftjjc5lv/cO4mOCuCnucrppYRRv3MHCz59kReoYHrmhL9aDB4kLNBEyfBxhPbrin6pg9PU9ei+Tn98ZqfPq1auJiYkhOjqaBx988IxcsyEkpAkhhBCiUWh2G5YD2yjfvQ6ftr3wSuiMTm/AWnSEksTz2VsWg3dYMN5dKvhj34/kBsJ1YyfSsUMcB4sPo9+vUL5gKfmffMzO0lIAyk3+aDGFlFXYSbr5BpLrmHl5JlWNQRswYAAzZsxo1HsdS0KaEEIIIc4YzWGnZNNiynetxbJ3M5qtAp3BhCkgjHx9LJvWlLM9exKluyrBUExB3lYOl28h3BzAeQmxmP78FYv3GBKSkyjYk8vBzdvZrAsnI7obcf16MXp0V86P8j8rbak+SeDFF188K/esTkKaEEIIIU6Z5nRQeXgn9rJCfFP7g95AwbKZ6PQGfDsPozSwM/E9u1HqtPLzFys4km5H6RBBTKovXx38jPMK/YjZEIAjfR+aLZ0Cs5l0ayBe/QyM7N2NXh+/T37aAa7sFYevl+mstetszuKsj0wcEEIIIcRJcZQVUb5nvWvQ/54NOCvKMPqHEnfne+h0OjL3ZLBtRxGb1x2muKACbdABttm2YKg0Myy5N1cnj8QzIgJ7RQVrrr0RU1AQtOvIWmcI8zOMWNEztn8Cd1zctUnap2kaU6ZMIT8//0wFNNlxoB4tr4FCCCFEM2M9cghTSAw6nY7cue9Tsm4BBp9AvJK7453SE+/ELhSWwqwZa8jOKEGn12ENLCInYB/ebRwM8mxDSnoRlWkbMPr60v2t19DpdFTk5PDpHxn8umI/Pp5GRvSJZ8KARKLDfE9cqUaUn5+PzWY7Uz1oEtLq0fIaKIQQQjQD9uI8Srf9RemWP7Bm7yX62ufxjGmL9cghNGsFhvAE0rflUlhRwhH/A6zcvx7nykgmDetPlx5x7Cvfh3n7fspn/0bZ7j3ojEaCevXEo09/llmCmDg4mZAALzbtyuVwTinDesbh5dF0I7HS0tKYMWMGr776Kh4NXNy2gWQJDiGEEEKcPltRDkd+eQfLvi2AhkdUCiGjr8cU5NomyWoOZd36A6x8/zcqSh2U+h9hX2oaiYFx9J0STFJpDmZbCJ0iFHLVXMqBxBuvJyeuAz9syCVtbiaQT5uoAIb1jKNLShhdUsKassk1xqCVlJSc6ZB2SqQnTQghhGjlNIeN8l3rQdPwSe2L024lY8bDeKf0xLfTEMwh0QDkluXx0y+ryVrjwOnUiEz0YX/QNnp3S6GHPgLHyo3kLvkDW2EhCddeTcyFF6BpGnaHxr9eX8rejGL8vM2M6deGcf0TCA/2buKWu5yFSQLSkyaEEEKIhtE0jcqMXZRsXETZjuU4LaV4xrXHJ7UveqOZ2BteAqCovIT/zf2dbc5NqKU78S0Mo2dqXy47fxghYb447YPZ/NAjHNyZjs5gIKh3L8LPG441oR1zl+9l3IBETEYdvdpHcP7gJAZ3j8XDZGji1v+tOczirI+ENCGEEKIVylvwMcVr5qIzmvFR+uLbaQheiV2OHi8vtbJmxT5+X7QFg9WMra0nlw+5gP7R3TCpByn7/VdCLrsEvdGIn6IQNmQQwYMGsSWrkrf+2svaWUsw6HX06xRFkL8nV4/v0IStrZ+3tzcdOnTggw8+aFYBDeRxpxBCCNEqWHMPULx2PoEDLsToH4pl32ZseYfx7TQEvYfrseP+wkMs2rOCfX9Y8MgMxW53EhLvQef+kXQN8CBv2V8c+eMPbEXFmIIC6fnuWxi8vADYeaCAFz9fQ3Z+OUF+Hox2P9IMCfBqymbX6/Dhw8TExACuXsUztb9nPeRxpxBCCCH+pmlOLLs3ULTqZyx7N6EzmPBM6ISvfyheCZ3xSuhMSWUpy9RFLNu4kd3aTgx6A50YQofukfQfnERETCBZ8xaw5Zn30RmNBPfuRfiI4QR068r2A0VAGZ2SQ4kM8SEqxIdrJnSgX6coTMbG3a7pdFQ94nz00Ue5+uqrGzugnTIJaUIIIcQ5SHPYOPzJ/VhzDmDwDSZo2DT8u4/E4O2Pw+nA5rSjdxiYt3A9G5bn4FXRlssv7cIAnzDKitaS99v76MIvg5jhBPfpjc5kJKRvH4ocBhauPsjCl5eSeaSMbu3C6JQcir+PmadvHdDUzT6h6mPQxowZ09TVOS4JaUIIIcQ5wl5aiGXPevy6DEdnMOHdtg8B/Sbj22EAOoOJQ8WZLNm4kD/T19KppD/lu01UWGxER4XRwSMf30/msSsz07WeWY/umENDATAHBxEx4jw+nr2F2X/sxqlB5+RQLhulMKBLVBO3uuGa8ySBukhIE0IIIVo4a85+CtN+oXTrH+B04pXQGaN/KMHDLgdg0Z7l/L5rGbtzD4HJSffgLhSt0ZEYaWDw5D7Etglk47/uxxgeRvzFUwjp1xejrw8Hsor5/uetXDKyHb5eJlJiA7l4RDtG9I4jOrRpdwQ4Wfn5+Vx99dUtJqCBhDQhhBCixbLlZ3Jk3odY9m5EZ/LAv9tIAvpMQO8bzK68faSEJOCwO0lLS8ewM4He5o5c2NlJ2eI15KtLMO/VE33bYHQ6HV1eeBa9yYSl0s6iDYf5LW0tO/YXYNDr6JISSq/2EQztEdvUTT5lwcHBvPzyy/Tp06dFBDSQkCaEEEK0KE5bJY6SfEzBUei9fLEX5RA8fBp+3UdRrtcxe9cfLPzrTwqLSrk6+Hp2rM7FVhxCiI+OSHUlGSu34R0TTdJlUwgdMgiDe2V9vclEYUklNz/3G5ZKB3ERvlw/qSPDe8YR6Nf0q++fqlWrVmGxWBg6dCiTJk1q6uqcFFmCQwghhGgB7KUFFK+dR/G6BZgCwoi+7gV0Oh2aplFUWcJ3W+ewZO8KrHYb3cIVknfFoaoexEd7MnB8F6K9LeQuXkrokEH4JCai0+koKq1k8dqDFJVauWaCax2zbxeqdEkOIzUhqNnOemyoVatWMW3aNBITE5k3bx56fZPNOJUlOIQQQohzjTX3IIUrZ7vGmzkceLftRUBfV49Quc2Ct8kLnaZj3frddMkYRDt9KVG/LKWydDmhARF0njCF8PbhAPhcezUOp8Y6NYcFaftZtTULu0Ojc3IoTqeGXq/j0pFKUzb3jKkKaNHR0Xz++edNGdBOmYQ0IYQQopnRnA7QnOgMJioOqZRt/wv/biPx7z0Bc0g06Xl7+Xbpm5RbKjnfNIm1azKJzO2G5rRgL9hDYPduhA0ZTGC3ruhNphrX/m7RTr6YuwN/HzMTBiYxqm88bSL9m6iljaN6QGspkwTqIiFNCCGEaCYcFWWUblpM0Zq5BPSeQEDv8fh2HoJPaj8MXr7sLTjIt8veYcOhTXTJgKiDfVhg2EV0XAAXTutOvI8F3/iJR3cBsNocrFx/iN/SDnDB0GR6tY9gWI84YsP86NMxslkvOHs6fv755xYf0EBCmhBCCNHkKg6nU7xuAWXb/kSzW/GIVTAFu9Yf0xvNYDSz5vAm3v35K5L2J3BjpgOvgnwq2uwnuFc4XS7pi8FsPnq9vRlFLEjbz5K1hyi12AgP8qLS6gAgItibiGDvJmlnY3M4HBgMBp588kmKiooICgpq6iqdFglpQgghRBPQHDZ0BtejyPxFn1GZuQffzkPx7z4aj6gkALJKcsgtLYBMX9b/UUibg4PQOSrRRbSl/Z0jCOrRHZ17rJXD4cRg0ON0ajz9SRoFxZX07xzFqD7xdG0bhl7fsicBnEhaWhr//ve/mTFjBrGxsS0+oIGENCGEEOKsshVkUbRmLqVb/iD2plcx+gYSNuE2DD6BRzc6P1KWz3fbfmXz2r+ITh+OA29CwnwYN6UTyUFWgjtcBLg2Bt+y+wi/rTrA1j15vPfgCIwGPQ9c1YuoUF/8fczHq8o5o/pOAqZjxuC1ZBLShBBCiEamaRqWfZsoXv0r5elrQa/Hp31/NIcVAFNwNACFliK+XTGPg3/touPhrVyRWcne0F0kdEtk4B0T0Ll7w4pKK1m46gAL0vaTcaQMLw8jQ7rHYKm04+dtRmkT3GRtPdta2lZPJ0NCmhBCCNHI7MW5ZH31NHpvPwIHXYR/jzEY/WoGqcMHCvj557Xk7PHBy9mB2IoDtLnqYvqMHoXJ3w+nU6Oi0o6Xh5H9WcVMn7ONDonBXDKyHQO7ROPp0fp+pa9fv/6cDWggi9kKIYQQZ5yz0kLxht+w5WcSNu4WAMr3bsQzrr1rIoBbuc3CT4vnkLPERlGlH55eJlJTvega5iDuvEHoTSbKK2zMW7GPX5fvo2/HSG6a3BlN0zicW0psuF9TNbFZKCws5JFHHuHRRx9t7gFNFrMVQgghmpKjrIii1b9SvHYezopSPNt0RLPb0BlNeCd2PVrOYqtgwaLvKZg/n9gDdg5GT6RPqo7h14/Aw9P1q7mgpIKff0vn17/2UlZhp1NyCJ2SQwHQ6XStOqBt2bKFlJQUAgMDeeutt5q6Oo1GQpoQQghxBpTtXE329y+7dgVQ+hDYfzKeMe1qlNE0jbnLV7LlOxWPSgfdcsrxHzqAOy8aind0dI2yn/+6nYWrDzCgczQXnZdC27iWP1vxTKgag3bxxRfz3HPPNXV1GpU87hRCCCFOgWa3Ubr9Lww+QXgndcVRVkTBn9/h32ss5pCYGmXLSorY+utyth8JYP+efAz6CjrGWJlw/fmY/H0ByC2w8PWCHUwclERSTADZ+eXYHU5iwnybonnNUgueJCCPO4UQQojGZi/Oo3jdfIrX/4azvBjfTkPwTuqKwSeA0DE31Cibn32I1V9+QtGGYnaEDcPbu4ixkzvSo188RpMBcM3UnPn7Tn79ax8A7ROCSYoJOGcXnD1VLTignTIJaUIIIUQD5S36nKKVs0HT8G7bE/9e4/FK7FKr3KGMPaS99wmmnXkEW3IoSwmnczcTEy8diclsOFruu0XpzFyoUml1MKJ3PJeNVggPknB2LKvVyt13392qAhpISBNCCCHq5bRWULp1Gb4dB6E3e2EOjSOg7yT8e47BFFgzKGiahq2oGLvRi5mz11NW2htzXAUX36gwSOl2tJzV5sBk1KPT6bBU2umhRDBtbCpxEa13IsCJmM1mpk+fTlBQUKsJaCAhTQghhKjFVpBF8dp5lGxchLOiDL3ZE9+Og/HrMqxWWafdzppfvyP7lwUUGxUOBnbBZvWgfc9wRk/sjH+Aa7Nzh8PJwtUH+XrBDm6/uCt9OkRy5dhUdLpze7um05GWlsaKFSu4++67SU1NberqnHUS0oQQQgg3p62S7P+9jGX3eteuAKn9COg1Ho9YpVbZypISVn83A8vCP/EutVEclsRur460SwpmxKQOhLl7xpxOjeWbM/hi7nYO55ahxAcd3a5JAlr9qo9Bu/HGG/H1bX0TKCSkCSGEaNWcFWVUZKTjndQNvckDncFI4OCp+HcfVWtXgCqapvHu18+SsNhCXohC28vaMnXsJRzJKic6LrBG2WenryJtaxbxkX48fF0f+naMlHB2AsdOEmiNAQ0kpAkhhGilrLkHKF4zj5LNS8HpIP6ejzF4+hA59YE6y2ftS2fzVzNQkrui6zMCioeyKdpOdFwAgycOQqfTER3n6iHbeaCAxOgATEY9Q3vEMqBLFEN7xGHQSzg7kdY4i7M+EtKEEEK0Ktac/eT99imWfZvRGUz4dBxEQK9xGDx96iy/a+satn/1OYFbD+E0+THP0omsVcvx8fNgwsXt6d4n7mjP2P7MYj6fu520rVncflEXxg1IZHC3mDqvK+qWmZlJXFwcX3/9dasOaCAhTQghRCvgtFtxWsow+gWBwYQ1P5Pg4dPw6zYSg7d/necUV5Tww1tPkrJsL35GHUV92xFz3mWs/ymTYWOT6DckCbN7U/OsvDK+mr+DJesO4eVh5MpxqQzrGXc2m9jilZSU4Ofnx+TJk5kwYQImk6mpq9TkJKQJIYQ4ZznKS1wLz66Zi0esQuTF92MOiSb+jnfQ6Q21ylvtVvas+pOEpA74RoRzJCoQe49xhLXrwvmX9wGgQ9cOeHjWDBAvf7mWvYeLmDIshYvOa4uft7nWtUX90tLSuP7663n33XcZMmSIBDQ3CWlCCCHOObaCLIpW/ULJxkVotkq8kroT0HPs0ePHBrTiihL+mPMltnnLCM+pgHFjKO44Cm1nHw6XWglyGNGcGjq9Dg9PE6UWGz8t3c2kwUn4+5i5c2o3/LxNhLiX2xANVzUGLSoqCkWpPYu2NZOQJoQQ4pyhaRo6nY6STYspXvcbvp2GENh3Eubw+DrL55Tlseh/H+O1aC2hBXYs/p6Un38h67KiKPhxKwkpIYyY0J6Y+EAAKqx25vy5l+8WpVNqsREd5sPwnnEkRNX9yFQcX/WANmvWrFY/Bu1YEtKEEEK0aJqmYdm9nsLl3xPQdxI+Sl8C+kzEv8eYOpfQ0DSNygoLnl7eFFgKKdq8mTCDF/43XED/8ZMoKbGx/7O1jJ3SmZTUMHQ6HZqmMW/lfr5ZsIP84kp6tY/gqnHtSYoJaIIWnxt2794tAe0EJKQJIYRokTSng7IdKylc/gPW7L0Y/EPRNCcABq/aWyxZ7Vb+TF/Bzp+/J3VTHj3+/TBKh/YYbvoPq5ZmkZGh0dloJCDIyI13D3LdQ9MA16Kz69UcIoJ9uP+q3nRMCjl7DT1HJSUlcccdd3D55ZdLQKuHruoD2JIoipIA7AUSVVXdd4LiLa+BQgghTijz66ew7NmIKSSawP4X4ttpMDpD7QHnR8rz+W3LQnLmLqDD1kK8KzW0lDgSp93CGrWSjWsP4elpYtCIFPoPTUKnd/WcrdmezVfzd/CvaT2JDffDUmnH02yQhWhP0+rVqwkNDSUxMbGpq3I2ndKHRnrShBBCtAhOawUlmxbj120EeqMZ/+6j8es+Cp92feqcqVnlh61ziX79J+JLHRg7tSN12tUcMYQy/ZPVAPQfmsSgESl4uWdkbt2Tx4w529i+L5+oEB+KSq3EhoOXh/zKPF1VY9B69uzJN99809TVafbkEyeEEKJZc1hKKV47j6JVv+C0lGDwDcQ3tT8+qf3qLL/zyB5+WfcL5+X60fWyq7mw4ziKbwwjKDoJZ3AkAWG+eFbY6dE3jgHDUwgIcs3I1DSN52asZsXmTIL9Pbn94q6M6hOP0aA/m809Z1WfJPD66683dXVaBAlpQgghmiXNYSN/6TcUr52PZrXgndKTwAFT8IxLrV1W09icvYPZ62bj/ecWuu+0UGbTKO7Wl+D27Tnk057ZM1VMpoPcdv8wPDyNjJvSGYD9WcXER/ih0+loE+lPapsgJgxKwsNUf++cODkyi/PUSEgTQgjRrDgrLeg9vEBvpOLAdryTuxM4YAoekfWPYfrv4rcxLExj4M4KzDYnQf37En/ZpWRavPj6lT/IySwhOi6AERPbo3fvn7nzQAFfL1BZsz2bZ24bQJeUMKaNrR0AxenRNI3XXntNAtopkJAmhBCiWbAeOUThih8pV9OIu/1tDN7+RF/1ZJ2TAQD2FRwk1icco9mDTjEd8M5ZT2ivzrS57FJ8Etqwc1s233y8iqAQby66sgcdukah0+vYeaCAr+bvYO2OHPy8zVw9vj0psYFnt7GtiE6n44MPPsBisRAeHt7U1WlRJKQJIYRoUpWZeyhc/j1lO1aiM5rw6z7q6LG6Atq+gkP89OdMzEvW0eWIkX7vv8dY5Twcbw+kqMRORm4pbYGU1HAuuKwrnbrHYDC6xpXZ7A6e/jgNh9PJ1ePbM2FgIt6esgVRY0hLS+O9997jnXfewc/PDz+/2suiiOOTkCaEEKLJ2ApzOPzJ/eg9vAgcOIWA3hMw+NS9QOzh4ix+XvoNht9X02NfBTq9ntDz+uO02qiw61j2WzprVuzH18+Du/4dht6gp2vvOPZnFTNvxT5uPL8TJqOBR67vQ1yEn4SzRlQ1Bi06OprS0lK8vGS7rFMhIU0IIcRZU7U7QGXWHoIGXYwpMJzwKffindgVvadPvec5NSfv/vwaY2emo5kMhI8fQ8JFF6HzDWDFH3tYvngPNpuDHn3jGDK6HXqDnswjZXw1fwdL1x/C02xkVJ82JMUEoLSpvQuBOHOqB7SZM2cSFhbW1FVqsSSkCSGEaHTH7g5gDAgnoO8k9CYPfNsPqPOcvPICFv7+LQMNbYgdP45rx96KwX8jsUOGYQpw9bbt253Hknk7Se0cyXnjUwkN98VSaeft7zbyW9p+DAY9U4alMGV4W/x9zGezya3SqlWragQ0mSRweiSkCSGEaFQVh9PJnf06tvxMTCHRhE28o97dAQAKygtZ8OvnsGA5sdlWDgT6Ez1qJCkhCWgT2rB9cyaF+UcYMDyZhOQQbvu/oYRF+uFwuLaEMpsM7NxfwNj+CVwysh3B/p5ns7mtWmBgIF27duXtt9+WgHYGyLZQQgghzjinrRJHWSGmwAjsJQVk/+8l9+bn9e8OYHfY+X7BdIzf/U7EESs2X0+iLphEyqQL0Ht6smtHDovnqmQdLiYi2p8b7xmEwaDHUmnnpz92s3DVAd741zC8PU3YHU5ZhPYs2r9/P/Hx8Uc3o5ets2qRbaGEEEI0raO7A6yegzkkhuir/4PRL4iYa5+t9xxrRQVUVGAKCGBveRa97UZCr7uItuPPR282k51ZzK/frePgvgICg7254PJudO4Rg8Pp5Ndle5i5cCeFpZX07xyFpdKOt6dJAtpZVDUG7b777uOWW26RgHYGSUgTQghx2uwlBRSt+pnidfPRrBV4JfcgaOCU456Tn5PBiq8/wrxiCxGdu9Hl4X/zrwsfwnChDp1ej93mQA8YjXqKiyoYf1EnuveJx2DUU1xm5Z+vLSUnv5zOyaE8fH0fUmVCwFlXfZLA5MmTm7o65xwJaUIIIU5b6bY/KUr7GZ/2/V27A0Qk1Fs2Z+d21n31KV4bdxPohMLEUALOGwyAUW/g0P4Cli7YicGg57LrexMS5ss//n0eOh0czC4hPtIffx8z/TtF0SM1nO7twqT3pgkcO4tTxqCdeTImTQghxEnRNI3KQzsoXPETPkof/Lqeh9NqwVFaiCk46rjnllaW8elTd9B5ewkFXeLpdunVJLbvDsDhAwUsnb+TXTty8fYx039YEgOGJ6PT6di6J48Zc7aRfrCQ9x8cQXiw99loqqhHUVER/fv3JywsTAJaw8iYNCGEEI1H05yU71xN4fIfqMxIR+/lh3dKDwD0Zi/0wbUXLNU0jW3ZKgcWzKd/1+EEdu1Cu8uvJCk4kfjo5KPlNq4+yE/fbMTL28R541PpMygBs4eRvRlFfPbrdtZszybY34ObL+xMcIDM1mxqAQEBvP7663Tp0kUCWiOSkCaEEKJBcn54lbLtyzEGhhMy5kb8up6H3uRRZ1mbw8aKg+v466+faft7OlF5djKPOAns2oUxnUYCkHmoCIfDSWybINp1jOC88an0HpiAh6frV1NhSSX3vrYUD7ORayZ0YOKgRDzN8murKaWlpVFQUMDYsWMZNWrUiU8Qp0UedwohhKiT01ZJycbF+HYajMHTh/Ld63FaSvHpMKDeZTQAtuWk8+YfH9AxLZNu6Rbw8Sbp2quJGjECnV5PVkYxS+erqFuySUgJ4erb+h89t6C4gpVbMhk3IBGAFZsz6Zwcgq+3LETb1KrGoLVp04Z58+ZhNEpgPgnyuFMIIcTp0xw2itf/TuGfs3CUFaIzGvHvNhLv5O71nrMrbx9OzUm70CRi/CPom+NB2/QKIsaOIeHKaRh9fcjJKmHpfJXtm7Lw8DQydHQ7+g5xhbFSi43vF6cze9ke7HYnPVIjiAj2pn/n449xE2dH9UkCX375pQS0s0TeZSGEEIBr/FjZtj/JX/I19sJsPOPaE37hP/GM71hnebvDzspD65i7czHp+fvo7ZvETbFjCOzahWtufYqysfvxTUo8Wv7Annx2q0cYPKot/YYk4uVtptLm4PvF6cz6PZ1Si40h3WKYNjaVCJkY0GzILM6mIyFNCCEEADqdjpJNS9CbvYi89GG8krvXu7TFwt1/MmvLLxRUFBHlG8bNlvb4/LiKnR4qvT58F73JRIVvGAu+WEd8Ugi9BrShe584OnaLwqvao0urzcHMhTtREoK5elx7kmMDz1JrRUMtWrRIAloTkTFpQgjRilUc3knB0q8JHX8bpsBwHOUl6L180Olqr9i/O38/Mf6ReBo9mJ++lLUZmxjj2xHTzIWU7FAJ6NKZ5Ntvodzoxx+/pbNl3WGMJgNDR7djwHDXTE5N01i+KZNlGw9z/5W90Ot15BVZCAmoPTNUNC273Y7RaETTNEpKSvD392/qKrVkMiZNCCFEw1iPHCJ/yVeUq2kYfAKwFWRiCgzH4O1Xo5zd6WDVofX8unMxO/P2cFPPKxiVMpjRKUMY4quw/s67sXt50fbuOwkbPow/f9/FknlrMRj19BuaxIBhyfj4uWaAbtiZw4w529h1qIi4CD8KSioICfCSgNYMrVq1invvvZcZM2aQnJwsAa2JSEgTQohWRNM08uZ9SPH639CZPAgachkBfSeiN9cMSg6ng592LGD+rqUUWIqI8A3j2u5TGdimF5W5uXiEheEVFUnijddh7NAd37AgdDodUbEB9B3iWoTW1x3OCoor+O9Xa9mYfoSwIC/uuaw7w3rGYdDLLgHN0apVq5g2bRrR0dH4+vo2dXVaNQlpQgjRCjitFejNnq4xZnoD/r3GETTwIgw+ATXKlVSW4ufhi16nZ23GZuL8o7ml1zS6RXXEUVrGvvc+IXfJH3R79SWsvqGsLY1mw1tr6D8siRET2pOSGk5KajgAlTYHHiYDfj5mKq0ObrqgE+MGJGAy1r98h2ha1QOajEFrejImTQghzmFOWyXFa+ZSuPwHIi99CM/YVDRNqzEhQNM0tufu4hd1IZtzVN6e+B/8PXyx2q2YjWY0TePIH3+y9+NPsJWUEjhhMnv9OrJh7WF06OjRL56BI5Lxdz+2LCqt5JvfVFZtzeLt/zsPTw9jrXuK5mfTpk1cdNFFEtAah4xJE0II4aI5HZRsWkzBH9/iKMnHK7kHek/Xo6vqYSmjJJtP133Lxqzt+Jl9mNDuPPTu42ajGc3pZPuzz1Owei2+bdvS8anHmftHHjvWHqZH33gGjUjBP9AVzmx2Bz8v28vMhSqWSjuj+yVgd2q17imap+TkZM4//3zuv/9+CWjNhPSkCSHEOUbTNDJmPEzlYRWPmHYEn3clXnWsdVZgKeLOOY9i1Bu4pONERiYPxsPoWh5DczrR6V0zPNUvvmNLridDLhtMWFQABXll6PV6AoL+HsdWUFzB/725jOz8cnqmhnPdpI60iZTB5i3Bxo0bSUlJwcfHp6mrci6TnjQhhGjNKg7vxCM6BZ1Oj3/3kej7XYC30qdWL9aBwsPEB8YQ5BXAjT0uo3tURwK9/h6bVrZvH7veepfQiy5lS44Hazd743BqJO4vIiwqgKCQv3+ZHym0EBroRaCfBz2UcPp3jqK7En7W2ixOT9VCtZMmTeKVV15p6uqIY0hPmhBCtHCV2fvIX/wllt3rCJ/yL3zbD6izXHZpLtPXz2JdxhaeG/UgScHxNY47bTYOzfofh777nj3hvTng3x6HpqNLzxgGj2xLcOjf4exgdgkz5mxj/c5cPnhohCyj0QLJTgJnlfSkCSFEa+KwlFCw9BuK1y1A7+FF8HlX4Z3Ss1a5CnslP26fx887FqLXG7iiy2TiA2NqlCnZmc72N9/HdmAvYUOHUBQ3BF8bDB7VlpCwv5dhKCyp5Kv5O5ifth8Pk4FLRrbFx8vU6G0VZ5YEtJZBQpoQQrRAmqaR9fV/qMzag3/PsQQNuQSDl1+tcg6ngwcXPEdGSTaD2vThyq4XEuwVWKOMpdzK4vnpbDYNYtLNU2g3YQBt65iNWVJu5dbnF1JhdTC+fwKXjlIIdK+FJloOu93OfffdJwGtBZCQJoQQLUhl1h5MobHojWaCR1yN3tMHj4iEWuUySrKJ8g3HoDcwuf0YIn3DSA1LOXpc0zQy/ljJ+h2lbNnvwGp10qFLNDF9OgB/z8bUNI30g4W0iw/Cz9vMVePa07VdGLHhtQOhaBmMRiMzZszAx8dHAlozJ2PShBCiBXBaK8hf/CXFa+YSPHwagQMurLNccWUp326ezcI9f3LvgJvoG9u9VpmKnBx2v/8Rv+YkYDH7075LFEPHtCM8smbw2nWokI9+2sLWPXm8fu8wkmICal1LtBxpaWksWrSIBx98UJZEOftkTJoQQpyLLPu3kPvLO9gLs/HvNQ7/HqNrlbE7HSzYtZRZW37BYq9kbMowOoa1q3md0gr+mL4A3z++RY/GwDGdSBozkMjYoBrl8oosfPbrdhavPYift5nbL+5Km0jpOWvJqo9Bu/322wkIkMDdEkhIE0KIZqww7WfyF07HGBRJ1FVP1bneGcALy95mY9Z2ukS059ruU4kNiDp6rLLCzqo/97L893QqrXqGdOhH/zsuwyMsrNZ1rDYH97yylFKLjQuHpjB1ZDt8ZWJAi3bsJAEJaC2HPO4UQohmSNOc6HR6KrP3UbJpMcFDL0dv9qxRJqs0l1CvIIwGI2sObwKgZ3Tno4+yHHYnK5buYcWidCwVDtp2CKdXOw9SBnWp8bjL6dRYvS2LPh0j0el0LN+UQVJMAJEhsrhpSyezOJsNedwphBAtnaOijPxFn6M5HIRPugOPiAQ8Rl1Xo0y5zcL32+YxZ+fvXNF5MpNSR9IrpsvR41X7ZNrLSlkzfyPeJblMuW4YyX1Sa91v065cPv5pK3syinjy5v70UMIZ0CW6sZspzpLCwkLatGnDl19+KQGtBZKQJoQQzYCmaZSpK8mb/zGOsiIC+kw82ptWxak5Wbp3JV9t/omiimKGJfRnUJveR4877E7WrzrA2hUHmDzEnwPvvE2PEgtJl00hpmfbGvc7lFPC9F+2kbY1i7AgL+6b1pPu7Wo//hQtU2FhIYGBgYwZM4YRI0ZgNMqv+5ZIfmpCCNHE7CUFHJn3PuU7V2OOSCTykofwiEquVe6D1V+yaO9y2oYk8sCg20gJSQBcjys3rzvM0vk7KcwvJ8zbxqbnPyEk0p8ejzyEb3JSjes4nBpPfLiS4jIrV49vz/lDkvEwGc5GU8VZkJaWxrXXXsvrr7/O6NGjJaC1YPKTE0KIpqY5qTycTvB5VxHQdxI6/d+Byel0YnfaMRvNjEoZQmpYCkMT+h0dU2YptzL97RXkZpUQFRvAuCl9MK9bhCNuEG2uuQqDh2uxWZvdycJV+xnZJx6T0cB903oSEeJNkJ9nnVUSLVP1MWhdu3Zt6uqI0yQhTQghmoD1yCFKNiwkeMQ1GP1DiLvzXfRGc40yh4ozeXfV57QJiOHm3tNIDm5DcnAbABwOJwaDHk8vE20Sg+gcWETHXn4EtQ9HS720xmK0KzZnMv2XbWTmleHrZWZw9xhSE4LPeptF45JJAuceCWlCCHEWaQ4bhct/pOCv79CbPPHvMRpTcHSNgGZ32Pll5+/M2vILHkYPxrUd9vf5msamNYdYPFfl6tv746NZiN/4PUWbNpNvH01Q925HA9qug4V8NNu1GG18pB9P3NSPnqnyi/tcdODAAQlo5yAJaUIIcZZUHN5J7px3sOUexKfDQEJGXY/RN7BGmT35B3hz5accLsmiT2w3bux5OYGe/gDk5Zbyy6zN7N+dR2xCEHmr1rDzi4/RHA5S7ryN8JEjjl5H0zTe+34TWfll3H5xV0b3icdg0CPOTXFxcfzf//0fF1xwgQS0c4iENCGEOAs0p4OcH19FcziIuOQhfNr2qnncvWyGn4cPBr2BBwbfTs/ozkePr1m+nwWzt2I0Gpg4tTOJHgVse+Jp/BSFtv+8C6+oSCyVdn5cupvxAxII8PXg3mk9CPT1wNtTFqM9V61atYqAgAAUReHmm29u6uqIM0wWsxVCiEZk2bsJj7hU9EYzldn7MAWGo/fwPnq8wl7Jj9vnsb/wMPcPug2dTnc0sFU39/st5OWWMX5iMsExoWiaRu7SPwgbPAinTs+i1Qf4fO52CkoqufvSbozs0+ZsN1WcZVVj0Lp06cJ3330n+3E2b6f0w5G+byGEaASOsiJyfnqdzK+epHjtfAA8IhJqBLRtOTu5b97TfL9tHl4mL2wOG8DRX7Y7NmdyaH8BAKMmKAzy2kX6/f+iIicHnU5H+LChbNtfyL2vLuWNmRuICPbmpbsGS0BrBapPEnjnnXckoJ2jGvVxp6IoVwCPACbgNVVV3z7meA/gfcAMHASuVFW1sDHrJIQQjUnTNEq3LCXvt+k4Ky0EDr6EgJ5ja5SpsFfy1cYfmbdrCRG+YTwx/F46hP+92GxlhZ35P25lw+qDdOgaxaQJCex8+VWKt20nfOQITH5/b3b+87I9FJdbuf/KXgzqFi2/rFsBmcXZejRaSFMUJQZ4BugJVALLFUVZrKrqtmrFXgceU1V1rqIo/wXuwxXqhBCiRcr//TOK0mbjEdOOsAm3YQ6Lr1XG4XSwOmMj49sO5/Iuk/GoNrPz0P4CfvhyPYX55QwamUKXMAsb/3kfjkorbf95F8GDB/Pzn3vomRpBXIQft13UBQ+TAU8PGWLcWrz//vsS0FqJxvxTPRJYpKpqPoCiKN8BFwNPVStjAPzdX3sD+cdeRFGUQCDwmJdjz3BdhRDilGlOB5rdit7shW/noRgDwvDvOabGorQV9krm7lzMJGUkPmZvXhn7GF6mmgvJHtibz4x3VuAf4MnVt/enTVII6W++jSkwkE73/4s9lZ48+coSDmSVUGaxM21sKgG+Hme7uaKJVI1VfPvttyktLSUsTLbxOtc1ZkiLBjKrfZ8J9DmmzL3AAkVRXgPKgL51XOce4PFGqJ8QQpy2yux9HJnzLqbQGMLPv8u1IXpEQo0y23LSeXf152SX5tImMJYe0Z1qBDSnU0Ov1xHbJoiho9vSrXMIJs0KQNLNN1JabuWjBbv4bdUBwoO9eeS6PvTpGHk2mymaWFpaGq+88goffvgh/v7+eHl5NXWVxFnQmBMH9NScWakDnFXfKIriBXwMjFRVNQp4B/isjuu8BiQe89/gxqmyEEI0jNNuJX/JVxz+5H5sRTl4J3evVabCXsmn62by5OJXQdN4Yvg/6RHdqUaZrRsyePfFJZSWVKLX6+iRbER9+N+oL/wXzenE4OHB7JWH+H3NQS4ansLb/zecvp2iZOxZK1I1Bi0zM5OKioqmro44ixqzJ+0QNcNUJJBR7ftOgEVV1VXu798Hnj72Iu6JBIXVX1MU5UzWUwghTkpl9j5yvv8vtvwMfLsMI2TEtRi8/WqVe2vldFYd3sDYlGFc0XUynsa/H01aK+3M+8E1OSAmPhC7zUHuH3+y6823Mfr5EXTVtezOKCYlNpCLz2vLoK7RJEYHnM1mimagKqBFRUUxa9YswsPDm7pK4ixqzJC2EHhCUZQwXI8yLwKqr7S3C4hTFEVRVVUFLgBWN2J9hBDijDB4+6MzeRB5+WN4J9XcxNpqt+LQnHiZPLm44wTGtRtOx/B2NcocPlDID1+uoyCvnMEj2zJ4RBKHvvmWw//7Ab/2qewfOpXnZ+0jPjKPV+4egpeHUQJaK7R69eoaAU0mCbQ+jRbSVFU9rCjKw8BiXEtsfKSq6ipFUX7FNaNzjaIo1wIzFUXRATnAdY1VHyGEOFWaplG2fTllahrhk+/B6BdMzA0v1XrkuPPIHt5eNQMlNJnb+1xNQlDdc5xWLNmNw6EdnRzgtNko2rwF3yHD+NLYmW0L99OrfQR3XNxVHmu2YmFhYfTq1YvXXntNAlorJTsOCCHEcVRm7CJv4XQqDm7HHJFI1OWPYvCp2atlc9iYtXUOP+1YQIhXELf1uYrOEak1yhQVWHA6NYJCvLGUuyYFOHOzMAcHYfLzY+euLB76cDVmk4GbJndmeM9YCWit1O7du0lMTESvl/XmzyGn9IdZFtYRQog6OCwl5C2cTummJRh8Aggdfxt+XYfXWFYD4FBRJq+u+IiDRRmclziAq7tfjLep5sy7bRsz+GXWZqJiA7jq1n54eZvJWbKU3W+/R/CA/ij/vIvkpAjOH5LMpMFJBPvXXJpDtB5VY9Buv/12/vnPfzZ1dUQTk5AmhBB10BnNVB7aSUD/yQQNvKjGdk7VeRo9cDqdPDj4dnpU2xAdak4OiI4PZMLFnXHabOz9+FOy5s7HHpfEm4XxPF1SQZCfJ9dM6HA2miaaqeqTBK644oqmro5oBiSkCSGEm2X/FopWziZ8yr/QmzyIvflVdIbaf00WVRTz2+4/uajDOEJ9gvnvuEfR62o+msrLLeXrj1aRn+faOWDo6HbYCwrY/NDTlKansy+5D9/Sju4xMtZI1J7FKWPQBEhIE0IIHJYS8n//nJKNv2MMjMBefARzSEydAW1L9g7eWPkpZdZyesd0oU1gbK2ABuDn70lgsDcTL+lKQnKI6z4GPaWFxcxLGMk2Uyw3TezIxEGJMvaslSstLeWGG26QgCZqkYkDQohWS9M0yrb9Rd5vn+AoLyGg3/kEDb4Evan2VksOp4NZW+fww7Z5RPtFcM+AG2gTWHP2ZnGhhSXzdzJ2ckfM7r00NaeT3CVLCRs6BJ3BwHPTV5KVV8G903rQJtK/1n1E67Rs2TLatWsnAe3cJRMHhBDi5GgUrZ6D0T+MyMsfq7WdU3Wvr/yElQfXMSyxP9f3uLTGwrQA2zdl8vPMTTgcTrr1jiM+KRhbSQnpr75Owdr1FFY6aTduBHdd2hOzSY/JaKjnTqK1SEtL4/Dhw0yZMoXBg2UjHVGbhDQhRKuiOR0Ur5mLb8fBGHwCiJz6IHov31qzNo81JmUovaK7MCSh5hbD1ko783/cyvpVB4mOC+DCad0JCfOldNdutj//EpV5+fwW3g+PLF/+Dfh4mRqxdaKlqBqDFhcXx8SJEzGbzU1dJdEMSUgTQrQalRm7yP31PazZe9E0jcC+k2qteVZF0zR+3bkIi72SizuOr7VrQJU5321m8/rDDByRwrAx7TAY9OT+8Sc7X3+TcqMXs6LH0LZ/V267qGud54vWpyqgRUdH8/XXX0tAE/WSkCaEOOc5rRbyl35D8epfMfgEEHHR/+Gt9K23fIWtgvdWf8Hyg2vpE9sNp+asMTlAc2rYbA7MHkaGjW1H975xJKSEHj2erfNht1cUi2IGc+2lfRnWo+6dB0TrUz2gzZw5U8agieOSkCaEOOflL/qC4rXz8O8xhuDh09B7+tRb9nBxFi//9T4ZJdlc0WUyF6SOrjH7srjIwo9fbcDDw8gl1/UiKMSHoBAfLJlZ5KetImby+aT07czvh6/hxdEK4cF1r68mWqe0tDQJaKLBZHanEOKcZC/OQ3PYMAVFYi8pwF6Ug2esctxzLLYK7vzlEXQ6Hff0v4FOx2zttGOza3KA3e5k7OSOdOsTh06nIy9tNTteeR2r3UnPd97APyK0njuI1spqtR59rFlaWoqvr28T10icZTK7UwghNKeD4rXzyV/yFZ6x7Yi6/DGMfkEY/YLqP0fT0Ol0eJk8uanXFaSEJBDqHXz0uLXSzoLZ21i38kCNyQGaw8Gez78i84cfyfQIIa3rOFINXsjCGqK6tLQ07rrrLj799FM6dOggAU00mIQ0IcQ5ozJ7H0d+fY/KjHS8kroSOvbmE55TXFnKGys+YWTyIPrF9aBfXI9aZWxWBzu3ZTPwvGSGjVEwGPVomsbax5+hcvNGNvi3xXT+Jfxnclc8TLK0hvhb9TFoISEhTV0d0cJISBNCnBPKd60la+bzGLz9CL/gHnw6DjrhSv678/fz378+oKiimMFt+tQ4pjk1Nq07TOfu0fj4eXDHA8Pw8Px7+QydTsdKXQwF8YGMu/1SerWX8UWiJpkkIE6XhDQhRIvmqCjD4OmDZ5tOBPQ7n8D+kzF4+Z3wvN93/8nH674l0NOfp0fcR1Jwm6PHqiYH7NuVh9Ggp2P3aDw8TWhOJzu/nIU5KIDEiWO59N4rMJv0BPjW3qFAtG5btmyRgCZOm4Q0IUSLZC8tIO+3T6nM3E3sTa+gN3kQct5VDTp3R+4u3l/zJV0i2nNX/+vx9/h7jND2TZn8Mss1OWDi1C506BYFgK24hLSnXkSXvo3shC4kThxLWJBXo7RNtHwpKSlMnTqVu+++WwKaOGUyu1MI0aJomkbJht/JX/QZms1K4MCLCBwwGZ3hxCv5250OjO6dBVYd2kCv6C7o9X+vf7Z4rsqyhek1JgcAZK/ZwNaXX8NgKWNzuyFc+H/XEhN+4t460fqsX7+exMREAgMDm7oqonmR2Z1CiHObo7yE7P+9RMWBrXjGdyR0/K2YQ6IbdO6W7B28u+pz/m/QbSQExdInttvRY1WzO9t1DAcdDBnVFoPBFd7SN+wk6+n/UGbyo+LiW7n1iuEYDfp67iJas6oxaKNHj+btt99u6uqIc4CENCFEi6H38kFv9iR0wm34dR1xwokB4ApgP+1YwNebfyLGLxKz4e+/9ux2B4vnqjjsTsZe2ImY+CBi4l1LddjLyjD6+BCe0oY5nccx+srxdEiNarS2iZat+iSBxx57rKmrI84REtKEEM2aNecARxZ8TMSF97o2RL/03w0+t9xq4a1VM1hzeCP943pyW+8r8TR5ApCVUcyPX60nJ7OEnv3boDk1dHodmqax84dfyf7qS7o89RiBHVK5++nrGxQIReskszhFY5GQJoRoljTNSfHqX8lf9AV6T29shTn1boZen7npi1mfsZlru09lXNvh6HQ6nE6N5Yt3s2S+ipe3mctu6E27Dq5fqraiItKeeRWdupkMnyhi8SIQJKCJejmdTh5++GEJaKJRSEgTQjQ79pICcn95C8ueDXin9CRs4h0nFdBKKkvx8/DlgvZj6B7ViaTg+KPHigstLFuYjtIxggkXdcHb17VVT27aara+8ia6Cgs72g5m8kM3EhEiK8OL49Pr9cyYMQOj0SgBTZxxEtKEEM1OwdKvqDiwjdCxN+HXY0yDe7JsDhvT189iXeYWXhz9b/w8fEkKjkfTNHaruSQrYQQGe3PLv4YQFOJd47oLflqOt9NM2YXXcMNVMjlAHN+qVauYPXs2Tz31FDExMU1dHXGOkpAmhGgWnLZKnBXlGP2CCD7vagL6XYA5NLbB5+dbCnnlrw/ZmbeH81NH421yrWFWWlLJz99uJH17Dpff2Ju27SMIDvUBoGRnOvbycoK6daXvrVeRfaSEgT3aHO82QrBq1SqmTZtGdHQ0RUVFBAXVvy+sEKdDQpoQoslZcw+Q/cOr6E0eRF/7LAZvPwzeDV+HbEfubl5Z/gEWeyX/HHAj/eN6AqBuzebnmRuprLAzZnJHUpRwADSHg/3fzOLQrP9hCY5k5MdvkBIfTEp88PFuI0SNgDZz5kwJaKJRSUgTQjSZqoVp8xZ8jM7sScj5d6HTnfxjxh+2z8XT6MEjQ+8iPtD16On3X3fw1++7iIj25+rbuhMe6Qp9lowMtr30GhV7drPVLwn7eRcxQgOZGyBO5NiAJmPQRGOTkCaEaBLOynJy57xL2fbleCV2IWzSXRj9Gt4rYXXYqLBX4u/hy519r0Wv0+Nj9j56PDY+kP7Dkhg+TsFodO0yYDmcwbp7/kWFQ8fvMcMYef0FnNcrvr5bCFFDRUUFSUlJfPbZZxLQxFkhIU0I0TR0emx5hwgePo2A/pNPqgetuKKEl/58D71ez+PD/4mfhy9Op8ayhekYDHoGDE9G6RSJ0ikScD3e1BkM2INCWRHYiYy4Ttx983DaRPo3VuvEOSQvL4+QkBCGDBnCoEGDamwlJkRjkk+aEOKsKt+1FqetEr3Zk5jrXyJwwJSTCmiHijL598IX2FN4kHFth6PX6SnIK2fG28tZPFclJ7OY6nsS56WtZs2td1KekYGft5lxD93KMw9MkIAmGiQtLY0BAwYwe/ZsAAlo4qySnjQhxFmhOR0ULP2awuU/EDTkUoIGX4LOcHJ/BW3K2s5/l3+A2WDmyeH3khzcho2rDzL3h63odHDhtO507uEak+aoqGDvJ9PJnv8bed4h5K87xJjoaDomhTRG88Q5qPpOAn379m3q6ohWSEKaEKLROSwl5Pz4GpY9G/DrMZrAARee9DXsTgefrPuWMO8QHhx8O6E+wRzJKWX2zE3EJQQx+fJuBAa7xqSV7Exn56uvY8nIYlVwJ7Yn9eeBru3OdLPEOUy2ehLNgYQ0IUSjsuYeJGvW89iLjhA6/lb8u486qfOdmhNN0zDqDTw05A78PHyxFDrAB0LDfbnmtv7EJgSh1/89PTNz4WKKCsv4LmYUET268soVPfDzNp/ppolzVEZGhgQ00SxISBNCNCqd0YTOaCL6qqfwjFVO6lyrw8bbaTPwNHpwa+8rCfEI5vdfd5C2bC9X3dqPxJRQ4pNca5vZS0uxFRXjFRNN6eDxvLcrmIvGdWbqiHY1ApwQJxIdHc1jjz3G6NGjJaCJJqWrPsC2pVAUJQHYCySqqrrvBMVbXgOFaOE0p4Oybcvx6TgInU6HpjlPev2z0soyXvrrPbbn7uLqbhfRy7c3P361gZysEnoPTGDkpPaYTK6lNUr37EV94SUcOgO9334NncFA5pEyotw7CwjREGlpaXh6etK1a9emroo495zSvxSlJ00IcUY5LKXk/PQalt3rifT0wTulx0kHtJyyPJ5b+hbZZUe4p/8NGA+E8PHHf+HlbeLyG/vQtn3432UXLWHXu+9hNXrybchgAg8X0y4+SAKaOClVY9Dat2/PTz/91OD9YoVoTBLShBBnjDX3AFmzXnCNPxt3C94pPU76Gg6ng2eWvEFxZQmPDP0HHcLbsebQPlJSw5h4SRd8fD0AcNps7P34U7Lmzic3KJavA/pz3rAOJEYHnOlmiXNc9UkCH374oQQ00WxISBNCnBFl6ipyfnodvdmT6KuexDM29ZSuY9AbuKHnZRTscaBl+EI49Ozfhp7929T45ak5neSoe1gf3oU/Qrpz56U9GNK94RuyCwEyi1M0bxLShBBnhN7DC4/IRMIvvBej38lvVL5oz3KsDivDYgeye1EFm9ceJqldGR26RtUIZ7aiInQGI0ZfHw6Mu5qt6zN5+ZrexMvitOIUfPbZZxLQRLMlEweEEKfMUVGGZc8GfDsMBFwbpp/soyJN05i1dQ7fbZ1DV1N3fLclU1xUwZCRbRk8MgW94e/xbBXZ2Wx+7Cm0oBD6PP8UTqeG1ebA00P+vSlOTtVn1Wq1UlxcTGhoaFNXSZzbTukZuuxvIYQ4JdbcAxz+5H5yZ7+JvTgP4KQDmt3p4N3Vn/Pd1jkMDB6Ic3k0er2O6+4cwNAx7WoEtLK9+1h/30OU5BbwnSMZq82BXq+TgCZOWlpaGhdeeCH5+fmYzWYJaKLZkr/dhBAnrUxNI2f2G+hNnkRNewKj/8lvteTUnLy47B02Hd7JxV3GM7XjRDYFHqJ9lyjMxwSvoi1b2fzUs5Q69MxTzufWW0Zjdi+/IcTJqD4GzWazNXV1hDguCWlCiJNS8Od3FCz9Go/otkRc9H+nFNAAdOiIymuLtjmJIUNd66l17R1Xq5zNamPN869R6vRgy6BLePKm4QS4Z3gKcTJkkoBoaSSkCSFOit7DG98uwwkddzN648lvtZRRkk32kXy2/17Cwe12klPD8PGrO3RpmobRZGTrgKmERIXw4AU9MMjuAeIUrFmzRgKaaHEkpAkhTsiWn4mtMAfvpK749xoHnPz4M4D0vL28/uO3hKYrmDUPxl7Ykd4DE2pdS9M0Vr75KT72cjr/8w7uvHWUbO0kTktMTAwDBw7khRdekIAmWgwJaUKI4yrfs4GcH15B7+FD3G1voDOYTuk66zI28+ryj4gu60BYSACXXNWbsEi/WuXsVhvzH3+VwG1p7E3oTGenE71Bxp+JU7Nz506Sk5OJiopi+vTpTV0dIU6KhDQhRJ00TaN4zVzyfvsUc1gcEVMfOOWA9tPyP/hp2wJi4iP5v3GXEujhj8FYe3J5fn4pix56hqisnWR36M+EJ+9BJwFNnKKqMWjXX389Dz30UFNXR4iTJiFNCFGL5nSQN/9jitfNx7tdb8IvuBu92eukr+N0avz5ezob5xeRENiN+66egHc91zmUU8Ky+x4jvugAtpHnM+Uf15xuM0QrVhXQoqKiuP7665u6OkKcEglpQojadHo0p4OA/pMJHj7tpDdIBygutPC/L9dycE8hHbpGMXZKx3oDGkBooBeFqb3ppIyi80XjT6f2opWrHtBmzZolY9BEiyU7DgghjrLlZ6A5nZhDY9E05ymFM4C8I6W8+8piHDYnYy7sSN/+yXVONLA7nPz0Yxp9AyuJHTHsNGsvBFgsFvr160dAQIAENNGcnNLMJ+lJE0IAUHFwO1kzn8cUFEn0dc+fckBzOB18vet/5AQW0aVvbL0BrbCkknffnkOPVf9jn6eRyP59MHp7n24zRCvn5eXFRx99RHx8vAQ00eJJSBNCYNm7iaxZz2P0DyH8wn+e0vIaRQUWfvp2A1nJW1mTv5ZLJkziog7j6rzW4dxS3nn5O0bsnIfZ14cezz0pAU2clrS0NHbu3MlVV11F7969m7o6QpwREtKEaOXKd60j+7sXMQZHEXXF4xh9A0/6Gvt35zHrs7VYKirZY9jHtUOnMr7deXWW3XO4iOkvfsmY/YsxR0bS/T9P4BF6arsWCAE1dxKYOnUqnp6eTV0lIc4ICWlCtGKaplGYNhtTaCxRVzyGwdv/pM9f89d+5v+0laAQby6+sSsZWjQD4nvWe46vl4k4gwXvpCS6PvkIJr/aa6UJ0VDVJwnMnDlTApo4p8jEASFaKU3T0Ol0OCvL0ZxODF6+J32NtSv2M+e7zXjHatx600h8feufvanuzyfe045XRDhOpxMcDvSmU1t3TQiQWZyiRTmliQOnNjJYCNGilWxeStZXT+K0VaL38D6lgAaQ2DEQa2oma6PncchyuN5yv63cy/xHX2bNP+6lIicHvV4vAU2cts2bN0tAE+c0CWlCtDIlGxeRO/tNVxfzKfSkH9ibz5cfpJFXUsTzK95iT+Am/jXoFlLDUuos//3CHex78y16FqlEjjoPj9DQ02uAaPUqKioAuPHGG5k/f74ENHHOkpAmRCtSvOF3cn95B6/ELkRe8hB6c8PH72iaxuq/9vHZOys4cqSE5xa8y+GSbO4fdBu9YrrUWf6zH9ZT/tFbdCjdR9xVV5Jy43Xo9PLXjjh1aWlpDBw4kA0bNgCuJTeEOFfJ35ZCtBIlm5dwZM47eCV1JWLqA+hNHg0+125z8PO3m5j7/RaSlTDGXJtMqamIhwbfQbeoDnWecyinlNyfZ5NQkUXSnbcTf/GFp7S0hxBVqsag+fr6EhUV1dTVEaLRycQBIVoJ65FDFC7/gdDxt6A3mk/q3NnfbGTD6oMMHJnMeWNS0el12Bw2THVsuF41IQFg/8E8AouzCehYd5AToqGqL7Mxc+ZMecQpWppT+heqhDQhznEVh3bgEaOcUi9WVeAqyCvn0KEjfJX9FX3jujO5/Zi671Vp5+03fqb3wZX0f0aW1xBnxvbt2zn//PMloImWTGZ3CiFqKl47j4wZD1O6afFJnadpGiv/2MP/Pl+Hpml4+uv5Jvcb9hUdIi4gus5zSsutvPncN/T46xt0hXnYS0vPRBOEICUlhauuukoCmmh1ZDFbIc5RRat/JW/Bx3i37YVvx8ENPs9mdfDzzI1sWZ+B0imC0goLL694l935+7l3wE30jO5c65yC4go+/s90+qoLMURE0eu5J/EICT6TzRGt0Nq1a4mPjycsLIzHHnusqasjxFknIU2Ic1DR6jnkLfgE73a9iZjyL3R1jB2rS0FeObOmryErs5jh4xQGDE/i2WVvsePIbu7udz19YrvVOqe8wsb7j3/M4D2L0Ce3o/fTj2D08TnDLRKtTdUYtGHDhvHhhx82dXWEaBIS0oQ4x9gKsshbOANvpS8RF/6zwQHN6dT4+qNVlJZUcvkNfWjbPhyAgfG9GNKmLwPie9V5nrenidQR/fCM09H9HzfJIrXitFWfJPCf//ynqasjRJORiQNCnIMqDm7HI7otOsOJ/x2maRpooNPrOLg3Hx8/DwJDvDhcnFXv+DOAHbuyqVi2mK5XT0VnMJzJ6otWTGZxinOUTBwQojUrXDmb0h0rAPCMa9+ggGattPO/z9fxx2/pAMQlBhMU4s2n62by4G/Pk1mSU+d56zbsZ8OjT1H24ywKNm46c40QrZqmaTz11FMS0IRwk8edQpwDCtNmk//7DHw7DcE3tX+Dzsk/Usa3n67hSHYJ0RMCj77+7ZbZzN+1lEnKSCJ9w2qd99ef28h9/RVibEVE33o7wT26n6lmiFZOp9Px6aefommaBDQhkJAmRItXtHoO+Qtn4NO+P2GT7mzQOenbs/n+i/Xo9TquuKkvyYorjM3esYDvt81jRNIgruw6pdbaagvnrML6yVsEalZSHnyAqH51j1MT4mSkpaXx7bff8uKLLxIeHt7U1RGi2ZCQJkQLVrRmrmsWp9KX8AvuQac/8diwkqIKZk5fS1i4L1Ov7UVQiDcAm7K288XGHxgQ15Obel5eK6Bpmsb2nZmkmk10efxRglPbNkqbROtSfQxacXExwcGydIsQVWTigBAtWN7vM7DlZRJx0YmX2XA4nBgMrmGou9Vc4hODMZn/DnVOp5Pf9/zF8MT+GKuNZ9M0jfzd+wlJScBqc4DTidlDZnCK0yeTBEQrIttC1aPlNVCIE3BaLejNXq6ZmU7HCScJHMkuZeb0NQwfp9C+S82NqQ8WZeBl8iTUu3YPhsOpMev5T4hJm0vyPXcTPbzhi+IKcTwS0EQrI7M7hWgNSjYt4eC7/8BWkIVOpzthQNuxOYuPXv+T8nIrXj41N1bPLy/kmaVv8spfH3LsP9isNgezHnqFuLRfscS3JVzGn4kzSK/X065dOwloQhyHjEkTogUp3fYXub+8jVdCJwy+Qcctqzk1lizYybLf0omOC2DqNb0ICPI6etxiq+C5ZW9TbrPw4ODba4xBs5RXMPv+54g7uAVLx16Mevp+WQtNnBHZ2dlERETQu3dvfvnll1pjH4UQf5OeNCFaiDJ1FTk/voZnrELExQ+gN3kct/wuNYdlv6XTrXcc194xoEZAszsdvLr8Qw4WZXDvgJtJCIqrce43H84h9uAWrANHM+KZByWgiTNi1apVDB48mG+//RZAApoQJyA9aUK0ABUHt5P9w3/xiEom8tKH0Zs96y1rszowmQ20bR/B1bf1o01ySK1fhj9tn8+GrG3c3Gsa3aI6HH1dczjQGQycf+140jvEM3xU70Zrk2hdVq1axbRp04iOjmbYsGFNXR0hWgTpSROiBTBHJOLffRSRlz2C3sOr3nLbNmbwxjO/k51RDEBCSmidvRXj2g3n9j5XMzJ50NHXDm7fy6Ib/kHBpi2EBHjRTwKaOEOqBzQZgyZEw0lPmhDNWGXWHkxBUeg9vAgdc2O95ZxOjUW/7mD54t3EtgnC+5gJAlUySrIJ9QrC2+TFsMS/dybY8dcGDr7yMnrNQUGZjeOPdhOi4XJycmQWpxCnSEKaEM1URcYuMr96Ep+2vQi/4O56y1nKrXz/xXp2q7n07B/PmMkdMRprjyErqijm6cWvkxzShvsG3nL09TU//U7ppx/gMHmR/PCjJHVTGqU9onUKDw/n2WefZfDgwRLQhDhJEtKEaIYqs/aS9fXTGLx8CR4+7bhlVy3bx95dR5g4tTM9+rWps4zD6eC1FR9TbC3log7jj76+7Oc/4ZN3KfENpc+zjxPRJqrO84U4WatWrcLpdNKvXz8uvvjipq6OEC2ShDQhmhlr7gEyv34KndmTqGlPYvQPrbtcpR2zh5FBI1No1zGCqNiAeq/59eaf2Jqzk9v7XE1itZmcoR1TWdl+CFMeuI6AIL8z3hbROlWNQWvbti1z5syRWZxCnCKZOCBEM6JpGjmz30KnNxA97QlMgbU3m9acGovnqbz38lLKS60YDPrjBrSVB9cxe8dvjEoezLDE/titNla+9DYV2Tm0TwrluufvkoAmzpjqkwQ+/fRTCWhCnAbpSROiGdHpdERc+E80pwNTcO1Hj9ZKOz98tR51Szbdesdh9jjx+mVtAmMZltCfa7tPxVZWzsJ/PYF/5m62R0bR/aopjdEM0UrJLE4hziwJaUI0A/aiXEo2LSZw0NQ6wxlAaXEF33yymoxDRYy+oAN9Bycet5eiwl6Jh8FMlF84t/e9moqCQpbe+wi++VnkDLmAyVde2FjNEa3UrFmzJKAJcQZJSBOiidmL88j48gmc5cX4dh5W5yNOgAWzt5GbXcql1/ZC6RR5/Gs6Hby47F1CfYK5vc/VlGVls+JfD+NRVkzehCu58ObJjdAS0Vo5nU70ej3PPfccxcXFBAcHN3WVhDgnyJg0IZqQvbSAzK+ewFFWSOTlj9Y7Bg1g3JROXHfngBMGNE3T+GTdt2zJUekY1g6A7dkVZDk8Kb74JiZLQBNnUFpaGuPHjycrKwuj0SgBTYgzSHrShGgijvJiMr96EntxHlGXP4pnTLtaZdau2M+2jZlcfmNvvLzNeHnXvUhtdfPSl7Bw9zIuSB1N98ogHBUV9OrahuD/PkNSTP0TDIQ4WWlpaUcXqpUJAkKcedKTJkQTqczei6M4j8hLHsIzrn2t4+tWHmDOd5sxGHQ4HVqDrrkxaxvTN8yiV0xXhuUHs/GhR1n31scAEtDEGVU9oMkYNCEah/SkCXGWaZoTnU6Pd2JX4u58D4OnT60y6pYs5ny3ieTUMC69vjcGQ8P+PaXX6ekQ1pYp2RHs/ewNDnuGE9ZnxJlugmjl1q5dKwFNiLNAetKEOIucVguZXzxOyZY/AOoMaAf25PO/z9cRFRfI1Kt7NiigOZ1OADqFK1yxN5jsz74g3TeeyHv/jxFDUs9sI0Srl5CQwPDhwyWgCdHIJKQJcZY4bZVkzXqBioM70BlM9Zbz9DYRlxjMFTf0wexx4s5uu8POf5a+wc87FlKcfYQDv/7GhoB2tLvvXwzrm3QmmyBauW3btmG1WgkJCeGDDz6QgCZEI5OQJsRZoDls5Hz/Xyr2bSFs0p34tu9fq0yFxYamaYRH+nHVrf3w9j3xJAFN0/ho3Teoh7cTYPbFNzyUHeNvouf//YOB3WMboymilUpLS+OCCy7gmWeeaeqqCNFqSEgTopFpTgc5P71O+a61hI67Gb/OQ2uVKS+18vHrf7JornpS156zcxFrNv3BDUtshC3aiUGv447rh9Kvc/SZqr4QNSYJ3H777U1dHSFaDQlpQjQ2nR5TSAzBI6/Bv8foWoetlXa+/ngVhQUWUpSwBl92XcZmfl/wNVcuKIZ8C9/vB6ezYbNAhWgomcUpRNOR2Z1CNBJN03CUFmD0CyZ46OV1lnE4nHz3+ToyDhYy9ZpetEkOafD1Cxf9yZRFBZSYA/gxcQR3XzcWvV7WqhJnTmVlJbfffrsENCGaiIQ0IRpJwdJvKF43n9gbX8boH1pnmTnfbWbX9hwmXNyZ1M7H30mgiqZpVObk4PHDEg75xjInZij/vm0YqW1kpXdxZnl4ePDpp58SEREhAU2IJiAhTYhGULJpCYV/fYdft5EY/OrvHWvXIYLgUB969m/ToOtWVFp4ZeVHjG07jFX9LmVNkZknbxlESlzgGaq5EK5HnBs2bOCWW26hS5cuTV0dIVotCWlCnGGWA9vInfMungmdCR17U53b5RTmlxMY7N3g3jMAS1Y2fz3yAOVtdVQmDeD62yYwpaSSNlH+Z7L6opWrPgbtqquuwtvbu6mrJESrJRMHhDiDbIXZZH/3IqbAcCKm3IfOUPvfQZvXHuKt5xezZ+eRBl+3eIfK6nvvRVdYip9He3pFdSfA10MCmjijjp0kIAFNiKYlPWlCnEEGn0B82vUmcMAUDF6+tY7vVnP56ZuNxCUGE58Y1KBr5v7xJ+rrb1DiCT/3a09FcRcKSyoJC/I609UXrZjM4hSi+ZGQJsQZoDnsaHYbeg8vwibeUWeZwwcKmTl9DWGRflx6XS+MJsMJr1u6Zw87//sqJTHBfNspGGPBQJ6/Y7AENHHG7dmzh5iYGL799lsJaEI0EzpNa7x1lRRFuQJ4BDABr6mq+vYxxxXgfSAIyAIuU1W1oAHXTQD2Aomqqu47QXFZOEo0Kk3TODLvAyoP7SD62ufRmzxqlSktruC9l//A7GHkun8MwM/fs8HXX/+/eby4ugLfQE+evWWoBDRxRpWXlx99rFlZWYmHR+3PrxDitJ3S+kiNNiZNUZQY4BlgENANuFlRlA7VjuuA2cDzqqp2BdYDDzZWfYRoLEWrfqZk3QK8knvUGdAAfPw8GDA8mWk39zlhQLOXW9jx/Evkbt/C88veobxTIjHRwTx/mwQ0cWalpaXRr18/Vq5cCSABTYhmpjEfd44EFqmqmg+gKMp3wMXAU+7jPYAyVVXnub9/Fgg89iKKogTW8bpsSiiahTI1jfyFn+GT2o/g4dNqHa+w2CgrrSQkzJcBw5NPeD1rQQHbnn6Wsr37WORzhI2RZUxsN4KX/jG4zlmiQpyqqjFoUVFRJCYmNnV1hBB1aMyQFg1kVvs+E+hT7fsUIEtRlI+B7sB24B91XOce4PFGqqMQp6wyYxc5P76GR3QKYeffhU5Xs2PabnPwzSeryc8t486HhmP2OP4ft/JDh9n25H+wFRWxYVwXlgZkMDR4Ap0ilMZshmiFqge0WbNmyRg0IZqpxlyCQ0/N8WA6wFnteyMwDHhXVdUewB7glTqu8xqQeMx/g898dYU4OQbfQLwSuxAx9cFajzmdTo3vv1zPgT35jD6/Q4MC2uYH/42zsoItFw5maUAGfiUdubp/7b0+hTgd6enpEtCEaCEasyftEDXDVCSQUe37LCBdVdU17u+/Br479iKqqhYChdVfc803EKJpOK0V6ExmjP6hRF7yUK3jmqYx9/vN7NicxegLOtCpR8wJr+kZGUHo4EFkKr2Zv2smvoYEXrv8Jvy8zY3RBNGKJSUlceONN3LttddKQBOimWvMnrSFwAhFUcIURfEGLgLmVTu+HAhTFKWr+/tJwNpGrI8Qp01zOsj+30vk/PAK9c2M3rj6EGtXHGDA8GT6DUk67vWO/PkX1oIC9EYjfpdM47+/HqRN+Shev+Qu/HxkELc4c1avXs3hw4cxGAw88MADEtCEaAEarSdNVdXDiqI8DCwGzMBHqqquUhTlV+AxVVXXKIpyIfChoig+uHrermqs+ghxujRNI2/+x1j2bCB0/G31DuTv1D0am81BrwHH34/z0Pc/sn/G50RNGI/HZRP4eutP3HXFSPqmxuPtaWqMJohWqmoMWr9+/fj888+bujpCiAZq1HXSGouskyaaQmHaz+QvnE5A/8mEnFf73xN7dx0hKiYAT6/jByzN6WTfjM/J+HE2oYMGcnDYOL499BnoHDwz6gHCferfkF2IkyWTBIRoFprXOmlCnEvK1FXkL5xR71Ib+3bn8dWHq1gwe9txr6M5HKS//hYZP84masJ4joy5iPc2z6C4soT7B98mAU2cURLQhGjZZFsoIRrA4OOPV3L3OpfayMkq4dtPVhMU4s3Iie2Pex17aSmlu3cTP+1ysjoP5NWl76MPLOLOPjfSNkTWqhJnjqZpvPDCCxLQhGjBTvi4U1EUX+AFIBWYCjwH/EtV1dLGr169dUpAHneKs8Bpt6I31j/DsrS4go/f+AuH3ckNdw8i4Dg7Amiahk6nw1FZyZYDxTw1YzGm9mlc2nUsF3Ya1RjVF61cQUEBVqtVApoQTa/RHne+gWsJjAigAvAHPjiVmwnRkjgrLWRM/zeFy7+vt8yv32+hvMzKZTf0Pm5Ay5j9C+pL/8Vps2Hw8GD5pgwiA0J5dfyjEtDEGZWWlsZtt91GZWUlQUFBEtCEaMEaEtK6q6r6MGBTVbUcmIZrL04hzlma00HOj69izdmPOaL+x5DjLuzEpdf1JjousN4yOUuWsvfjT8HpBJ2ONYc3YU7YzrO39ScqqP7zhDhZVWPQtm3bRklJSVNXRwhxmhoyJs1xzPcGau4cIMQ5RdM08hZ8QvmutYSOvQnv5O61yqhbsmjbIQK/AE/8AurfMD1/zVp2vfE2/p06Yrj0Ou58bzbFEUuJC4zC09PQmM0QrUxVQIuOjmbmzJmEhoY2dZWEEKepIT1pfyiK8gLgpSjKGOB7YEmj1kqIJlS06meK184joN/5+PccW+v4muX7+fbTNaxPO3Dc6xTvUFFfeBnvNvH43nAHj32+lLygP/Az+/LAoNvwOM5YNyFOxrEBTR5xCnFuaEhIewAoBYqAZ4BNwL8as1JCNCWDpy8+HQcRXMdaaOnbc5j7wxbatg+ne5+441/I6cS7TRuC7/gnj36RhjMhDS9PPY8M/weBXgGNVHvRGvn4+NChQwcJaEKcYxoyu/MCVVV/Oua1q1RVbbJlq2V2p2gMmt2GzuhaiLZqJmZ1B/fm88UHaYSE+nDNHQPw8Kx7tIDTZkNvcl0n80gpD73zF1aPHEwp63lwyG20D2vbuA0Rrcbhw4eJiXHtDVvXZ1YI0Wyc0h/OesekKYoyCTABLymKoq92AxPwJCB7i4hzhq0gi8wvHid03M14p/Ss9cvObnfw3efr8PP34Iqb+9Yb0BwVFWx55AlCBvQjdspkfL3NxEf4cd2kfkSEXYy3qf4ZoEKcjKpHnA8//DDXXnutBDQhzkHHmzjQDTgPCAfuqva6HXi1EeskxFnlKC8h65tncNoqMQVH1VnGaDRw8dU98fP3wNev7o3PNYcD9eVXKd29m+CJk7DZHfy861eGjAwlMVoeb4ozp/oYtHHjxjV1dYQQjaTekKaq6tPA04qi3K6q6jtnsU5CnDWaw0b2/17EXpRL1LQnMAVH1zheUlTB3vQjdOkVS1xCUP3X0TT2fPgJBavXEHXNtTy/uhLzwc85bE5jdMqQxm6GaEVkkoAQrUdDluD4SFGUCwFfXI88DUCKe+00IVosTdM4Mu8jKg5sI/yCe/CMS61x3FJu5YsP0igqsJDULhRf//qX2jj8w09kzZ1H2MSJvL7Xj2yHit68kV4xXbm++6WN3RTRSuTn53PNNddIQBOilWhISPsWSAKigPVAX2QJDnFO0NCZzAQOmIJvp8E1jlgr7Xz14Sryj5RxxU19jhvQAIy+PgQNGsQHZUkcLN+DWdlEu5Ak7ul3PXp9QyZRC3FiwcHBvPzyy/Tu3VsCmhCtQENCWjegLfAu8AquZTvebcQ6CdHoNM2JTqcndPQNHDvDWXNq/PDVejIOFjL1ml4kptS/KKjTakVvNhM5ehQfH/IjfXsOoyYEsK8iivsH34ZZ1kITZ0BaWhrl5eUMHz6ciRMnNnV1hBBnSUP+iZ+pqqod2Al0UlV1KyCjoEWLZc3L4PBH91GZvQ+g1qy4vbuOoG7JZvT5HUjtHFnvdcoPHmLtrXdQsH4DAJePSeX+K3tx57ApPDvqAXzNPo3VBNGKVI1Be+6553A4jt0ARghxLmtISCtVFOUKYCNwiaIonXGNTxOixXFUlJE96znspQXoPbzrLJPULowb7h5In8H179lpLShg21PPoDkcbC7QkV9eyPtb3yEk2gKA2WBqlPqL1qX6JIHPP/8cg0G2EhOiNWnI4847gJtw7TxwA/AH8FBjVkqIxqA5HeT88Aq2gmyirngcU2B4jeP7d+eh0+mITwomJr7+mZwOi4VtTz+HraiINQMuZcHcXSSW/UiBtQCjXn6JijNDZnEKIU4Y0lRVTQfud397KYCiKB0as1JCNIaitJ+x7NlA6Lhb8GrTscaxvNxSZk5fg3+gFzf/czA6fd0Lg1athVa2dy87BlzEgoMayYP3kGXJ4cHBd5ASknAWWiJagzlz5khAE6KVO96OAwm49urMBx5QVbVcURRfXLsN3AnUvaKnEM2QpmlY9m/BW+mLX/dRNY5Zyq188/FqAKZe07PegFbFHBrKgZ5j+THLi65DcthZsYcbe15Otyj5t4s4fQ6HA4PBwBNPPEFRURFBQfX36gohzm3HG5P2CZCHa+mNhxRF6QNsA8a6/xOixdDpdERe+m/Cz/9HjYkCDoeT7z5bR0F+OZdc14vg0PoH+zsqKtAZDNjHX8w3haFcMjKF4DAY23aYLFgrzohVq1YxatQoDhw4gF6vl4AmRCt3vMedcaqqnqcoihewFrgZ13ZQL7tnewrRIpRuX4FnrILRLxiduebemRtWHWRv+hEuuKwrbZJC6r1G9sLfOfjNTDo9+zSpbcJ59Z/DSIz2R6M9aPWeJkSDrVq1imnTphEdHY2HhzyoEEIcvyetFEBVVQsQDFylqurzEtBES2LN2U/Oj6+Rv+TrOo/36BvPFTf1oWvvuHqvkb9mLbvefo8S72A259jJLMlhhvoxueX56HV6WaxWnLbqAU3GoAkhqjRkdidAjqqqCxq1JkKcYZrDTs7sNzF4+RAy4qoax/btOkJQiA8BQV6kpIbXcwUo2ZmO+uJ/cYRH85ahJ3037ePwgfmUVpbh1JyN3QTRCmzYsEECmhCiTsfrAqj+EEd6z0SLU7j8e6zZewkdewsGb/+jr+dkFvPNJ2v45btNxz3fkpnJtqefxeHtyzte/enUIYqKqNXklOVx36BbiPQNa+wmiFYgMTGRsWPHSkATQtRyvJ60LoqiFLu/9q72tQ7QVFX1r+c8IZpcZdZeCv78Dt+Og/FJ7Xv09bKSSr75ZDVms4FJU7sc9xomP3+cbVL4uLQN8ckxxHTbz8I9O7it91W0D2vb2E0Q57gtW7aQnJxMQEAAb775ZlNXRwjRDB2vJy0Z6Oz+r/rXndz/F6LZMgaE4t9jNCGjbzj6mt3uYOb0NZQWV3Lp9b3xD/Sq81xHRQVOqxWjrw9be1+AX1wM91/bnV35e5mojGR40oCz1QxxjkpLS+PCCy/kySefbOqqCCGaMd2xm0u3BO413PYCiaqq7jtB8ZbXQHFaNE2rtR8nwOJ5Kst+S+eiq3rQsVt03ec6HGx/7gUclgo6PfU46PVYKu14e5qotFsx6Y0yUUCcFtlJQIhW6fgLcNZDftuIc4o1Zz8Znz2MLT+z1rEBw5K56MrjBDRNY8+Hn1Cwei3LHREcOlJOVmkun2z8kgpbBR5GswQ0cVokoAkhTob8xhHnDM3pIOfnt7HlZ6L3/HtR2oN787FW2vHwNNKxe90BDSDjx9lkzZ3HjrgeLNS1obC8lBeWvcP6jC0UV5aejSaIc5jNZuOee+6RgCaEaLCGLsEhRLNXtHI21qzdhE/519HZnJmHivjigzQ6dY9m0iVd6z33yF8r2Df9M7KiFWZ7duLhq3ow+8AsssuO8OjQuwn3DT1bzRDnKJPJxPTp0wkMDJSAJoRokBOGNEVRIoGPgbbAYOAz4FpVVWs/TxKiiViPHKLgj2/xSe2Hb3vXwP6S4gq+/WQ1Xt4mho9Vjnu+V3wc+Qmd+Fzfldsu6so+5zo2Zm3nll7T6BAuMznFqUtLS2P58uXcc889KMrxP4dCCFFdQx53vgP8CFhwbba+Afio8aokxMkrXPEDOrMHIWNuAsBmc/DtJ6uxWGxcdkMffP096zzPVlyCpmkYIiL5s+1IpoxKZUivCBbuXsaQhL6MSB50NpshzjFVY9B+/PFHysrKmro6QogW5oSzOxVFWaeqag9FUdarqtrd/dpmVVWbbBkOmd0pjqXZbViPHMQjMgmAX2ZtYl3aAS69thdKp8g6z7EVF7Pp/ocI7tuXxOuuxmZ3YDTo0el0FFiK8DR64GWqO9wJcSIySUAIUU2jze50KopytJyiKH4NPE+IRmcvycdZaUFnNB0NaAADz0vm/Eu61hvQnFYr2595norcI3yf7U1puRWjQc+Kg2txOp0EeQVIQBOnTAKaEOJMaEjY+h74EghQFOUWYBEws1FrJUQDaJpGzuw3yPjs32jufTQL8srQNI2gEB+69al703TN6WTna29SskPl16jB7DEEg07H3PTFvLbiY9IOrz+bzRDnoKysLOLi4iSgCSFOywlDmqqqzwK/AquBUcAHwFONXC8hTqh002Iq9m3Gv+c4dDo9BXnlfPTan/w+Z8dxzzvw5dfk/bWctJi+HApry+M39iPHkskXG3+gZ3Rn+sX2OEstEOeakpISAC644ALmz58vAU0IcVoaMrvzFuArVVU/Pwv1EaJB7KUF5C2cgWdce/y6j8RmdW35pGnQo1/8cc81J6ewI7YbK/3b8/yN/fDz1fPMgo/x9/Dl9j5X17lbgRAnkpaWxvXXX88777zD0KFDMZlMTV0lIUQL15DHncOBPYqifKwoSr/GrpAQDZG34BOctgpCJ9wG6Ph55kayM4u5cFp3gkN96jzH7p5dp7XtyMqYfjx4TV+SYgL4dN1Msspyuavf9fh5+J7FVohzRdUYtNDQUFJTU5u6OkKIc0RDHndeBrQD1gJvKIqyRVGUuxu9ZkLUw2mrxGEpIWjQVMwhMaT9sZct6zMYPlahbfvwOs+xHM5g7S13kLNkKdFhvrxz/wh6pLrKjkgeyHXdL5H10MQpkUkCQojG0qBZmqqqFuAai/YcUAo82JiVEuJ49CYPoq54nMABFwIQEe1Pj37xDBqRUmd5e2kp2/7zHJU2Bz/tB4dTw2TUY7VbAVBCkxnbdtjZqr44h+zZs0cCmhCi0ZwwpCmK0l1RlDeBQ8BNwItA3dPmhGhkxesXYi/Oc40b07k+voltQ5k4tUudY8k0h4MdL/4XS1Y2X4cMpszDD70OKu1WHlr4Av/b+uvZboI4hyQmJnLXXXdJQBNCNIqG7N35E/AJ0EdV1QONXB8h6lVxcAdHfn2PgL6TCB5xNT98uZ7QCF+GjGpX7zl7P55O0cZNzIsYQGjXTtw5tRs6nY5P133LoaJM2nZLPIstEOeK1atXExISQlJSEv/4xz+aujpCiHNUQ0JaG1VVZdV+0aSc1gpyf3kbo38IQYMvYePqQ2xZn8F54+sfpK1pGqVmH9aGdKKoXQ9euKY3RoOeZftWsWjvci5sP5Yuke3PYivEuaBqDFqPHj349ttvm7o6QohzWL0hTVGUP1VVHQQUK4pSPaTpAE1VVf9Gr50QbnkLPsGWn0nUtMcpKHYw94cttEkOYcDw5DrLaw4HOoMBa9/hbMsK5Zmb+uHtaSKjJJsP1n5F+7AULuk08Sy3QrR01ScJvPHGG01dHSHEOe54PWlT3f/vVMcxWUhKnDVlO9Io2fg7gQOmYI7tyJdv/YXBoOfCK7qh19f+KNqKi9n80KMk33YzvTp1pHu7MAwG1/i1g0UZ+Jq8uavf9Rj0hrPdFNGCySxOIcTZVm9IU1U10/3le6qqjqt+TFGUlYCsmSbOCs+ETgQOmkrQoIs5sK+ArIxiLrqyB/6BXrXKappG+lvvUpaRyao9RYzqxNGABtA3tjvdo/6fvfsOa/pqGzj+DYS9EZQlIohBERVEEbe466yjw221al2vHdraWmerfap122rrbuseWOu2jjqDA0dF4x6oKIrsneT9g5ISExQHhHE+15WrzTm/cScguXNmDUyNxUKjwsuZN2+eSNAEQShSz+vu3EjO+mg+MpnsfJ4qEyCjsAMTBLVKCSoVxuZWODZ9D4BKPuUY8UVz7B0t9Z4Te+AgT+URHCwXRL3ybprynVcOYGVqSROvEJGgCa9k8eLFpKamUr68/rX4BEEQ3rTnLcHxGTAKuA+MzPMYRM4uBIJQqJ4eXs+9FeNQZaSRlprJlaiHAPkmaOkPH3F10RLumFfAtmVbWodUAuB8zCVWnN1AxL2zqNViDoxQcHK5nH79+pGamoq1tbVI0ARBKFLP6+68BdySyWRVxexOoail3blI/NHNWAc0QWJqzp+rTqO4+JCR48Kwc9Dt5gS4uXMfmVlKzgW3YfK/S23EJMcy+/gSPGxdGVGvn9iXUyiw3DForq6uJCcnY2mp/8uBIAhCYRGzO4ViR5mWxKPwuZg4VMCp9SDORtzl0vkYWrT3yzdBA7gja8AmX2MmDWmBmYkxaVnpzDj8ExIkjG00FHMT8yJ8FUJJljdB27Bhg2hBEwTBIF51dqcgFAq1WsWjrXNRpibg0m8aTxOV7Aq/iFeVcjRopn+5jdQ7d8HIiDahXoTWdMPWyhSAk/fOcS/pIV82GUEFa+eifBlCCRYREaGVoIlJAoIgGEq+Y9LyzO6MBVwVCsVtoB0wARDdn0KhUKUmkZ34BKdWH2BSvjKbf4tEKjWiS8/aSPQst6HKyuLMN99zdsIU1EqlJkEDaOIVwqy2X4sFa4WX4uDgQK1atUSCJgiCwRVkx4HlwA2ZTKYExgKrgF+ANoUZmFA2GVvZ4f7B/5D8OwOzXiMvzC1MsLXT3835z9LfkDy8z6k6bxNqlPOd48CNY7jbulDVyRs3W5cii10o2W7fvo2npye+vr5s3LjR0OEIgiC8eIN1wFuhUIwDOgIrFArFJMCxUKMSypyshEfEbv8JVWYaRlJT1Co1EomEWnUrIquhP9F6evkqCTu3c8mxKn1Gd0cikXDi7hkWnfyN7Vf2F/ErEEoyuVxOy5YtWbx4saFDEQRB0ChIkpa7qFQbYL9MJjMGrAsvJKGsUWVn8mjTTJIvHUOZHE9aaiY/zThE1Ln7+Z+TlUXkd7NINrYgYPiHONiac+HhZeadWE5VJ2+G1etbhK9AKMny7iTw9ttvGzocQRAEjYIkacdkMlkUYAEcA/b9+xCEN+LJnuVkPLhO+Y4jkTq48OeGCzyNS813PTSA63efckFdjtgmnQgJ9uZ63G1mHFmEq015Pm/8EWZS03zPFYRcYqsnQRCKs4KMSRsJhALnFQqFSiaTzQR2Fm5YQlmRdP4ASZF7sAvtgpWs3r/LbTygRXs/3Cra53uej5czfh8NokmgBwB7r/2NjZk1XzUdibWpVRFFL5RkCQkJDBgwQCRogiAUWy9M0hQKhVImk7kBA2UymQmwV6FQqAo/NKG0U2VnEndwDeaV/HFs1pMnscns3PLPc5fbUGVlEfW/H/Ds/jZt6ss05R8G9yQhPQlHC/siil4o6ezs7Jg3bx4BAQEiQRMEoVh6YXenTCb7DPgSOAecAT6WyWTjCzswofQzkpri1u8bKrz9KRIjY65depSz3Mb7+pfbADg2fzkJJ09y7/ZD0rMz+FG+iiepTzE2MsbR0r5oX4BQIsnlcnbs2AFAy5YtRYImCEKxVZDuzr5AI4VCkQggk8mWAieAbwozMKH0UquUpEQdw8q/ISZ2/63kHtLEmxpB7lhZm+k97965KNSH9nDbpRp1WzRgzoklnL5/nlDPIMpZOhRV+EIJljsGrVKlSrRu3RqptCB/AgVBEAyjIBMHyE3Q/v3/BCCr0CISSr2nf6/n0dY5pF0/C8Ddm3FE334KkG+Clp2RyYUZc0mVWtB43EjW/bOVU/fO0a92dwJdxaYYwovlnSTw+++/iwRNEIRiryB/pW7JZLL/A3789/lw4E7hhSSUZilXThJ/dCM2tcKw8AkkLTWTTb+ewcxcypDPmmKUTzfnXz+vxybpMandPuCK8grbFPtoU6Up7XybF/ErEEoiMYtTEISSqCAtaR8BbwOp/z66AcMKMyihdMqKu8+jP+Zh6uJDubYfIpFI2LHpH5KTMuj8fu18EzSAq+WrE1mvK817tWH3tb8JdPWnf2APJJL8zxGEXAcPHhQJmiAIJY5ErS7YNpwymcwSMFIoFMmFG1KBYvECbgKVFQrFrRccLvYZLQbUahX3lo4lO/Ex7gO/x8SuPJfOP2DDytM0ayujSStfveepsrJQpqZiYmdHVrYSE6kxqZlpIAFLE/1bRQlCruzsbKRSKWq1mqSkJGxtbQ0dkiAIZdMrtSjk25Imk8l8ZTLZSZlMliiTycIB6+KQoAklk0RiRLnWA6jQ9VNM7MqTlprJjs3/4OJuS8Mw/cttAByYtYRTw0aR9PghG6K2kZ6VjqWphUjQhBeSy+U0bdqUa9euIZFIRIImCEKJ87zuzoXASiAEuAbMKJKIhFInOylnUoCFpz8WXgEAmJpJCWlcmU7v1sLYWP+v4blDZzA99hePy3vz6/XdbL28h9sJ94osbqHkyh2DJpVKsbGxMXQ4giAIr+R5SVoFhUKxQKFQXAI+B+oUUUxCKZL56DZ3fxpO0rn/NjxXq9UYGxvRqEUVXNzt9J6XnJzGnZ9+It3EAqsBTTl46zhdq7VD5pR/q5sggJgkIAhC6fG8JC07938UCoUSseyG8JJUmWk83DwTI1MLLHyCAMhIz2LpvKNcV8Q+99wd0xbhmBaHVc8erLy2FVk5b7r7v1UUYQsl2Pnz50WCJghCqfG8JO3ZQW5iAL5QYGq1msc7fyYrLobyXUYjtbYHYN+fl3hwNx4z8/xXfzkZFUPC7WiSqtbmYLnbAIwM/QBjI+OiCF0owapUqULnzp1FgiYIQqnwvHXSPGQy2bz8nisUilGFF5ZQ0iWd/Yvkf/7Gocl7mnFoN68+5vTxO9Rv6o1Hpfx3CKhd1Zl7H35EWP2KBCmTeZD0kPJW5YoqdKEEOnfuHD4+PlhbWzNz5kxDhyMIgvBGvGjiwJM8j2efC8JzqLGsUgf7hl0ByMzIZtv68zg6WdK8rUzvGdlKFdd/XUP2o4c0qeeEiZkp5a3KUculelEGLpQwcrmc7t27M3682FJYEITSJd+WNIVCMbkoAxFKF9vAVtjUbqlZbPbCmXvEx6XSd1goJqb6uy13/7gO+30bSVdls8DhEnU9avFB0LtFGbZQwuSdJDBu3DhDhyMIgvBGic3rhDfqyV+rMHPxxtq/kdZuAEH1PXFxt8Pd017veZdOXsTyr3DinT2J8Ekn/n4CTb3qF1HUQkkkZnEKglDaFWiDdUEoiBRFBAkntpLx8KZWeVpqJhKJJN8ELTUplWuz5qI0lmI29C2O3ztDjxod8HGsVARRCyVRdnY2Y8aMEQmaIAilmmhJE96I7KSnxG7/EVMXbxybvqcpv3XtMWuWnqTnh/Wo5K1/8P/275filvoEBnzAkjs78S1Xmc5+rYsqdKEEkkqlrFy5EktLS5GgCYJQar0wSZPJZEbAp0ANYMS/j+//XTtNEFCrVcT+OR91Vgblu4xGYmwCgEqlZnf4RSytTHGraK/33KxsJecrBGDUyoWARtWwkcsZGdJfLLch6BUREcGePXv46quvqFy5sqHDEQRBKFQFaUmbATgDdclZO60t4AqIJTgEANJunCPtxjmc2g3BtJy7pjxSfoeHD5Lo3jcIExPdpCszPgFjM1MmD2uKSq1GamzEnHaTMDISvfCCroiICHr16oWbmxsjR47Ezk7/bhWCIAilRUE+DVsA/YF0hUKRCLQGWhVmUELJYukTiGufKdgE/vdrkZ6WxYGdCjy9HalW01XnnOysbA6O+4bIsV9xP/EB4Zd3kq1SigRN0CtvgrZ+/XqRoAmCUCYU5BMxS6FQqHKfKBSKDPJsGSWUXaqsDDIf3QFyNk/PO5vz+uVY0tKyaNNZuzzXzlkrsLp/g+SaISyMWMXOKwdIzkgustiFkuPZBE2MQRMEoawoSHfnPzKZbDhgLJPJZMAnwNlCjUooEZ7+vY7EUzup+NECpLbakwL8A93w8HLAzsFC57xzh89ie3w3T92rklrfgutRt/mkwYfYW4jWEUFXfHw8lSpV4vfffxcJmiAIZUpBWtL+DwgCKgBHAWtgdCHGJJQAGTE3SZBvw9q/sU6C9iQ2p0VMX4IW/zSZOwsWkCk1x/3/urPp0i6aeIVQv2JQkcQtlBxPnz4FoHXr1uzevVskaIIglDkvbEn7dxzawCKIRSgh1Colj3cswtjSBscWfbTqrl1+xOpfInh/UF18q+l+qK7/8xx2EhO8BvXhl2tbKW/lxMCg93SOE8o2uVxO//79mTt3Lq1bt8bYWMz2FQSh7CnIEhzz9JWLDdbLrsTTu8l4cI3ynUdjbGGjKVcpVez9IwqHcpZU9nXSe27PbnWJCvImwN+V/4vzQoIECxPzogpdKAHy7iRQq1YtQ4cjCIJgMAXp7sy7qXoS0BRQF2ZQQvGmSk/GskodrPwbaZWfPnGH2IfJtOpYDalUu+Xjwd1HKOYuwDQzDe/KZgD4OFbC29GzyOIWij+x1ZMgCMJ/CtLdqbXRukwm+w74o9AiEoo9h8bvoFartGZtpqdlcXCXgko+5ZDVcNE6Pj0jm11TF1DlURTSZvWYePU3+tTqRhvfpkUdulCM3b17VyRogiAIebz0olQKhSIJcH/hgUKpk3rzHGm3LgAgkWj/6ty7E49SqaZN5+o6S278unwfVR5GYdKgCYse7MFcakY9j9pFFbZQQnh4eDB27FiRoAmCIPyrIGPS5vNf96YEqANcKsyghOJHlZFG7LaFGFtY4T5wJpJntm3ykTnz8YQWmJmbaJUfPH0X6wN/oDa34HJDB25HX+KLxsNxEMttCP+KiIjA1tYWPz8/PvzwQ0OHIwiCUGwUpCXtMf+NSYsFfgX6PPcModSJ+3styqQ4nNoN1UnQ7tyIQ61W6yRo9x8ns2fZVjzTH2LSuRk7oo/xVtUwgtxqFGXoQjEml8vp1asXX331FWq1GOoqCIKQV0EWs/VRKBR9Cz0SodjKeHCDxJM7sA1qjbmHTKvuxpXH/Lb4BJ3fr02tYA+tOqVSjdTHF8c6dsQ1qEq1G/H0qtmlCCMXirO8kwR+/PFHvTtTCIIglGUFSdJqyWQyiUKhEF9zyyC1SsnjnYsxtrTFoXkvrTqVSs3ePy5i72iBfy3d/TkrVrBhyidtNM8bVKonPogFQMziFARBKIiCJGkPgIsymewEoNlcUayTVnZY12yOsZUdxuZWWuVnTtzh4YMkuvcNQmryXxfoyagYIo5dpvHNA9xtXR0zD3daeDcUCZqg8csvv4gETRAE4QXyTdJkMpnZv5upH//3IZRBEiNj7ILb6pSnJGWwf8dlvKqUo1rN/1rRHsenMXtNJB0eHCIp/ibhPjEEmIbQwrthUYYtFFNqtRqJRML8+fNJTk7G2dnZ0CEJgiAUW89rSTsOBD27TppQdjzevQQz1yrY1GymU/c0LhVzCxPada2haSFTqtTM/P00zon3qRR7lQuB5TAvX55Bwe+LVjQBuVzODz/8wC+//IKdnR0WFrp7uwqCIAj/ed7sTvGpWoal3jxH4qmdZMU/1FvvUcmBEeOa41zhv22h1u9VcPH6Y7qnnyfDxpyjVY35v9CBWJqID+OyLncM2sOHD8nIyDB0OIIgCCXC81rSzGUyWSD5JGsKheJM4YQkGJoqO5Mnu35B6uCCfYO3teqUShWR8rsE1quIsfS/HD85LYttR27S3TkRo+vRHAi1pUfQ21Qp51XE0QvFzbOTBMqXL2/okARBEEqE5yVp3sAm9Cdp6n/rhVIo4Xg4WXEPcHl/AkZSU626iMM32bvtEnYOFvhW++/D1trChNkfN8VKqiYl2I2eNSshK+9T1KELxczJkyfFLE5BEIRX9LwkLUqhUAQWWSRCsZCdFEf80c1YVW+IpXctrbrE+DQO7r6Cb7XyVPHLGfCtVqs5fuEBoQGuONub8yjlMS6tWiI+igWAChUqUK9ePWbNmiUSNEEQhJdUkCU4hDJEauNIhe5jMa1QWaduzx9RqFVq2r7tr5kIsPXv6yz94yJfdq2K6tc5bKyhYvC7Y6nm7FvUoQvFyLVr1/D29sbT05Pff//d0OEIgiCUSM+bOPB3kUUhFAtqZTYAllWCkNo4aNVdu/yIqHMPaNTSF4dyOeulXY+OZ+X2KOrXcMFOvgvlw8c4uHggKye6OcsyuVxOu3btmDt3rqFDEQRBKNHyTdIUCsX/ve7FZTJZT5lMFiWTya7KZLLhzzmuvUwmu/m69xNenSo7k+gln5JwapfeeitrM6rXcqVB85yhiCqVmp82ncfa0pRBde14eugIZ/2s6NviA4yMCrIlrFAa5U4ScHV1pWfPnoYORxAEoUQrtE9TmUzmDnwLNAJqA4NlMll1PcdVAGYilvwwqITjW8l6HI2pk7veelcPO7r3rYNUmrOzwL6Td1DcecqA9tW5uXIJqWYSynVpj5dDxaIMWyhG8iZoGzZsEGPQBEEQXlNhNnm0BPYrFIo4hUKRAmwEuus5bgkgFsw1oKz4R8Qf24xVtQZYeAVo1V1XxPLHunNkZmRrlZd3sCAsuCKBJk9RXrnJ5XpudK+jvVyHUHYkJyczcOBAkaAJgiC8QYU5ccCNnH0/cz0A6uU9QCaTjQLOACfyu4hMJrMH7J8p9ngjEQoAPNm3AiQSyrXsp1WelprJH2vPYm5hgpGRdkNn7arlqV21PGq1Gr8vP6deUG1MnlmuQyg7rK2tWbRoEb6+viJBEwRBeEMKM0kzImc9tVwSQJX7RCaT1QC6AS14ftI1GphYCPEJQOaT+6ReOYlD0/eR2jpp1e3c/A8pyZm8+0FdzQbqN+4lcOTcPd5pWZXY5AfEpscTFFJP36WFMkAul3P37l26d+9Oo0aNDB2OIAhCqVKY3Z3RgGue5y7A/TzPe/xbfwrYAbjJZLLDeq4zB6j8zKNxIcRbJpmWc8Nj0A/Yh3TUKr949j7/RN6nSWtf3CraAzmTBRZtPs8e+W3SHsdxdeTnbFu3kNSsNANELhha7hi0hQsXkpmZaehwBEEQSp3CbEnbB0ySyWTOQAo5rWaDcysVCsVE/m0hk8lkXsBBhUKhk3wpFIp4ID5vmUwmK6yYy5TspKdIbRwwLe+pVa5Sqvhr+2XcPO1pFFZFU37wzF0u3Ypj1Du1ubLqZ6SpGQQHtxR7c5ZBeScJrF27FlNT0dUtCILwphVaS5pCobgHfAUcAM4CqxUKRYRMJtshk8mCC+u+QsEoUxK4u2gk8fJtOnVGxkb0/ag+XXsFYmSc8yuSkpbF8j+jkHk6EGyTSvbxSC4HlKN1g85FHbpgYGIWpyAIQtEo1B0HFArFamD1M2Vv6TnuFuBVmLEI2p4e2YA6KwPLKkFa5Y8fJlOuvBX2jpZa5av3XCYhOYMJA+rxz4zxpFoY4d+7LybGJkUZtlAMREREiARNEAShCIhVR8ugrLgHJJ7Zg01gS0zL/bcu2tMnqSyZe5iDu67onNOqXiU+7BxA+aQHGN19yL3mfoT6NijKsAUDyx13NnLkSHbu3CkSNEEQhEImkrQyKO7gaiTGJjg0fkdTplap2br2LBKJhKD6njrneLna0rGxN3Y1/Kk1ewYDBk/BSCJ+fcoKuVxOo0aNuHjxIgBWVlYGjkgQBKH0E5+yZYwyJYG0G2exC+mI1Pq//Tnlh29y50YcbTr7Y+fw30SAo+fuM+PXU6SmZ/E45i57rh3C3KuSZoN1ofTLHYNmYWGBk5PTi08QBEEQ3ohCHZMmFD/GVnZUHLYQifS/sWSxD5P4a8dlqlavQK26/y1Zl56RzZI//sHW0hTlwwdc+vhTjoTYUOMjGW62LoYIXyhiuQmam5sb69evF12cgiAIRUi0pJUh2clPUavVGFvaYmT6X2tZWkoWTuWt6dAjQKuFbOP+qzyOT+PDLjW4sngRmcZqKoc2EQlaGfHPP/+IBE0QBMGARJJWRqhVSh6snsKj8Nk6dZ7ejgz+pDHWtuaaspgnKWw+eI1mQR6Uv32B9IsKTtW2p2u9rkUZtmBAVapU4Z133hEJmiAIgoGIJK2MSL5wiKzYO1j51deUPYhO4OAuBcpslc4Ys193XsLYSELvxu5c+2Up951M8O3cFTtz26IOXShikZGRPH36FHNzc7799luRoAmCIBiISNLKAFVWBnGH1mLm5ouVX2hOmVLF1rVnOSO/Q2Zmts45gzrX4PO+dZE+uAtqNfc6BNHBr2VRhy4UMblczjvvvMNXX31l6FAEQRDKPDFxoAxIPLkDZdITynf+P02L2Rn5XR49SKJHvzpYWP63pY9SmdOq5mBjTnA1c6AC9Zb9QgNLy3yuLpQWeScJTJw40dDhCIIglHmiJa2UU6vVJEcdxcInCItK/gCkp2VxcLcCT29H/AK0JwFs/fsGny84TFJcAg+PHmXjxe2kS9WGCF0oQmIWpyAIQvEjWtJKOYlEgnv/6SjTUzRlR/66RmpyJq0HVdcai5aQnMH6fQqqVS7Ho/XreLBrN3vaO+Ln5EONCn6GCF8oAiqViq+++kokaIIgCMWMSNJKMWVqEhITU4xMzJBa22vKq9dyxdLKFLeK9lrHr92jIC1TSU8/KTEzdvNPNRu8/QJFglbKGRkZsXLlSqRSqUjQBEEQihHR3VmKPdm7jHtLPkWt1J4Y4FbRngbNfbTK7j5MYsfxW7St607S6pVk2ltypKYFvWu9XZQhC0VILpfz5ZdfolQqcXd3FwmaIAhCMSOStFIqI+Ymyf8cxlIWgsQ4p8H07q2nbF17ltSUTJ3jtxy8hpmJMc2eRJJ27z47gsxoVrUJHrauRR26UARyx6AdPXqUhIQEQ4cjCIIg6CG6O0upuAO/YWRuhX1oTkuYWq1mzx8XSYhLo93burn5kK41aV2/Ek7RCtRm4OYHPWq0L+qwhSLw7CQBR0dHQ4ckCIIg6CGStFIo7eZ50m6cxbFFP4wtrAGIOvuAe7fj6fhOTUzN/vuxK1VqlEoVpkbgV8kRKoXi1DCU6oYKXihUYhanIAhCySGStFIo+dJxpLZO2Aa3BSA7S8m+7Zeo4GZLrboVtY49cOoO63ddZHDcAdzfas1u53ja+TajgrWzIUIXCllmZiY+Pj6sXLlSJGiCIAjFnEjSSiGndoNRJsVhJM1ZpPbUsdskPE2j4zu1MDL6b8mNtIxsft15idYxJ8i4f4N/0u+x44ocPycfkaSVMk+ePKFcuXI0btyYHTt2YGQkhqMKgiAUd+IvdSmiVmajTElAIpEgtS2nKfcLcKFN5+p4V3XSOn7zgWu4RUfhdf8izm93ZLXyAjXKywjxCCzq0IVCFBERQYMGDdi6dSuASNAEQRBKCPHXuhRJ/udv7iz8iMzH0Vrl9o6WhDTx1ip7mpTO37tP0u6JHNsa/hysLiUtK50BQe/obLYulFwRERH06tULFxcX6tevb+hwBEEQhJcgkrRSQq1SEn9sMyaObpiUc/+3TM2fG85z785TneP3n7yLS/IDTK2tMR/0Dn/dPEZb32ZUtHMr6tCFQpKboIlJAoIgCCWTGJNWSqREHSMr7gEVuo3RtIRdiXrImRN38PIph7ung9bxXZtXoXbVwVRyNCXdWE1Hv5Z0rdbOEKELheDBgwciQRMEQSjhRJJWCqjVKp4e3YiJsyeWsnr/lqk5uv869o6WVK+lvSBt3KUrGGdn4hNQAwBroHetrkUdtlCIXF1dmThxIq1atRIJmiAIQgklujtLgYzoK2Q9jsahUXckkpwf6Z2bcUTffkpoU2+MjP/7Md+9H8fRid/xzw9zSUlNZvrfC7ged9tQoQtvWEREBJGRkQD07t1bJGiCIAglmEjSSgHzin54DJ6Dld9/A8OP7b+OpZUptetpr4t2bM5SHDMS8Bz8IVuu7iHywUVUalVRhywUgtwxaBMmTECtVhs6HEEQBOE1ie7OEk6tzEJibIKp83/JmFqtpmJlR3xkzpiYGmvKFccicVPISfSrg1ktH7bvWEUzr1B8y1U2ROjCG5R3ksCSJUvEDF1BEIRSQCRpJZhareb+qq8x96xOuRZ9NeUSiYRGLapoHavKyuL2jz+hklrSYMwwfv0nHCOJEe8GdCzqsIU3TMziFARBKJ1Ed2cJlnY9koz7VzEp99+yGQlP0/gn8h4qpXYX5oO4NI6ZeZP+Vg8STVI5fCuCdr7NKGfp8OxlhRLm119/FQmaIAhCKSRa0kootVrN0yMbkdo6YRPQVFN+/NB1Th29jWdlR2ztLTTl7hVs6TVpCB7lbZBK1fQP7EGjSnUNEbrwhqjVaiQSCT/88ANJSUmUK1fuxScJgiAIJYZoSSuh0m//Q8Y9BfYN3kZibAJAWmomkfK7BAS5ayVol2fN5dHBQ/hWdMDCTIqJsQntqjbHxszaUOELr0kul9O5c2eePHmCqampSNAEQRBKIZGklVAJEX9ibGWPda0wTVmk/C5ZmUpCmv63BdTTcxd4cuhvjsuvoVarmXt8KcfunDJEyMIbIpfL6d27NwkJCWRnZxs6HEEQBKGQiO7OEsqp3VCy4u5hJDUFQKVUcfLoLSr5OOLiZgvkdIf988tKko0tsW3WnMgH/3D0zimqOVd53qWFYiw3QRNj0ARBEEo/0ZJWQkltHLCoVEPzPCE+HanUiJDG/y2n8fjUGYzu3uSqdz0aB1di9fmtVLB2Jsy7kSFCFl7TqVOnRIImCIJQhogkrYRRZaQRs24a6feuapU7lLNk2NhmyPxdgJxWtIs/ryJeak2Tgd05fvc0dxLu8V5AR6RGxvouLRRzHh4eNGrUSCRogiAIZYRI0kqYpAsHSb12GvhvRfnkpAwyM7KRGEmQGOUsYpqVrWKvtT+3g1pRo6oz6/75g8r2FQmtWMcwgQuvTKFQkJ2djYuLC8uXLxcJmiAIQhkhxqSVIGq1isRTOzBz88Xcvaqm/K/tl7h55TEjvwrD+N99Ok1NjBk9oQ9KlQpjI2P6B/bAytQSI4nIy0uS3DFoH3zwAePGjTN0OIIgCEIREklaCZJ28zxZT+7j3GmUpiwlKYN/ztwnMKSiJkF7cPgYGTdvUPHdHhib5SzFEexeyyAxC68u7ySBDz74wNDhCIIgCEVMNKuUIIknd+Qsu1Gtgabs9Ik7KJUq6jXKmTCgVir5Z/FyFHsOIzE25uDN46y98AfZKqWhwhZegZjFKQiCIIgkrYRQq9VYeNfCvlEPJNKcxWuV2SpOHbuFj8wZpwo5C9Oe3bQTy6Q40hu2RilRs+7CNi4+uoKx6OYsMdLS0hgyZIhI0ARBEMo40d1ZQkgkEuzqttcqu3E1luTEDDq+k9OKpszK5tHmzaRblKN1/44cuHmMJ2lP+aheHyQSiSHCFl6BhYUFS5YsoWLFiiJBEwRBKMNE80oJoMpMI+ncflRZGVrlvtUqMGh0I6rInAHYv/IPrNMSsO3QGamphC2XdiMr501ABT9DhC28JLlczqpVqwAIDg4WCZogCEIZJ5K0EiD5wiFi/1xI5sNbOnVuFe2RGElQqdQciFZys1IQTd9vy4Gbx3mS+pTuNdqLVrQSIHcM2rJly0hPTzd0OIIgCEIxILo7izm1Wk3CqZ2YufpglmfZjW3rz2FqJqVNZ38AjIwkjP+iC2kZ2RgZG1O1XGU6+bWmZoVqhgpdKKC8kwTWrVuHubm5oUMSBEEQigHRklbMpd08R9bjaGyD39K0iCUnZXDuVDRqdc6CttGPkri1dgM8fkg5u5wlN7wcKtK71tuiFa2YE7M4BUEQhPyIJK2YS5D/mbPsRvWGmrJI+R1USjXBDbxIy8hmwczN3FuzloRz58lWZrMicgMPk2MNGLVQUFFRUSJBEwRBEPQSSVoxpsrKQJmaiG2dtpplN1RKFaeP3aayrxNO5a35bdclqt89jcTahvItW3Dw1gl2XNnPg6RHBo5eeJ60tDQABgwYwK5du0SCJgiCIOgQSVoxZmRihvsH/8O+wduasitRD0lMSKduQy+u3n1KxL5T+KTeo2KXjqilxmyJ2kkVRy9quVQ3YOTC88jlcho2bMiZM2eAnCU3BEEQBOFZIkkrplQZaSjTkpFIJEiM/5vfUd7VlkYtquAjc2LB+nM0SrqEkYUFru3acujWCWJT4+juL2Z0Fle5Y9Csra1xd3c3dDiCIAhCMSaStGIq8fQu7swfQnZyvFa5o5MVYW/5kZiWhUSipopfRdw7dwRLczZf2oWPYyUCXf0NE7TwXLkJmqurKxs2bBBdnIIgCMJziSU4iiG1MpuEUzsw96iK1NpeU3424i4OTpZU8i5HOTsLfhjdDCNJMyQSCamZaQS6+hPsVlO0ohVDly9fFgmaIAiC8FJEklYMpVw+gTIpDrt2QzVlGenZ7Aq/iF+NClx9nEyguwXSuEfY1shpNbM0tWBQnfcNFbLwAj4+PvTt25fBgweLBE0QBEEoEJGkFUMJEX9i4uiKRZVATdn509FkZmTj4GXPzHVnGWZ3G9vIwwT//COXsh9hLjXDz7mKAaMW9Dl16hSenp6UL1+er7/+2tDhCIIgCCWIGJNWzGTG3iHj/lVs67ZHIsn58ajVak4evYWrhx0bjtzA1c4EhytncKxXF+Nyjvxyeg0rIzdqFrcVige5XM7777/PuHHjDB2KIAiCUAKJJK2YMXX2xOPD2djUbKYpu3X9CY8fJiN1tuT2w2T6e6ajTErCtX07/r51gtiUJ/QQe3QWK3knCUybNs3Q4QiCIAglkEjSipHcljDT8p4Ymf63dlZqUiaOzlbsjnpAUFVnLM8dw7KSJ1b+1dgctRMfh0oEutYwVNjCM8QsTkEQBOFNEGPSipGnf68lO/4Rzp1Garo6AfwD3ahQ2Z7kPy7yfv0KPDwah2fP9zh8O4JHKU/4IOhd0YpWTKjVaqZOnSoSNEEQBOG1iSStmFBnZ5F4Zg/mHn5aCdrjR8k4OlnhZG/JF33rAlBx6WIALt6RU8ulumhFK0YkEgnLly9HpVKJBE0QBEF4LSJJKyZSFHJUqYnYBrXWlGVnK1m58BhKSxN6fVAXF1sTjKRSjExy9vFs4dOIFj6NDBWykIdcLmfNmjXMmDEDZ2dnQ4cjCIIglAJiTFoxkXhmD1L78lh419KUXTofQ0pyJuceJXLtbjzRGzdzZthIstLSOHnvHCqVyoARC7lyx6BFRkaSmJho6HAEQRCEUkIkacVA5uNo0u9cxDawtVZXZ8SRm2QbS7CvYE1D//I83L0Xi4oVOfPkMjOOLOLU/fMGjFqA/xI0Nzc31q9fT7ly5QwdkiAIglBKiCStGDAyt8K+QVdsaoVpyu7fjefe7XjuKZX0bFONuGPHyEpIwLV9O8Iv7aaCtTPBbjUNGLXwbIImxqAJgiAIb5JI0ooBqbUDjs17YWxlpym7cOYeKsCqgjWhAa482L4TCw93ol3NuB53m85+rTAyEj8+QzI2NkYmk4kETRAEQSgUYuKAgaXePIc6OwvLKkFaXZ2N21TldlombwW4knL9OslXr+E9eBBLL+/F3tyWJl71DRh12RYTE4OLiwvBwcFs27ZNLH8iCIIgFArRFGNgTw+uIW7/r8B/H/RqtRpLcxMGvxdIPX8XrL0rU+2rL7BuFEJs6hPaV22BqbGJ4YIuw+RyOY0bN2bdunUAIkETBEEQCo1oSTOgjJgbZNy/SrnWH2g+7FUqNfO/P4hnNWe6dPJHIpEgMTbGsV7OGmmz205EqVYaMuwyK+8YtGbNmhk6HEEQBKGUEy1pBpR4Zi8SqSnWNZpqyhT/xJAQm8Kxf2IAiNm1h9u//k5CWiLp2RkYGRlhIlrRipyYJCAIgiAUNZGkGYgqI43ki39jVb0RxhbWmvI9uxRkoqZrx+qgVhO9eQtJiius/WcbH++YTLYy24BRl02xsbH06dNHJGiCIAhCkRJJmoFkxT3A2MJGa4eBhw8SSXiYjNLWjPoBrsSfPUfGw0dYhzXi0K0T1HELQGoseqiLmrOzM999951I0ARBEIQiJT7xDcTM1ZuKwxZCnhmdW8MvokLNWx2qIZFIiNm1BxM7O47YxaN8rKSjX0sDRlz2yOVyVCoVoaGhdO3a1dDhCIIgCGWMSNIMQJmWhJGpOZJnxpa5+DjyMDmDRkEeZDx+QtzJU5Tv3J69t44RWrEOFazFnpBFJXcMWpUqVdi+fbtYk04QBEEocuKTxwDiDq7m7o8jUKu0Z2l2ai3j6zHNkEgkqLKyKBdan3s1KpCWnU5nv9b5XE140/JOElixYoVI0ARBEASDEC1pRUyVlUHKxSNY+gYjMTIGIDtbyW8rT/NWBz/KV7AFwMLVBb+xn+IHeFepiae9uwGjLjvELE5BEAShuBBNBEUsVRGBKiNVa5/OnbsU3Il6xKETdwBIuXmL1Dt3UalVACJBK0KbNm0SCZogCIJQLIiWtCKWdO4vpHblMa/kD+TsLnD66G2yjaBzu2oA3Fr5K6l37hL+ng/BHrV4u3pbQ4ZcJqhUKoyMjJg+fToJCQk4OjoaOiRBEAShjBMtaUUoOyGWtFv/YFOruWafziPHbmGUqaRyDRdMTY1Jj4khPvIsNKjF1ae3sDe3NWzQZUBERATt2rXjwYMHGBsbiwRNEARBKBZES1oRMrZ1wrXPZEwcXDVlB/ZeJRvo0TUAgJjde8HIiIMuadgrbWlUqa6Boi0bIiIi6NWrF25ubmKCgCAIglCsiE+lIiSRSLDw9Edqk9NSk56RTbpKRYUqjtjamKHKyuLRX/uxCKzByZTrtPVtJraAKkR5EzQxBk0QBEEobkRLWhFJuxNFyqXjODR+B2NLGwDMzaR8O7kN2Uo1kDNhQJmWzmVfK8yMTWnt08SQIZdqZ86cEQmaIAiCUKyJJK2IJEXuJfXqKRzDegPwMDaZhCepVPUrj4lUAoBNVV/qLl+CZ3YCVRLvY21mZciQSzUvLy/CwsKYMmWKSNAEQRCEYkl0dxYBVXoKKZdPYO3fGCMTMwB+Wx3J2l8iuH8vAYCsxCTUajVSayvc7d1o4BlsyJBLraioKDIzM3F0dGTx4sUiQRMEQRCKLZGkFYHkqKOoszOx/ndttCdP04i/E4/U1gw3dzvUajVRk6dyaeYPzDuxnLsJ9w0ccekkl8vp3Lkz33zzjaFDEQRBEIQXEklaEUg6tx8TZ0/MXH0A2LDlAiZIaN7aF4D4M5EkX7vOPVdzjtyOID07w5Dhlkp5dxIYPny4ocMRBEEQhBcSY9IKmVqZhem/CZpEIiEtI4s7UY8wNzOmfv1KqNVq7qxdj6mzM2ut7+Nn44NvucqGDrtUEVs9CYIgCCWRSNIKmcTYBOcOwzTPT0TeQ6pWE9SgEhKJhPiz50i+chX1u214mBFJv7rvGjDa0icjI4Phw4eLBE0QBEEocUSSVsgyn9zDxNENiSRnBmfz+l5Ucrenoos1AA927sa0XDk22z/CHReC3AIMGW6pY2ZmxvLlyylfvrxI0ARBEIQSRSRphSg7KY7oRaMo12oAdvU6kJqSiYWFCd4V7TXHVP3k/0iJjqZ2ahQedi4YScQwwTdBLpcTGRnJ0KFDCQgQie+bkpCQwOPHj8nMzDR0KIIgCAZlbGyMjY0Njo6OmJmZFco9RJJWiNJunAXA3NMftVrN9BkHsVTB55NaYWQkQa1UYmxmhq2PD+/iY9hgS5G8Y9D69u2LpaWloUMqFdLT03n48CEeHh5YWFhoWocFQRDKGrVaTVZWFomJidy5cwdPT89CSdREs00hSr1xFmMre0wreHH20kOMkzKwc7bEyEhCwsUoTg8dwY1/TnHy3jlUapWhwy0Vnp0kIBK0Nyc2NhZnZ2csLS1FgiYIQpkmkUgwNTXFyckJBwcH4uLiCuU+IkkrJGqVkrSb57Hwro1EIuHPbVEYIaFzlxoARK/fiCojg+1xkcw/sZzUrDQDR1zyiVmchSs9PR1ra2tDhyEIglCs2NrakpSUVCjXFklaIcl4cANVWhKW3rW5/SCBzEcpWDhZ4l7RntToaOLPnsOuXRhHY87SwrsR1qZiC6jXdevWLdzd3UWCVkiys7ORSsUICUEQhLxMTExQKpWFcm2RpBUSU+eKVOjxBRY+tdkUfhETJLR5yw+Ax38fAYmECDclEqB91TDDBlvCpaamAvDuu++ye/dukaAVItHNKQiCoK0w/y6KJK2QGJmaY1W1LsYWNvR6pxY1w7wJqOmKWq0m9u/DWNeoxp7HkTT0rIuTlaOhwy2x5HI59evX5/jx4wCFNsNGEIqCWq02dAiCIBQjIkkrBMr0FJ4e2Uh2QiwAFcpZ0aV99ZxsW63Ga0B/TNo1xc7Mmo5+LQ0cbcmVOwbNwcEBb29vQ4cjlDB9+vRBJpPpfTRs2LBIY4mJiWHgwIE8ffoUgOjoaGQyGbt27Xrj97p48SIjRowgJCSEGjVqEBYWxtSpU3n8+PEbv9erKMzXnuvgwYP06dNHp/zy5cvIZDLat2+v97z58+cTGBiY73WDg4OZP3++VllWVharVq2iW7duBAUFUb9+ffr27cuhQ4de70U8R2ZmJtOmTaNhw4YEBgYyatQoHj58+MLzoqKi6NevH7Vq1aJRo0ZMnTpV01MBkJKSwpQpU2jQoAGBgYEMHDiQy5cva+rT09Np06YNN27cKJTXVRaJASaFIO3WeZ4eWoOJux9zF56npr8LHTv7AyAxMqJcSF3KAfPUYWJdtFckJgkIb0JQUBCff/65TrmJiUmRxnHs2DGOHDmieV6+fHnWrVuHl5fXG73PpUuX6NmzJw0bNuTbb7/FxsaGGzdu8Msvv3D48GE2b95c6ieHJCcnM2nSJJ1kCmDLli34+vpy9epVIiMjn5uQFfReAwcO5Nq1a/Tt25fRo0eTnZ3N9u3bGTx4MOPGjaN///6vdQ99Jk6cyP79+/n888+xtLRk1qxZDB48mM2bN2NsbKz3nNu3b9O7d2+Cg4P58ccfuXv3Lj/88AOpqalMnz4dgFGjRnHmzBlGjBiBTCZj27Zt9OzZk40bN+Lt7Y25uTlDhgxh/Pjx/P7772J4xBsgkrRCkHb9LBIzS47cMSX7SSpJCekAqJVK7m3ZSmpNb7y8q2MqNTVwpCXTtWvXRIImvBG2trbUrl3b0GHoMDU1LZS4Vq1ahYeHBwsXLtR8gIaEhBAcHEyHDh3YunUrvXr1euP3LU5WrFhB5cqVdRa5ViqVbN++nQ8//JBNmzaxYcOG107Svv32WxQKBWvWrKFatWqa8ubNm2NlZcX3339PixYtqFix4mvdJ687d+4QHh7ODz/8wFtvvQWAn58fbdu25a+//qJ169Z6z1uwYAEeHh78+OOPmglCSqWSVatWkZWVhUKh4MiRI0yePJn33nsPgEaNGnH79m3mzp3L3LlzAejUqROzZ89m3759tGrV6o29rrJKNOO8YWq1mrQbZ7GoVIODh24hQUKrNlUBSLjwD7d//Z11Oxaz6ORvBo605PL29mbIkCEiQRMK3ebNm5HJZFprICUmJiKTydi8eTOQ0wXWtWtX/vzzT9q0aUNAQADdunXjzJkzWteSy+X06tWLwMBAmjRpwnfffUdGRgabN29m3LhxAISGhjJ//ny9XX4nT56kV69eBAUF0aBBA6ZMmUJKSoqmvk+fPkyfPp3Zs2fTsGFDatWqxbBhw7S6uZ48eYJardYZ++br68u4ceOQyWSashs3bjBq1Cjq16+v6RZduHCh5ly5XI5MJuPEiRP06NGDmjVr0qFDB06dOsWpU6fo0qULtWrVomfPnty+fVtzXZlMxtq1a/noo4+oVasWYWFh/Pbb8/8e3r59m2HDhhEYGEhwcDBjxozR+pl88cUXDBs2jE8//ZSgoCA+/vhjvdfJzMxk9erVmuQlryNHjhAbG0vjxo3p0KEDO3fuJDk5+blxPc+TJ0/YunUr3bt310rQcg0bNoyePXuSnp6u9/zc9ze/R+7v37NOnDgBQLNmzTRlXl5e+Pr6cvjwYb3nqFQq/vrrL7p37641g7tXr17s3r0bExMTbt26BeQkZnkFBgZqtQJLpVLatGnD0qVL9d5LeDkiSXvDsp7cIzvxMfG2vkgSMrBytMC5gg0AsYcOozIzIcpZzVtiRudLO3nyJNHR0RgZGfHZZ5+JBE14bWq1muzsbJ3Hy7p16xbz5s1jxIgRzJ8/n4yMDP7v//5Pc63z58/zwQcfYGNjw+zZsxk5ciQbNmzg22+/pVmzZnz00UcALFmyhB49euhc/9ChQ/Tt2xdnZ2fN+du3b2fIkCGoVP8thL1p0ybOnTvHtGnTmDRpEnK5XNNVBdCkSROuX79O79692bRpE9HR0Zq6/v37ExwcDOSMPerbty/x8fH873//Y/HixYSEhDBv3jwOHDigFduYMWPo3r07CxYsQKVSMXr0aL788kv69+/PtGnTuH79OlOmTNE6Z+bMmVhaWjJ//nxatWrF1KlTWb9+vd739vHjx/Ts2ZP79+/z/fffM3nyZM6ePcvAgQO1tic7dOgQGRkZLFy4kHfffVfvtY4fP05cXJzeFp7w8HD8/f3x9vamU6dOpKens2PHDr3XKYjjx4+jVCpp2rSp3voKFSowfvx4fH199db7+/uzbt26fB95k7C8bt68iZOTk85C3h4eHppE61n37t0jJSUFJycnxowZQ2BgIHXq1GHKlCma99jFxQWABw8e6JybnJxMfHy8pqx169ZERkbqHCu8PNHd+YZlPr6LxNiEnVetsCCLRk1zBrQrMzJ4fPw41zxMCfSsRZVyXoYNtITJHYNWv359fv31V0OHI+Qx7scjOmWNarnTvmFl0jOzmbzkhE59i2BPWtbzJCE5g+9WndSpfyu0Mo0D3Yl9msasNad16t9uWoV6/i5EP0rCo7zNK8d+6NAh/P39dcqPHz+Oo2PBZ12npKSwYsUKatasCeR0Ew0bNozLly9To0YNFi9erOlmzB0TlJGRwZYtW7Czs8PT0xPI+WB2dHTUSp4A5s6dS82aNZkzZ46mzMPDg0GDBnHw4EHCwnK+9BkbG7N48WLNLOfLly9rJT+9evUiJiaGFStWcPp0zvvq7u5OixYtGDRokOaLz82bN/H09GTOnDma9yE0NJR9+/Zx8uRJzf0gpwUvNym6f/8+EydO5H//+x9dunQB4OrVqzotZd7e3vzwww9ATuL44MEDFi1axDvvvKPz3q5cuZKMjAyWLVumiaVmzZq0adOGHTt2aO6TnZ3NlClTnvtzO3HiBG5ubtjb22uVJycns3//fj799FMgJyEJCQlhw4YNemMqiJiYGADc3Nxe6Xxra+tX6vJOSUnBykp33U0rKytNTM/KbZWcNm0ajRs35scff0ShUDBnzhyUSiWTJ0+mZs2aeHl5MXnyZKZPn06lSpXYsWOHZgJEWlqa5n2tXr06kPN3O/fnI7wa0ZL2hln7hVLp05W4eLpj52ZL7WAPAJ6ePoMqLZ2Lnia8U6OjgaMsWfJOEpg5c6ahwxFKkTp16rBx40adh62t7UtdRyqVUqNGDc3z3FaHtLScnUQiIyNp0qSJ1qDt3Nas/AZy50pJSSEqKoq2bdtqlTdu3Bg7OztOnvwvyZXJZFrL0Li4uGhigJz1nD777DP+/vtvpk2bRocOHcjIyGDVqlW89dZbXLhwAYAaNWqwevVqbGxsuHbtGvv27WPBggVkZ2drtV4BmsQUwMnJSXN+Lnt7e53V2J/tbmzRogX37t3Tm0TI5XJq166Nra2tpqXT1dUVHx8fzdI7AI6Oji9MrO/du4erq6tO+c6dO8nKyqJJkyYkJiaSmJhIq1atOH/+PAqFQuv9e5HcY3J/rq+6rEp+rby5j/yuq1ar9caZXznkzECFnOR5+vTphIaG0r9/f0aOHMn69euJjY3F1NSUBQsWYGRkRPfu3albty7h4eEMGjQIAHNzc831rK2tsbOz0/myIbw80ZJWCIxMzHi/Uw2tsvSYh6TbmOEeHIKXg4eBIit5xCzO4m/6sEb51pmbSp9bb2dt9tx6ZweL59a/TisagI2Njc4A8ldhamqKkdF/33lz/z+3KzIhIYFy5cq90rWTkpJQq9V6z3d0dNQaN2VhYaFVL5FI9H6YOzo60q1bN7p164ZarebAgQOMHTuW//3vf5pWr0WLFrFkyRKSkpJwd3cnMDAQqVSqcz19rTZ5P7D1KV++vE48APHx8TqzS+Pj4zl37pzeFk9nZ2fN/xfk/U1OTtYbW3h4OEqlkjZt2ujUbdiwgfHjxwM5rys3odEnKytLc/3cFrT79+9TpUoVvcfHxMRoEvpnRURE0Ldv33zvNX36dLp27apTbm1trTVWMVdqaio2Nvr/veT+DBs3bqxV3rBhQ77//nuuXbuGs7Mzvr6+/PHHHzx48IDs7GwqVqyoSdyevba5uflrjekTcogk7Q1KvXmOJwdW849zVwKDq+Hi+t+3cY+uXXDt2J6GFM7WEaWRWq1mxowZIkETDCa35SFvYpJ33aiCsra21tmAOT4+nosXLxIUFPTcc21sbJBIJDx58kSn7vHjxzpdd/mJiYmhe/fufPnll1otWRKJhLCwMLp27cq2bduAnKRlzpw5TJw4kQ4dOmg+gENDQwt0rxfJXQ8uV+5rc3R01Gmps7a2pkmTJowaNUrnOvoSxOext7fn3r17WmXR0dGcPn2a4cOHExISolW3fPlytm3bxtixYzWbaWdlZfH06VMcHBy0jo2Pjyc9PV3Tmli/fn2kUimHDx+mSZMmOrHExsYSFhbG8OHDGT58uE69v78/GzduzPe1eHjo/7Lv5eXF48ePSU9P10pIo6OjqVOnjt5zKlasiEQi0UlA8z5PS0tj9+7dhIaGarVGKhQKfH19dbaMS0xMLPDvppC/Qu3ulMlkPWUyWZRMJrsqk8l0fgtlMllnmUx2ViaTnZPJZOEymcxB33VKirTrkWQ8vMX+gzH8/rNc84c9PimO+PREjE1MMDd5/jdM4T8SiYQlS5awYcMGkaAJBpHbqvPo0SNN2alTp176OoGBgfz9999ag/x37NjBkCFDUCqVWq1wz7KysqJatWo6i7sePnyYpKSkFyZ5uZydnZFIJKxevVrv5Ijbt29rBrFHRkbi4uLC+++/r0nQLl68SFxc3BvZFeHgwYNaz//66y+8vb11Wtggp0v6xo0byGQyAgICCAgIoGrVqixYsEAzrq6gXFxcdLpUw8PDkUql9O3bl5CQEK3He++9R3x8PHv27NHEIpFI2Lt3r8619+3bh0Qi0SRCdnZ2dOrUifXr13PlyhWd4+fMmYNarc534Vxra2vN69X3eDZJzBUaGopSqWT//v2aslu3bnH16tV8k+zc8W979uzR+h09dOgQpqam1KhRA6lUyqRJk7QmU9y9e5dDhw7RvHlzreslJiaSlpamt2tZeDmF1pImk8ncgW+BOkAGcEwmkx1QKBRR/9bbAj8BdRUKxT2ZTDYFmAT8X2HFVNhSr5/larYXNhgTXL+S5lu4/OuviCGZd2b8goVI0l5ILpezdOlS5s2bJ76JCQYVEhKCmZkZ3377LR999BH379/np59+wtT05dY4HDp0KL169WLUqFG88847xMTEMGfOHHr37o21tbVmDNzevXv17nYwcuRIhg0bxujRo+natSsPHjxg1qxZmuU8CsLY2Jjx48czevRo3n//fd577z08PT1JSEhg69atHDt2TDMpJyAggLVr17JgwQLq1avH9evXNWur5bdkxMs4fPgwU6ZMISwsjIMHD7J3716tSRF5DRgwgK1btzJo0CD69u2LiYkJy5Yt4+zZs4wePfql7hsaGsrSpUu1uhm3bdtG/fr19f6tadSoEQ4ODmzYsIEOHTpQsWJFevTowdSpU4mJiaFu3bqkp6dz5swZVq5cSc+ePbXWPBszZgznz5+nV69e9OvXj6CgIJKSktiyZQsHDhxgwoQJb3zBYk9PT9q2bcvXX39NcnIytra2zJo1C5lMRsuW/+1wExUVhampqaYrdvTo0QwcOJDRo0fz7rvvEhUVxaJFixgwYIAmUe/evTuLFi3C0dERa2trZs6ciaOjo86CvJGRkUgkkjfW8lqWFWZ3Z0tgv0KhiAOQyWQbge5A7lxsE2C4QqHIbXs+D+isoiiTyewB+2eKi92gruzEJ2Q9vsu55HYA1KqbE+L96OtY3nqEbSM/kaAVQO4YNFdXV5KSkl44tkUQCpOtrS1z5sxh5syZDBkyBF9fX77//nu93VPPU7t2bZYuXcrs2bMZPnw4Tk5O9OnTh6FDhwI5yUPuNjzvvPMOH3zwgdb5uWuULVy4kGHDhmFvb0+HDh34+OOPXzjxIK82bdrw+++/a2LJHQNWt25dNmzYgJ+fHwBdu3bl5s2brF27liVLluDu7s7AgQO5fv36S7de6TNo0CAuXbrEsGHD8PT0ZPbs2ToTI3K5ubmxevVqZsyYwZgxY5BIJPj7+7N8+XK96489T0hICHZ2dhw5coTu3bsTGRnJrVu3+PDDD/UeL5VKadeuHWvWrOHOnTt4enoyefJkfHx8CA8PZ/ny5QBUqlSJsWPH6iwE7OjoyOrVq1m+fDk7d+5k6dKlmJmZ4efnx7Jlywpt+7Hp06czffp0Zs6ciUqlokGDBnz11VdavysjRozA3d1dk5jXr1+fn3/+mTlz5jB06FAcHR0ZPnw4Q4YM0Zzz2WefIZFImDFjBhkZGdSvX5+xY8fqtOodPXqU2rVr620ZFV6OpLA29JXJZOMAK4VCMf7f54OAegqFYrCeYy2Aw8B8hUKx8pm6ScDEfG5TWaFQ3HpBKEWyY3Fi5F5ity9iVXw/vH2c6fdRzjeITQsm47L3PJVnTsHNV3fgq/CfvAma6OIsfi5duvTSH4qC8CyZTMbYsWMZOHCgQe4/f/58jh07xpo1awxy/9IuMzOTJk2a8M0332i13JV2Bfj7+Ep7ZBXmmDQjtBMkCaB69iCZTGYHbAfOPZug/WsOUPmZR2M9xxmWlSOn1YFIJcYEheSseZSUmoDVsYukuDuKBO0FRIImCEJR6NevH3fu3OHcuXOGDqVU2rp1KxUrVqRFixaGDqVUKMzuzmi0kykX4H7eA2QymSuwG9gP6N3HQ6FQxAPxz5z3BsN8M2yr1qHH+CCSkjKwtMjZnPnCji3YpCgp92E3A0dX/FlZWeHv78/ixYtFgiYIQqGxtbVl8uTJzJgx44XbUQkvJz09ncWLF7N48WKxufobUpjdne7AEaAekAIcAwYrFIqIf+uNATkQrlAovnnJa3sBNykm3Z2pcbFkK1XYOmsnF8r0dG7t34t3uw7iFzYf9+7dw93dHXj+YouC4YnuTkEQBP1KXHfnvxMCvgIOAGeB1QqFIkImk+2QyWTBQCcgCOj+7zIcZ2Uy2ZLCiqcwXdy2mr/nLmDRzEOkp+WsK6NUKTE2N8fnrY4i8ciHXC6nWbNmrFixAijYat6CIAiCUFYU6mK2CoViNbD6mbLcVRRPUQq2pVKp1KjuXkCR2QJbYyPMLUxQq9VsGzuM9Nq+vNf7M0OHWCzl3UmgXbt2hg5HEARBEIqdEp8kGdrZyEuQLSVFaUNQ/ZwJA1f/3ovz1cfYqk0MHF3xJLZ6EgRBEIQXE9tCvaZLRw6hzpBhYmJEjUB31Go1t9dtINvKmIZv57/vWlkVFxdHv379RIImCIIgCC8gkrTX8DAuFfMn17iU2YTAUA/MzKU8PH0Ky3tx3G0TgJ11id7lqlA4Ojoya9Ys6tSpIxI0QRAEQXgOkaS9hgqOlvi/+xHOVx9SrX5lAC6t/pUMCyPqdutt4OiKF7lcTkpKCmFhYVqbOwuCIAiCoJ9I0l6Tn38V/Pxz9j5Tq9V4te/Azce38KlQxcCRFR+5Y9C8vLxo2rTpS21jIwiCIAhllZg48Ir+PHKDX+f9xqG1u8nKVAI5S0h4hbWi+Tv694Eri/JOEvjtt99EgiYUG3369EEmk2k9qlevTv369fnoo4+4fv16kcSxefNmZDIZcXFxRXK/Bw8eMGnSJMLCwqhRowZNmzblk08+4cKFC0Vy/1wXL15kxIgRhISEUKNGDcLCwpg6dSqPHz8u0jjyEx0djUwmY9euXYV2j4MHD9KnTx+d8suXLyOTyWjfvr3e8+bPn09gYGC+1w0ODmb+/PlaZVlZWaxatYpu3boRFBRE/fr16du3L4cOHXq9F/EcmZmZTJs2jYYNGxIYGMioUaN4+PBhvsfnvuf5PSIiIgBQKpUsX76cdu3aUbt2bd566y1+++03ctd9TU9Pp02bNty4caPQXltRES1pr0CpUrPl0HVCU5I4Hm1N6NtqUm7f4cDWlbh37EBg5fz/8ZQlYhanUNwFBQXx+eefa55nZmZy+fJlFi5cyMCBA9m9ezdmZmYGjPDNioyMZMiQITg4OPDhhx/i4+PDw4cPWbduHe+99x6TJk2iR48ehR7HpUuX6NmzJw0bNuTbb7/FxsaGGzdu8Msvv3D48GE2b96MtbV1ocdhSMnJyUyaNEknmQLYsmULvr6+XL16lcjIyOcmZAW918CBA7l27Rp9+/Zl9OjRZGdns337dgYPHsy4cePo37//a91Dn4kTJ7J//34+//xzLC0tmTVrFoMHD2bz5s16v7CXL1+edevWaZWp1Wq++OILTE1NqVmzJgA//vgjP//8M8OGDaN27dqcOnWKadOmkZaWxocffoi5uTlDhgxh/Pjx/P777yV6DU6RpL2CiIsxqJ4+IkbtSkAVKaZmUi6tWY3VyXPcCPUXSdq/du7cKRI0oViztbWldu3aWmX16tXD3Nycr7/+mhMnTtC0aVPDBPeGJScnM3LkSLy9vVm2bBmWlpaauvbt2/Pll18yadIkqlevjr9/4e41vGrVKjw8PFi4cKHmAzQkJITg4GA6dOjA1q1b6dWrV6HGYGgrVqygcuXKBAQEaJUrlUq2b9/Ohx9+yKZNm9iwYcNrJ2nffvstCoWCNWvWaK2K37x5c6ysrPj+++9p0aIFFStWfK375HXnzh3Cw8P54YcfNOOQ/fz8aNu2LX/99RetW7fWOcfU1FTn3+OKFSu4f/8+4eHhmJubo1KpWL58OQMHDuSjjz4CIDQ0lLi4OJYtW8aHH+b0ZHXq1InZs2ezb98+WrVq9cZeV1ET3Z2vYG/EbaqbZaBCSnCzaqQ9eEDSiVNc8LWgmX9zQ4dncEplTvfvhAkT2Lp1q0jQhBJHXyvO4cOH6d27N4GBgQQEBNC5c2f27NmjqZ8/fz5du3blzz//pE2bNgQEBNCtWzfOnDmjdZ3w8HDatGlDzZo1+fDDD4mPj9e51969e+nWrRu1a9emadOmzJkzh6ysLE19WFgYP//8M+PHj6dOnTqEhIQwb948kpKS+OyzzwgMDKR58+Zs3rxZc86mTZuIjY3l66+/1krQAIyMjBg/fjzm5uYsWZKz8UufPn0YOHCg1nEqlYqGDRsyd+5cALKzs5k7dy7NmjUjICCArl27cvz4cc3xcrkcmUzG2rVradSoEU2bNiU6OponT56gVqt5dltCX19fxo0bp7U/840bNxg1ahT169fXdIsuXLhQc27uPU6cOEGPHj2oWbMmHTp04NSpU5w6dYouXbpQq1Ytevbsye3btzXXzY3ro48+olatWoSFhb1wL8/bt28zbNgwAgMDCQ4OZsyYMVrd1F988QXDhg3j008/JSgoiI8/1rslNZmZmaxevVrvJKojR44QGxtL48aN6dChAzt37iQ5Ofm5cT3PkydP2Lp1K927d9e7bdGwYcPo2bMn6enpes/PfX/ze+T9HcvrxIkTADRr1kxT5uXlha+vL4cPHy5Q7HFxccyfP5/+/fvj4+MDQFJSEl26dNFJ8ipXrkxcXBypqakASKVS2rRpw9KlSwt0r+JKJGkvKTkti8jLj5Bk21DeLA43P2+iN21BZQSZjWtRzrJsL7shl8tp2bIlt2/fxsjICHt7e0OHJAj5UqvVZGdnax4pKSnI5XJmz56Nm5sbwcHBAJw/f57Bgwfj6+vLjz/+yOzZs7GwsODTTz/V+pC+desW8+bNY8SIEcyfP5+MjAz+7//+j+zsbCCndfnzzz+nYcOGLFy4kIoVKzJr1iytmNatW8eIESMICAhgwYIF9O7dm2XLljFu3Dit4xYtWoRSqWTBggW0a9eOhQsX0r17d5ydnZk7dy7e3t5MmDCB+/fvA3D06FHKlSuXbyuZtbU1DRo04ODBgwB06NCBEydO8PTpU80xcrmcx48f06FDBwC+/vprli9fTt++fVm4cCHe3t58+OGHOonpjz/+yJQpU/j444/x8PCgSZMmXL9+nd69e7Np0yaio6M1x/bv31/zvqekpNC3b1/i4+P53//+x+LFizUJ6YEDB7TuMWbMGLp3786CBQtQqVSMHj2aL7/8kv79+zNt2jSuX7/OlClTtM6ZOXMmlpaWzJ8/n1atWjF16lTWr1+v9/15/PgxPXv25P79+3z//fdMnjyZs2fPMnDgQDIzMzXHHTp0iIyMDBYuXMi7776r91rHjx8nLi5ObwtPeHg4/v7+eHt706lTJ9LT09mxY4fe6xTE8ePHUSqV+bYIV6hQgfHjx+Pr66u33t/fn3Xr1uX7yJuE5XXz5k2cnJx0vhB4eHhw69atAsW+aNEipFIpQ4cO1ZTZ2dkxYcIEqlevrnXsgQMHcHFx0bpf69atiYyM5MGDBwW6X3EkujtfUna2ivb1K5Ed+Q8BPkZkxsXxaP9BLnqb0yCgbLei5R2DZm5ubuhwhCJy/9cJOmVW1RpgF9wWVVYGMWu/1am3qdkMm1phKFMTebhppk69bZ02WFdvSHbiYx5tnadTbxfSEauqdcl8cg/Tcu6vHPuhQ4d0khZzc3NCQ0MZN24cVlZWAFy9epVWrVoxceJEzXFubm68/fbbnDt3jubNc/7tp6SksGLFCs3YGaVSybBhw7h8+TI1atTg559/pnHjxkyYkPOeNW7cmPv372sSDpVKxZw5c2jfvj2TJk0CoFGjRtjY2DBx4kQGDRqEn58fkPPhOm3aNCQSCYGBgaxbt44KFSpoxth5eXnRqlUroqKicHNz4969e7i7P/+98vDwIDU1lfj4eNq2bcvUqVPZt2+fZpzazp078fPzw8fHh+vXr7N582a++eYbTX2TJk2IjY1lzpw5rFq1SnPdfv36ERYWpnneq1cvYmJiWLFiBadPnwbA3d2dFi1aMGjQIE3r+82bN/H09GTOnDk4OjoCOV1b+/bt4+TJk1rX7NOnjyYpun//PhMnTuR///sfXbp00fwMn20p8/b25ocfftDE/uDBAxYtWsQ777yj896sXLmSjIwMli1bpomlZs2atGnThh07dmjuk52dzZQpUzTH6HPixAnc3Nx0vsQmJyezf/9+Pv30UwBcXFwICQlhw4YNemMqiJiYGCDn9/VVWFtb63RBFkRKSorm309eVlZWmpieJzk5mY0bN9K3b1+918lrw4YNHDt2jPHjx2uV5yZycrlc8/MpaURL2kuytzFjULdaDP2mF6F930OVnoFRNW/iQmUEu9c0dHgGIyYJCCVRnTp12LhxIxs3bmT69OnY29vTvHlz5s2bR6VKlTTHdevWjXnz5pGamsqFCxfYtm0bv//+O4BWK4pUKqVGjRqa5y4uLgCkpaWRlpbGpUuXaNKkiVYMbdq00fz/9evXiYuLo23btlrH5LZcnTp1SlNWs2ZNzXguc3NzrKystO6dmwAkJiYCOa2GL5pdnbfezs6ORo0aaWY3KpVK9u7dq4kld6ZdkyZNtFojmzZtypkzZ7TelypVtJckkkgkfPbZZ/z9999MmzaNDh06kJGRwapVq3jrrbc0M01r1KjB6tWrsbGx4dq1a+zbt48FCxaQnZ2tdf3c9yOXk5OT5vy870dSUpLWOc92N7Zo0YJ79+7pTSLkcjm1a9fG1tZW81pdXV3x8fHR6uJ1dHR8boIGcO/ePVxdXXXKd+7cSVZWFk2aNCExMZHExERatWrF+fPnUSgUWu/fi+Qek/szfbZruaCebW1+9pHfddVqtd448yt/1vbt20lPT6d37+evOfrHH38wceJE2rRpo3OstbU1dnZ2Wi21JY1oSXsJyWlZXL7xhKoettjaWWJkLMXC3Y3Qb78j1NDBGdDZs2dFglaGufWZkm+dkYnZc+uNLW2fWy+1dXpu/eu0ogHY2NhoBm4HBATg6urKgAEDMDU15fvvv9ccl5qayoQJE9i5cyeQM/4lt0Ur74eUqakpRkb/fffN/X+VSkViYiJqtRoHB+0hEbkJBUBCQgIA5cqV0zrG2toaMzMzrbFJ+loXLCws8n2t7u7uXLlyJd96yEkeLC0tNQlex44dGTt2LPHx8URFRfH06VPNshC5Y+meTTpz5e0mzS9pcXR0pFu3bnTr1g21Ws2BAwcYO3Ys//vf/zStXosWLWLJkiUkJSXh7u5OYGAgUqlUJznQ9368qEW/fPnyOvHkvrZnxyXGx8dz7tw5vd3Fzs7Omv9/9menT3Jyst7YwsPDUSqVWol7rg0bNmhaiszNzbXGKD4rKytLc/3cFrT79+/rJMu5YmJiNF8onhUREUHfvvlvcTh9+nS6du2qU25tbU1KSopOeWpqKjY2NvleL9e+ffuoV6+e1r+PZ61YsYLvvvuOsLAwZs6cqTf5Mzc3f60xfYYmkrSXcPz8fX5bf5YqSHgvLItyFbxIdrTExdMHU6mpocMzGG9vb9q2bcv48eNFgiaUaKGhoXTv3p0NGzbQtm1bTXfa1KlTOXr0KD///DN169bF1NSUa9eusW3btgJf287ODolEwpMnT7TK804cyE2Onj0mMTGRjIyM1xrj2axZM/7++28uXLigM6MQclr7jh07ppV0hYWFYWpqyv79+zl79iyBgYGaD30bGxskEglr1qxBKtX9KHFwcNA79igmJobu3bvz5ZdfarVkSSQSwsLC6Nq1q+Z9DQ8PZ86cOUycOJEOHTpoPtxDQ9/M1+K8iST89747OjrqtNRZW1vTpEkTRo0apXOdF3XHPcve3p579+5plUVHR3P69GmGDx9OSEiIVt3y5cvZtm0bY8eOxdTUFCcnJ7Kysnj69KlO0h8fH096eromualfvz5SqZTDhw/rTahjY2MJCwtj+PDhDB8+XKfe39+fjRs35vtaPDw89JZ7eXnx+PFj0tPTtRLS6Oho6tSpk+/1IKd1Wi6Xay2P86xZs2axePFiunTpwrfffqv3dxBy/u2U5LHRorvzJRw5dx8vEzUWRmmUczDjyqy5RMz/gW8O6Y6ZKQsuXLhAWloatra2zJ8/XyRoQqnwySefYGNjw3fffaf5oD579iyNGzemYcOGmJrmfCHLnaFW0G4kc3Nzateuzb59+7TK8y4mWrlyZRwcHHQWUM0dOB4UFPRqLwro0qUL7u7uTJo0SW/LwvTp0zXraeWysLAgLCyMAwcOsG/fPk1XJ+R0FavValJSUggICNA8jh8/zooVK/L90HR2dkYikbB69WrNhIq8bt++rRnEHhkZiYuLC++//74mQbt48SJxcXGv3H2XV+4kiVx//fUX3t7eOi1skPN6b9y4gUwm07zWqlWrsmDBAs24uoJycXHR6VINDw9HKpXSt29fQkJCtB7vvfce8fHxmtnEderUQSKRsHfvXp1r79u3D4lEokmE7Ozs6NSpE+vXr9fbkjpnzhzUanW+C+daW1tr/XyffTybJOYKDQ1FqVSyf/9+TdmtW7e4evXqC5NshUJBRkZGvmPhVq5cyeLFi+nbty/ffffdcxO0tLQ0vV3LJYVoSSugxJRMLlyJJVBtjJf5DZJvV0KZksIhX1PaepS9ddFyx6C9/fbbWt1CglDSOTo6MmTIEGbOnMmvv/7KwIEDCQgIYP/+/WzZsgVXV1dOnDihmdqf39IF+owcOZJBgwYxbtw43nrrLU6cOKGVtBkbGzNixAimTp2KnZ0dLVq0QKFQMH/+fNq2bUvVqlVf+XVZWVkxZ84chgwZQrdu3fjggw/w8fEhNjaWDRs2IJfLGT9+vNbYLsjp8hw2bBgSiYR27dppyqtVq0abNm0YM2YMI0aMwMfHh4iICH766ScGDRqk1e2bl7GxMePHj2f06NG8//77vPfee3h6epKQkMDWrVs5duwYv/76K5DTBb127VoWLFhAvXr1uH79umZttZd53/Nz+PBhpkyZQlhYGAcPHmTv3r3MmTNH77EDBgxg69atDBo0iL59+2JiYsKyZcs4e/Yso0ePfqn7hoaGsnTpUq1uxm3btlG/fn29rT6NGjXCwcGBDRs20KFDBypWrEiPHj2YOnUqMTEx1K1bl/T0dM6cOcPKlSvp2bOn1ppnY8aM4fz58/Tq1Yt+/foRFBREUlISW7Zs4cCBA0yYMAEvL6+Xeg0v4unpSdu2bfn6669JTk7G1taWWbNmIZPJaNmypea4qKgoTE1Ntbpir169CuR8aXnWo0ePmDlzJlWrVqV9+/acO3dOq75GjRqapC0yMhKJRPLGWl4NQSRpBXT8wgPs1aBGgm+FdGJ2/UWqdwUeO0loXKmeocMrUnknCeTOQhKE0qRfv36sWbOGn376ibfffpsvvviC9PR0pk2bBoCPjw8LFixg2rRpREZG8vbbbxfoug0bNmT+/PnMnTuXP//8k4CAAMaMGaO1NETv3r0xNzdn2bJlbNiwgfLlyzNgwACGDRv22q+rZs2ahIeHs2zZMk2SYGdnR7169Vi7dq3ebtBGjRpha2uLv7+/ztiymTNnMnfuXH7++WeePHmCu7s7n376qc76as9q06YNv//+O0uXLmX27NmaMWB169Zlw4YNmvF+Xbt25ebNm6xdu5YlS5bg7u7OwIEDuX79+ku3XukzaNAgLl26xLBhw/D09GT27Nk6kzZyubm5sXr1ambMmMGYMWOQSCT4+/uzfPlyveuPPU9ISAh2dnYcOXKE7t27ExkZya1btzQLsT5LKpXSrl071qxZw507d/D09GTy5Mn4+PgQHh7O8uXLAahUqRJjx47VWQjY0dGR1atXs3z5cnbu3MnSpUsxMzPDz8+PZcuW0bBhw5eKv6CmT5/O9OnTmTlzJiqVigYNGvDVV19pTVAZMWIE7u7umsQccrqdpVKpzvIdkLOOXGZmJleuXNG7xMnx48c1v6dHjx6ldu3aeltGSwrJm2gyLmoymcwLuAlUVigUt15w+Bt5gd+tPElKVAxO6njau9/l4f7T7Grrhl3NGnzWcMibuEWJIGZxll2XLl166Q8jQSiuZDIZY8eOfWFCWVjmz5/PsWPHWLNmjUHuX9plZmbSpEkTvvnmG62Wu8JSgL+Pr7Q3lRiTVkBj+gTTp08ALeubYWRZDiMfTxQOWTSv3MDQoRWZrKwsPv74Y5GgCYIgvKZ+/fpx584dne464c3YunUrFStWpEWLFoYO5bWI7s4CMjaSULWGF9TwAsBLqWR6QjRe9vpntpRGJiYmrFixAjs7O5GgCYIgvAZbW1smT57MjBkzXrgdlfBy0tPTWbx4MYsXLy7Rm6uD6O4skNlrzmD6OIUWNY2pXNMPM4fnL1RY2kRERHD48GE++eSTEv8LL7w60d0pCIKgX2F1d4qWtBdISM7gxKm7+GPMjYfHSVzyM6mBvlxq5MmHwT2RGj1/Be+SLiIigl69euHm5sbgwYMLtAihIAiCIAivTyRpL3DswgMckSBBjZsympTEZM5ZJPAgPrpMJWjr168XCZogCIIgFCExceAFjkRG42xkhJv5IyRp5hhZWnLCLpH6FV99UcmS4NkETYxBEwRBEISiJZK050hIzuDm9SdIVeApuUxKdDxpNSujNJZQv5QvYBsTE4Onp6dI0ARBEATBQESS9hzpmUoCqzjjYK3EOeUu6qxsIitKqGTvgYtNyV0c73kSExMB6NSpE7t27RIJmiAIgiAYiBiT9hwVHC0Z81ED1GoVaXeqkXTzAVdsYqhh62Lo0AqFXC7ngw8+YOHChTRr1gwTExNDhyQIgiAIZZZI0vKhUqm5GR1PJTdbpFJjLCtVxbJSVQYYOrBCkncnAbHMgiAIgiAYnujuzMetB4nMmHuY77/awZXZk7j3xzZuPb2LSq0ydGhvnNjqSRCgc+fOyGQyzp8/r1UeHR2NTCbTetSoUYOwsDAmT57MkydP8r3mt99+i0wmY8mSJfkes2PHDnr27ElQUBC1a9emU6dO/PLLL2RmZgJw9+5dateuTb9+/fSeHxMTQ2BgIMOHDwfgiy++wM/Pj5MnT+ocm5iYiEwmY/PmzS98Pw4ePEifPn10yi9fvoxMJqN9+/Z6z5s/fz6BgfmP2Q0ODmb+/PlaZVlZWaxatYpu3boRFBRE/fr16du3L4cOHXphnK8qMzOTadOm0bBhQwIDAxk1ahQPHz584XlRUVH069ePWrVq0ahRI6ZOnUpqaqqmPiUlhSlTptCgQQMCAwMZOHAgly9f1tSnp6fTpk0bbty4USivSyhdRJKWj0jFI2yR4GCawtOIKB4dO87ne6cTfmm3oUN7o27evCkSNKHMUygUKBQKqlSpwsaNG/Ue88knn7Bu3TrWrVvHL7/8Qr9+/di1axc9evQgNjZW5/js7Gy2b9+Or69vvtdcu3Ytn332GbVr12b27NksXLiQ1q1bs3DhQsaOHQtAxYoVGTlyJCdOnGDbtm0615gyZQomJiZMmjRJU6ZWq/n66681id7LSk5OZtKkSZoY8tqyZQu+vr5cu3aNyMjIV7r+s/fq3bs3c+fOpUmTJsydO5fp06dTvnx5Bg8ezIoVK177HvpMnDiRrVu38umnnzJ9+nQuX77M4MGDUSqV+Z5z+/ZtevfujZmZGT/++CMjRozgjz/+YOrUqZpjRo0axZYtWxg4cCDz58/HycmJnj17apIyc3NzhgwZwvjx4ymJi8kLRUytVpe4R9WqVb2qVq2qrlq1qlcBjn8lX84/rJ70yTb1+jHfqo906qre/9uP6h5rh6pvPb37qpcsllQqlXr+/PnqmJgYQ4ciFHNRUVGGDqHQfPfdd+rOnTurly9frg4MDFSnpKRo6u7evauuWrWqeufOnTrnXblyRV2zZk31mDFjdOr279+v9vPzUx87dkxdtWpV9cmTJ3WOad68uXrChAk65b/99pu6atWq6itXrqjVarU6Oztb/fbbb6sbNmyoTkxM1By3d+9eddWqVdVbtmzRlH3++efqwMBAtZ+fn3rWrFla101ISFBXrVpVvWnTpue+H/Pnz1f3799fpzw7O1vdsGFD9YoVK9QdO3ZUjxs3TueYefPmqWvXrp3vtevUqaOeN2+e5vkXX3yhrlWrlt7frwkTJqirVaumvnPnznPjfVm3b99W+/n5qbdv364pu3nzplomk6l3796d73mfffaZumPHjuqsrCxN2W+//aZu3bq1OjMzU33hwgV11apV1WvWrNE6791331WPGjVK8zwrK0vdqFEj9Z49e97gqxIMqQB/H18p3xEtaXqkZ2Rz7/ZTJIBDYjQSEyknnNJwsXbG087d0OG9EREREVy/fh2JRMKIESNEC5pQZimVSrZt20bjxo1p164daWlp7Ny5s0Dn+vr60qZNG3bs2KHV5QUQHh5OzZo1CQ0Nxdvbmw0bNuicHxcXp7c1pV27dnzyySdYWFgAYGxszNSpU4mLi2POnDkApKam8s0339C0aVO6dOmidb6bmxvvv/8+S5cu5cqVKwV6LbkyMzNZvXo1b731lk7dkSNHiI2NpXHjxnTo0IGdO3eSnJz8UtfP68mTJ2zdupXu3bvrHQs7bNgwevbsSXp6ut7z5XK5Tld03kd+3bonTpwAoFmzZpoyLy8vfH19OXz4sN5zVCoVf/31F927d0cq/W84d69evdi9ezcmJibcunULgEaNGmmdGxgYyJEjRzTPpVIpbdq0YenSpXrvJQi5RJKmxz83nmClUmMsUWIR+xjbunU4l3Cd+hWDSsXelXK5nF69ejFu3DhDhyIIBnf06FFiY2Pp2LEjFSpUIDQ0VG9ClZ/Q0FCysrK4cOGCpiwpKYkDBw7QsWNHIGe8265du0hKStI6t0mTJmzYsIHPPvuMffv2ER8fD4CjoyNDhgzBw8NDc6y/vz/9+vVjzZo1XL16lUWLFpGcnMyUKVP0xvXJJ59Qrlw5xo8fj0pV8LG0x48fJy4ujlatWunUhYeH4+/vj7e3N506dSI9PZ0dO3YU+Nr67qVUKmnatKne+goVKjB+/Hh8fX311vv7+2u6oPU98iZhed28eRMnJycsLS21yj08PDSJ1rPu3btHSkoKTk5OjBkzhsDAQOrUqcOUKVM03couLjkz/x88eKBzbnJysubnC9C6dWsiIyN1jhWEvMTsTj2qV3akQ/tqWFw+gmWaI0/83VCl3CSkFCxgm3eSwLODdwXhVUzaP0unLLRiHdr4NiUjO5Ppfy/QqW9WOZRmlUNJzEhm1tGfdepbV2lCA89gHqfGseDECp36DrKWBLvX5H5iDG6vuSTO1q1bqV69OlWrVgVyEqqxY8dy/fp1fHx8Xni+o6MjgNYEgh07dqBSqTStUZ07d2bOnDls27aNnj17ao6bOnUqmZmZbNu2jW3btiGRSKhWrRpvvfUWffr0wdzcXOteo0aNYu/evYwbNw6FQsGECRM0icGzrK2tmTBhAsOGDeO3336jb9++BXo/Tpw4gZubG/b29lrlycnJ7N+/n08//RTISUhCQkLYsGED77zzToGu/ayYmBggp+XvVVhbW1O7du2XPi8lJQUrKyudcisrK01Mz4qLiwNg2rRpNG7cmB9//BGFQsGcOXNQKpVMnjyZmjVr4uXlxeTJk5k+fTqVKlVix44dmgkQaWlpmve1evXqQM7f5GdbQgUhl2hJ08PS3IR2Yb40GzaAwIWLaNjuPcY3HYW3g6ehQ3stYhanIGhLTk7mr7/+olWrViQmJpKYmEj9+vWxsLB4qda0Z4WHhxMSEoJUKiUxMRErKysCAwN1JhDY2dmxaNEidu/ezRdffEHjxo25desWM2fOpHv37iQkJGgdb2FhweTJk7lw4QLBwcH06NHjuXG0aNGCNm3aMHv2bO7fv1+g2O/du4erq6tO+c6dO8nKyqJJkyaa96pVq1acP38ehUKhOa4gvQ25xxgb5+x/rK/LtyDUajXZ2dn5PvK7rlqt1htnfuWQMwMVwNvbm+nTpxMaGkr//v0ZOXIk69evJzY2FlNTUxYsWICRkRHdu3enbt26hIeHM2jQIACtpNva2ho7Ozuio6Nf6bULZYNoSXvGk4Q0tu+7ir+zhBq1vTCztUFqLKWmS8lfO2z+/PkiQRPeuElhn+RbZyY1fW69rZn1c+udLB2fW/+6rWi7du0iLS2NuXPnMnfuXK268PBwPvkk/3vnevToEQDly+fsQnL37l3OnDkDQN26dXWOj4qK0rSi5PLy8mLAgAEMGDCAjIwMVq5cyQ8//MDKlSsZNWqU1rENGzYEdMc95efrr7/mrbfeYtKkScycOfOFxycnJ+u04EHO+6FUKmnTpo1O3YYNGxg/fjyQk4jkJjT6ZGVlaa6f24J2//59qlSpovf4mJiYfFsLIyIinttCOH36dLp27apTbm1tTUpKik55amoqNjY2eq+V2/LWuHFjrfKGDRvy/fffc+3aNZydnfH19eWPP/7gwYMHZGdnU7FiRU3i9uy1zc3NX2tMn1D6iSTtGacuPSTy2E0eSDJJmzUZsw97cLWiGd2qv4WZ1NTQ4b2WRYsWkZqaqvkwEYSybuvWrdSsWZPPPvtMq/zatWtMmTKFv/76i4CAgOde48SJE5ibm+Pv7w/kJDPm5uYsWrQII6P/OiuUSiVDhw5lw4YNTJw4kV27djFx4kS2bdum9W/SzMyMwYMHs2PHDq5fv/7ar9HZ2ZnPPvuMCRMm8Oeff77weHt7e+7du6dVFh0dzenTpxk+fDghISFadcuXL2fbtm2MHTsWU1NTnJycyMrK4unTpzg4OGgdGx8fT3p6Ok5OTgDUr18fqVTK4cOHadKkiU4ssbGxhIWFMXz4cM06cHn5+/vnu7wJoDWmLy8vLy8eP35Menq6VkIaHR1NnTp19J5TsWJFJBKJTgKa93laWhq7d+8mNDRUqzVSoVDg6+urNeEActate7ZbWRDyEt2dzzh9+SEOEnDOvo9EreY49zl06wQmxiUzn5XL5fTp04eUlBSsra1FgiYI/7p//z4nT56kc+fOhISEaD3ee+89nJ2dn5sAANy4cYM9e/bQsWNHzUzMP/74g6ZNmxIaGqp1zQYNGtCsWTP+/PNP0tPT8fX1JT4+nt9++03nuqmpqTx69CjfAfMv65133qFu3br88MMPLzzWxcVFZ1xWeHg4UqmUvn376n2v4uPj2bNnDwB16tRBIpGwd+9enWvv27cPiUSiSYTs7Ozo1KkT69ev1zsLdc6cOajV6nwXzrW2tiYgICDfx7NJYq7Q0FCUSiX79+/XlN26dYurV68SGhqa771q167Nnj17tCZiHDp0CFNTU2rUqIFUKmXSpElakynu3r3LoUOHaN68udb1EhMTSUtL09u1LAi5SmbmUUiUShWKK4/xURvjkPoQc8+KyNNu0sK7IUaSkpfP5h2Dlt9AWUEoq8LDw5FIJLRu3VqnztjYmHbt2vHbb79pxnLdvn2bs2fPAjktJpcvX2bp0qVUqFBB0y166tQp7ty5w8cff6z3np06dWL37t3s2rWLLl260LdvXxYvXszdu3dp164djo6OREdHs3LlSiwtLenVq9cbea0SiYQpU6bQuXPnFx4bGhrK0qVLtboZt23bRv369fW2+jRq1AgHBwc2bNhAhw4dqFixIj169GDq1KnExMRQt25d0tPTOXPmDCtXrqRnz55UrFhRc/6YMWM4f/48vXr1ol+/fgQFBZGUlMSWLVs4cOAAEyZMwMvL6428D7k8PT1p27YtX3/9NcnJydja2jJr1ixkMhktW7bUHBcVFYWpqammK3b06NEMHDiQ0aNH8+677xIVFcWiRYsYMGCApiuze/fuLFq0CEdHR6ytrZk5cyaOjo70799fK4bIyEgkEkm+SaEggEjStFy9G49FRgZgim1cNOnNapKlvE59jyBDh/bSnp0kIFrQBEHbH3/8QVBQUL7/Njp27MiqVavYtGkTALNm/TeL1crKCldXV7p160b//v01LTZ//PEH5ubm+S4p0aRJE+zs7Ni4cSNdunThyy+/1HTZjR8/ntTUVJydnWnevDkjRozItyXoVXh7ezN06FDmzZv33ONCQkKws7PjyJEjdO/encjISG7dusWHH36o93ipVEq7du1Ys2YNd+7cwdPTk8mTJ+Pj40N4eDjLly8HoFKlSowdO1Yn8XR0dGT16tUsX76cnTt3snTpUszMzPDz82PZsmWaMXhv2vTp05k+fTozZ85EpVLRoEEDvvrqK81kBoARI0bg7u7Or7/+CuR0z/7888/MmTOHoUOH4ujoyPDhwxkyZIjmnM8++wyJRMKMGTPIyMigfv36jB07VudnefToUWrXri3+NgvPJXnVWTWGJJPJvICbQGWFQnHrBYcX+AXui7jDsQ3HsFZmE3J9C//0rMdp8zgWdZyuNbakuDt58iQ9e/YUkwSEN+rSpUt6FxwVSp/58+dz7Ngx1qxZY+hQSqXMzEyaNGnCN998o9VyJ5RcBfj7+EqLrJaczKMItKznyZiJnejRsQJeH/Qn27MCTbzql6gEDcDBwYHatWuLBE0QhFfSr18/7ty5w7lz5wwdSqm0detWKlasSIsWLQwdilDMiZa0UuTWrVtUqlSpVOyKIBQ/oiWtbNm3bx8rVqzQO7FBeHXp6el06NCBxYsXF2ixZKFkKKyWNDEm7V/HLzzgyJZDVDJX0zS4AqbBNXGwdTJ0WAWWOwbt448/ZtiwYYYORxCEEq5ly5aiK64QmJubs2/fPkOHIZQQJasfrxCdvvwQo+RsHsZkcG3+T3y6bRKbLr76nnRFKTdByx3ILAiCIAhCySeStH9dvRJNqtKWchmx4O1OslSJzKn4N0XnTdA2bNggxqAJgiAIQikhkjTgaWI6jon3UGOE7eOb3PGwxM7MhurOb2YhycKSkJDAgAEDRIImCIIgCKWQGJMGRN2Mw0miIp5s7NJj2WMD9TwaFftZnXZ2dsyfP58aNWqIBE0QBEEQSpninYUUEWsLEyzNjXAzeoRROVtirFWEViy+C9jK5XLNHnwtWrQQCZogCIIglEKiJQ2oVdWZWpNyVoyOf9KZ4Yk3qVZMuzpzx6Dlbmvy7Ia9giAIgiCUDmX+Ez4zS0lSYgqOjjZIJBLsy1Wgabni2TKVd5LA6tWrRYImCIIgCKVYme/uPHc1lq0zlzLzs43IZ/yPHVf2k6nMMnRYOsQsTkF4844fP87AgQOpW7cuAQEBtG3bltmzZ5OcnKw5Ri6XI5PJkMlkXLlyRe91FixYgEwm09rDEUCtVvPHH3/Qu3dvgoODCQwM5O2332bFihVkZGTovUd+j7CwMCBny6bnHTdw4MAXvu5Lly7Rvn17srK0/9bFxcVRo0YNQkJCyMzM1Dlv8+bNyGQy4uLi9F63c+fOfPHFFzrvwZYtW+jVqxf16tUjODiYd999lz/++OOFcb4qtVrNTz/9RLNmzahVqxYDBgzg+vXrLzzv7t27DBs2jMDAQOrXr8+YMWN48uSJpj47O5u5c+fStGlTatWqxXvvvYdcLte6b48ePbTKBOF1lPmmGMWVO2SobDDNSuXxg1tsjnpMmyr6N0c2pEOHDokETRDeoEOHDjF06FC6du1K7969MTc359KlSyxevBi5XM7vv/+utdm2RCJhz549VK1aVedau3fv1ilTqVSMGTOGnTt30q1bNwYNGoSJiQknT55k3rx5/Pnnn/z88884Ojri7+/PunXrNOfu2LGDlStXapWZmppq/t/c3JyVK1fqfV02NjbPfd3Z2dl89dVXjBo1ChMTE626P//8E1dXVx4+fMiePXvo0KHDc6/1ItnZ2YwcOZIjR47w3nvvMWjQIIyNjfn777/5/PPPuXDhAl999dVr3UOfhQsX8vPPP/PZZ5/h7u7OTz/9RP/+/dmxY0e+709CQoJmz+PZs2eTmJjIDz/8wOjRozUbrE+ePJnNmzczaNAg6tWrx+HDhxk4cCDLli2jXr16SCQSxowZw/jx4/njjz8wNzd/469NKFvKfJKWdO0cT7Kd8Ui+zEXvTELca2NsZPziE4tIVlYWJiYmjBkzhqFDh2Jra2vokAShVFiyZAkNGzbk22+/1ZSFhobi7e3NkCFDOHLkCE2b/veFLTAwkD179jBixAit61y/fp3r169TpUoVrfJly5axfft25s2bR+vWrTXlDRs2pG3btrz//vtMnDiR+fPnY21tTe3atTXHnD17FkCrLC8jI6N8617kzz//JCUlRSumXOHh4TRv3py7d++yYcOG107SFi1axIEDB/jll19o3LixprxJkyaUL1+eH374gTZt2hAcHPxa98krOTmZpUuXMmLECPr27QtAcHAwzZs3Z+PGjQwYMEDvecuXL0etVrN06VKsra0BsLa2ZsqUKcTGxmJkZMTGjRsZNGgQH3/8MZDzs3z06BHff/89GzduBKBevXrY2dmxdu1a+vfv/8Zel1A2lenuzvSMbMyePkSFFPv0h9xwNqJ+MZrVKZfLadasGdeuXUMikYgETRDeoLi4OPTtXdywYUM+/vhjnRbrNm3aoFAouH37tlb5rl27CAkJwdHRUVOWnZ3NkiVLaNasmd5kyM/Pjw8++IA9e/YUqBvuTVq+fDnt2rXT2eP3+vXrXLx4kcaNG9OxY0fkcjl379595ftkZWXx66+/0rx5c60ELVffvn3p1atXvksdRUdHP7dbd/78+XrPO3fuHKmpqVqbl9vZ2WlavvKzb98+2rdvr0nQAMLCwjh48CDOzs7cuXMHlUpFo0aNtM6rU6cOFy5cID4+XlP21ltvsWrVKrKzs/O9nyAURJlO0hS34sj952hhFE+Wsy3+5XW7MgwhdwyaVCp9YfeFIAgvr0mTJhw5coShQ4eyfft2YmNjATAxMWHo0KH4+flpHR8UFISzszN79uzRKt+1axdt27bVKouKiuLp06c0adIk3/vnJm+HDh16pfizs7P1PvQlnrmuXbvG5cuX9SaOW7ZswcnJidDQUMLCwrCystK0Dr2Kf/75h/j4eK3WyLzMzc2ZMGECQUH6vxiXL1+edevW5fvo0aOH3vNu3boFQMWKFbXKPTw8NHXPyszM5MaNG3h4ePDNN99Qt25datWqxaeffkpCQgIArq6uADx48EDr3OjoaADu3bunKWvdujX37t3TtIgKwqsq092dFctbcq9KVfyj43jqXI4g94Bi0dWZm6C5ubmxfv16MQZNKNYufDVBp8ypYQNc32qLMiODqCnf6tSXD2tGhRZhZCUmcvl/M3XqXdq2wblxQzJiH3NlzjydevfOHXGsV5fU6HtYeri/Utwff/wx8fHxhIeHc+DAAQC8vb1p06YNAwYMwM7OTut4iURCy5Yt2bt3Lx9++CEAN27c4Pr167Rq1UqzdiH894Ht7p5/bB4eHgDcv3//pWNPTU3F399fb90vv/ySb3Iol8sxMTHB11d7iSGVSsW2bdvo0KEDUqkUqVRK27Zt2bx5M6NGjdIam1dQMTExALi5ub30uZAzBu9VunSTk5MxNTXVGsMHYGVlpTUhJK/ExESUSiWLFy+mRo0azJ49m5iYGGbOnMmnn37KkiVLcHFxoV69esyaNQsXFxf8/f05duwYmzZtAiAtLU1zPXd3d+zt7Tlx4sQb7coVyp4ynaQ5Oljz1oB3NM+f9w20qFy4cEEkaIJQBExNTZk+fTr/93//x/79+zl27BgRERH89NNPbNq0idWrV+u0xrRp04a1a9cSExODi4sLu3btol69elpdnfDf35LnLZPzOkvomJub89tvv+mtq1y5cr7nRUdH4+TkpDNh4MSJE8TExBAWFkZiYiIALVu2ZOPGjRw6dEgzs/TZLlJ9co/JTexe5+/q87oLjYyM9HaVqtXqfOPMrzz3PlZWVixYsEDzs7G2tub//u//OH/+PDVr1mTGjBmMGTOGfv36AeDj48OwYcOYPn26ziQBNzc3rdY1QXgVZTZJy8pWcWTbLpyd3JDVrYaJuVmB/gAVNh8fH7p06cJnn30mEjShRAj4dkq+dcZmZs+tN7G1fW69mbPTc+tftRUtLxcXF3r27EnPnj3Jzs5m69atTJw4kQULFvC///1P69h69ephb2/P3r176dOnD7t37+b999/XuWZBWslyu8lcXFxeOmYjIyMCAgJe+rzk5GS9Mw7Dw8MBNAPt89qwYYMmScs999mlO3JlZWVpjsltQXvee/Dw4cN8/85FR0drjSt71ogRIxg5cqROuY2NDZmZmZpJV7lSUlLyHTpiaWkJ5EwcyZs8N2zYEACFQkHNmjVxcXHh119/5fHjxyQlJeHl5aV5755teTU3N8+35U4QCqrMJmnXbj4i9cxRNqeGEvD7L8QOasjg4J4Gi+fcuXN4e3tjY2PDjBkzDBaHIJQFZ8+eZdiwYfz000/UqlVLUy6VSunWrRv79+/XO6Df2NiYFi1asGfPHpo0acLVq1f1ju+qUaMGzs7O7Nu3L9+xU3/99RcAzZo1ezMvqgDs7e11EofU1FT27t3Lu+++S/v27bXqtm3bxpYtW3j06BHly5fHyckJgNjYWJ3kSq1W8+jRI80x1atXx9HRkcOHD+tNZDMzM+nYsSMtW7Zk2rRpOvXly5d/7pi48uXL6y2vVKkSarWa6OhorVbFZ5/nZWtri4ODg07ymftcIpGgVqvZvn071atXx9vbW/M6FQoFtra2Ol3biYmJOjN+BeFlldmJA3fOn+JJVnlMs1O5b5OIpYnh1rORy+V0796d8ePHGywGQShLvLy8SElJYdWqVTp1SqWSu3fv6ozbytW6dWtOnz7N+vXr9XZ1Qk5L15AhQzh48KDWWLVc169f5+effyYsLKxIP8hdXFx4+vSp1kK1e/bsITU1ld69exMSEqL16NevH9nZ2WzZsgWAgIAAzM3N2bt3r861T5w4QVJSkmYMlpGREb169dJ0JT9ryZIlJCQk0LFjR72xmpqaEhAQkO8jvxa4wMBAzMzM2Ldvn6YsISGBiIgIQkND831vGjZsyKFDh7TGluVO6ggMDEQikTB//nxWr16tdd0///yTpk2banW95iasuZMNBOFVldmWtMzb53mU5Y19+kNuVjKhV4VqBokj7ySBL7/80iAxCEJZY29vz8cff8z06dOJj4/n7bffxsXFhUePHrF27VoePnzIggUL9J7boEEDrKysWLly5XO/WPXu3ZuoqCjGjBmDXC6nZcuWmJmZcfr0aVasWIGnp6fWGm0vQ6VS5TtzUCKRaLUO5hUaGkp2djbnz5/XJFPh4eF4e3vrXaTX19cXPz8/Nm7cyODBgzE3N+ejjz5i7ty5pKSk0KxZM1QqFVFRUSxZsoTmzZsTEhKiOf/DDz/kxIkTDBkyhN69e9OgQQMyMzPZu3cv4eHhfPDBB89NnF6FlZUVvXv3Zu7cuRgZGeHl5cWiRYuwtrbWatW8du0amZmZVK9eHYBhw4axf/9+Bg8ezKBBg3jw4AEzZ86kffv2+Pj4APD+++/zww8/ULlyZTw9PVm4cCHp6ekMHz5cK4YbN26QmJio6S4VhFdVJpM0pUqNVdJ9UqmJe/pFHrla4udc9M3SYhanIBhO//79qVSpEr/99hvffPMNSUlJODg4aBa4fXbSQC4TExOaN2/On3/+qberM5dEImH69Ok0bdqU1atXM3bsWDIzM/Hy8uKjjz6iV69emJmZvVLs6enpvPvuu3rrjI2NiYqK0lvn7e1NlSpVOHr0KMHBwTx8+BC5XM7QoUPzvVfHjh2ZMWMGcrmc+vXrM3ToUCpUqMDatWsJDw8nKysLd3d3PvjgAwYNGqR1rpmZGUuXLuXXX3/lzz//ZP369RgZGeHj48OsWbNo167dK73+F/nkk08wMjJi2bJlpKamEhgYyHfffac1Jm3y5Mncu3eP/fv3AznjgX/99VdmzJjBqFGjsLKyolu3bnz66aeac/r27UtKSgq//PILiYmJ1K5dm1WrVul0ox45cgQXFxdq1qxZKK9PKDskxWFG48uSyWRewE2gskKhuPWCw3Ve4M0bd7mxYi5HU5rhm7qHm+/58mVT3QGohUmpVGoG44oETSgJLl26RLVqhmlxFt6czZs3M2/ePPbv35/vQrLC6+nUqRNdu3YVOw6UIQX4+/hKMxPL5L/Qyt4VqT5wNO0a2WDTtjYtfBq9+KQ3zNjYmJUrV4oETRCEItWpUyesrKzYtWuXoUMplY4dO0ZycjLvvfeeoUMRSoEy2d0J4FrJA9dKHkDRbqYul8vZs2cP48ePx8vLq0jvLQiCIJVK+e677xg7diytWrXSWTNNeHVqtZqZM2fy7bffis3VhTeizCVpKmU2B+Z+w6OMalQOciCgeSOsTC2L5N55x6CNHDkSe3v7IrmvIAhCXgEBAezcudPQYZQ6EomEzZs3GzoMoRQpc92d969dxTThKVcfW/HPn7tYefbV96Z7Gc9OEhAJmiAIgiAIz1PmkrTYWzeIySiPRK0ixime2i7VC/2eYhanIAiCIAgvq8wlaSkP7/IoswI2GY+JdpUSUMGv0O+Zu32ISNAEQRAEQSioMpekZcc94CnOWGc/xsGrMjZm1oV2r6dPnwI5GxXv2rVLJGiCIAiCIBRYmUvS0rLMQK0mzfIJtVwLr6szIiKCBg0aaKa5GxsbF9q9BEEQBEEofcrc7M52Y76kVWYWdx/VwEbPnntvQkREBL169cLNzY3AwMBCuYcgCIIgCKVbmUvSAKSmJlT2KJxtoPImaGIMmiAIgiAIr6pMJWlXTkVw9PejZJpJaPzJW1Qvr7uh8OuIjo4WCZogCMJrUKvVSCSvtIOOIJQ6ZWpMWtytazxSu5GZJOFOwv03fn13d3e++OILkaAJQgnQp08fZDKZ1qN69erUr1+fjz76iOvXrxdJHJs3b0YmkxEXF1ck98nv8ffffxfq/Qvi1KlTjBo1Sqc8OTmZH3/8kY4dOxIYGEijRo0YOnQokZGRWsf16dOHIUOGFFW4REdHI5PJtLbYmj59OsHBwQQFBXH69Gmd+jftt99+Y9y4cTrl+/btQyaTMXjwYL3nffHFF3To0EFvXWJiIjKZTGdh3oL+HN6khIQEvvjiC0JCQqhbty5fffUVycnJ+R4vl8uf+3t+7949IOfLwE8//USzZs2oVasWAwYM0Po3HxsbS4sWLQr93+WLlKmWtOSHD8gwlmFGIjInnzd23YiICKytralevToDBw58Y9cVBKFwBQUF8fnnn2ueZ2ZmcvnyZRYuXMjAgQPZvXs3ZmZmBozwzVuyZAk2NjY65T4+b+5v4qvauHEjN2/e1Cp78OABAwYMIDk5mX79+uHv709KSgrr1q2jV69ezJo1i7Zt2xok3vLly7Nu3TrNFn8KhYIVK1bQr18/WrVqRdWqVbXq37T79++zYMECtm7dqlMXHh6Or68vR44cISYmBhcXl9e6l6F+DiNHjiQ6ZNh37AAAIAZJREFUOppJkyaRnp7O999/z+PHj1m8eLHe4/39/Vm3bp1WWUZGBqNGjcLf3x9XV1cAFi5cyM8//8xnn32Gu7s7P/30E/3792fHjh3Y2Njg7OxMly5d+Pbbb/nhhx/e+OsqqDKVpKU9Tsr5r00KFW1d38g1c8eg1ahRg82bN4tmekEoQWxtbaldu7ZWWb169TA3N+frr7/mxIkTNG1atPv7FjZ/f38cC2nSVGH4/PPPSU5OZv369bi5uWnKW7RowdChQ/n6669p1KgR1taFt5xSfkxNTbV+fxISEgDo0KEDNWvWBND5/XqT5s+fT8uWLXV6buLj4zl48CAzZ85k4sSJbNq0ieHDh7/WvQzxczhx4gRyuZz169dTq1YtAFxcXOjfvz8XL17E399f5xxra2ud9/zbb79FIpEwc+ZMjIyMSE5OZunSpYwYMYK+ffsCEBwcTPPmzdm4cSMDBgwAoF+/fjRs2JCoqCiqVy/8he/1KVPdnRn/tpD+f3t3HlZlmT9+/A0CghzFZVwwJWzMWwsE3JDAXMjBzMZcGG3ErzlqfkNNK8usXNIyNVSQXCMvbFUZszHNyTH9OeaCWqljo/e4xHwDlwwjZRMUfn8855w4cFiV1c/rurjkee5nuc+5fTifc69OrevjVO/249OCgwRWr14tAZoQdYS9D5p9+/YRERFBQEAAvr6+DB48mJ07d1rTY2NjGTp0KNu2bSMsLAxfX1+GDRvGt99+a3Odzz77jLCwMDp37syECRNIS0srcq9//OMfDBs2DH9/f3r37k10dDS5ubnW9H79+rF27Vpee+01unbtSmBgIMuXL+f69etMnz6dgIAA+vbtW6F1JHNzc1m7dq31NTz++ON8/vnn1nRLE9/69evp168fwcHB1te4f/9+wsPD6dy5Mw8//DAxMTHcunXLeu758+cZP368tTlw3LhxnD59GjCa37Zs2cKZM2dQSpGYmMjJkydJTExk/PjxNoEBgKOjI8899xzh4eFcv37d7mv56aefmDlzJiEhITz44IOEhITw5ptvkpOTYz1m7969DB06FD8/P4KCgpg5c6ZNmZSUXrC5MzY2ltGjRwMQHh7O6NGj7TaHnjx5kjFjxuDn50fPnj2ZP38+WVlZ1vTRo0cza9Ysxo0bR5cuXVi0aJHd13blyhW2bdvGY489ViRt+/btODg4EBISwoABA9i8eTP5+fl2r1MWt1sOpTW1JyYm2j3v4MGDNGvWzBqgAQQGBmIymdi3b1+Z8n727Fk++ugjpk2bZv1ycvz4cTIzMwkNDbUe5+HhQY8ePWyu26hRI4KDg3nvvffKdK/KcNfUpOXl3SLX0Y0GN67SVHnd9vVkFKcQhvUrDxTZ94Bfa7oHe5Obc4uP44r+Afbr1hb/Hm3JTM8h4f2jRdK7BXnzYEBrfv0li88+KdrfpWfv36MebMnPP6XzuxYV/+aen5/PzZs3rds3btzg5MmTLFu2jNatW9OtWzcATpw4wdNPP83IkSOZNGkSGRkZxMXF8cILL7B3717rH/+kpCSWL1/OlClTaNiwIVFRUUydOpU9e/bg5OTEjh07mDFjBqNGjaJv377s2bOHpUuX2uRp48aNzJ49myeffJLnnnuOU6dOERsbS3JyMlFRUdbjVq9eTVhYGO+88w5ffvklK1asYPv27fTr14+YmBjWr1/P7Nmz6dmzp80Ha15ens1rBmMeR8uXzBkzZrB7926mTJmCUoqdO3cyffp0srOzCQ8Pt54TExPDG2+8QU5ODj4+Phw8eJAJEyYQFhbGlClT+OGHH1i2bBlpaWnMmTMHgEmTJtGqVSuWLVtGXl4eMTExTJw4kd27dxMZGcnVq1c5f/48UVFRtG/fno8++giAhx9+2G75derUiU6dOtlNy8vLY/z48Tg4ODBnzhxMJhNff/01cXFxeHl5MXr0aFJSUpg8eTIjRoxgxowZXLx4kYULF3Ljxg2WLl1aanpB4eHhNG3alHnz5vHWW29Za9IKOnv2LBEREfj7+xMdHU1qaipLliwhOTnZpvnu008/Zfjw4YwdO5ZGjRrZfX07d+7Ezc2NHj16FEn729/+Rt++fTGZTAwePJgNGzZw4MABgoOD7V6rNPv37wcqVg4Affr0KdIEWVD79vZnW/jhhx/w8rL9vHZ0dOSee+4hKSmplFwbli1bhre3N3/605+s+yzntm3b1ubYNm3asHv3bpt9YWFhzJ07l5ycHFxcXMp0zzvprgnSHB3r8eQio+9JXl7ebV/v3XfflQBNiFpu7969RZpMXF1drTUm7u7uAJw5c4b+/ftbgw2A1q1bM2TIEI4fP07fvn0ByMjIID4+3voBfevWLSIjIzl9+jQ+Pj6sXbuWXr16MXv2bAB69erFhQsX2LNnD2D8bYqOjuaxxx5j7ty5AISEhNCwYUPmzJnD+PHj6djRWMquZcuWLFiwAAcHBwICAti4cSMtW7a09rHz9vamf//+/Pvf/7YJ0ux9UL/00kuMGzcOrTXbt2/n9ddfZ+TIkdb7p6ens3TpUoYOHWo954knnmDgwIHW7ejoaPz8/Fi2bBlgfKB7eHgwc+ZMxo0bR4MGDTh//jyTJk2iV69eAHh6erJt2zYyMzPx8vKiadOmXLhwwdpcdenSJcAYlFVely9fxsPDg1dffdX6ngUFBbFv3z6OHDnC6NGjOXHiBDk5OTz99NO0aNECAHd3d2vn8tLSC2rVqpU12Lj//vtp3749ycnJNsesXLmSZs2asXbtWusHvre3N6NGjeLIkSN0797deo/XXnsNZ2fnYl+fpYN84YnSk5KSOH78uHUARZcuXbj33ntJSEiocJB2O+UA0LRp0wo1sWdkZFifwYLc3d1LHDxg8eOPP7J7927mzZuHo+NvDYfp6em4uLgUCbrsXfeBBx4gOzub48ePW8unKt01QVpeXp61kAoWVnlZhocvX76cjIwMfve7392pLApRK42JfKjYNGeXeiWmNzC5lJju0cStxPTbqUUD6Nq1q3Vk3JkzZ1i0aBFBQUEsXrzY5g/4sGHDGDZsGJmZmZw7d46kpCQOHToEYNN05uTkhI+Pj3Xb0lk7KyuLrKwsTp06xSuvvGKTh7CwMGuQdu7cOa5evVqkA/agQYOYM2cOR48etQYcnTt3ttZ+ubq64u7ubnPvxo0bA8ZIvYLi4+OLNOdaOlMfPWrUaha+/8CBA9m+fTvnzp2jQYMGgO1Ag6ysLE6cOMFzzz1nU0v38MMPk5eXR2JiIkOGDMHb25tZs2Zx4MABevfuTUhICM8//zzFsQQgFfli7enpyQcffEBeXh5JSUkkJSVx+vRpUlNTrUGrj48PLi4uhIeHM3DgQPr06UO/fv2s9y0tvbwSExMJDQ3F0dHR+j75+/tjMpk4ePCgNQjw8vIqMUADSElJsTvYY8uWLTRq1IiAgABr2f/hD38gPj6eq1evWoOlsnTPsRxzO+UAxudmwWbvwgrW5BY+z97ndXH7C0tISKBRo0YMHjy4yPnFvf7C+y2BaUpKigRplWn3uji++VcjPO5JZuKLL1So/1hiYiJRUVHExcXh4eGBm5tbJeRUCFFVGjZsiK+vLwC+vr54enoyduxYXFxcWLx4sfW4zMxMZs+ezY4dOwBo166dNVgq2NfHxcXF5sPD8nteXh7Xrl0jPz+fJk2a2OSh4Bc9S8fzZs2a2RxjMpmoX7++zbd8ezUMZfmbpJQqtlbj119/xcnJyRrgFc5jenq6NUgrmMdr166Rl5fHkiVL7I6Eu3LlCo6OjsTHxxMbG8tXX33F5s2bcXV1Zdy4cUyZMsXu32RLMHXhwoViR5+WNHIxISGB6Ohofv75Z5o3b46fnx/169e3llnbtm2Jj49n7dq1fPjhh6xbt47mzZszZ84c+vfvX2p6eaWlpbFx40a7TX9Xrlyx/l64/O1JT0/H1dXVZl9+fj6ff/45165dIygoqMg5W7du5amnngKMwL7gF4yCLP0fLde/3XLYsmWL3WlCLN5//30CAwOL7DeZTDbvi0VmZmaZBijs2rWLRx55pEiNWcOGDcnJySE3N9cmGM7IyCgy8tnyHhTX366y3TVB2vWUq9xwak12flaFA7SIiAhat27NjRs3KiGHQojqFhQUxPDhw0lISGDAgAH069cPgPnz57N//37Wrl1L9+7dcXFx4ezZszYd6kvj4eGBg4MDqampNvsLdlK3BEeFj7l27Ro3btwoEjzdaR4eHty8eZO0tDSbe/388882+SvMEjA+88wzNp2xLSxNhZ6enixYsIC8vDyOHTtGQkICK1asoH379jZNpxYPPWTUou7bt89ucHDixAnCw8NZtGgRTzzxhE3a4cOHmTVrFpGRkURERFgD0+HDh9sc17VrV9asWUNWVhYHDx4kLi7O2o+wZcuWJaaXl8lkIjQ0lCeffLJIWuHgvTSNGzcu0jR3+PBhUlJSmDNnTpH3a/HixSQkJFiDtGbNmpGammq3VsnSvNm8eXPg9soBsI6aLE67du3s7vf29i4y8CYvL4+UlBQef/zxYq8HRkB57tw5myl2LO69917y8/NJTk62uXfhbfitJrqyn73i3DWjO7OvGdW0Hu3L3zxZMEDbtGmT9Q+OEKLuef7552nYsCELFy601jQcO3aMXr16ERwcbP1WbhkFVtZRc66urvj7+7Nr1y6b/Xv37rX+3q5dO5o0aVJk8tMvvvgCMPoXVaauXbsC2L1/s2bNip3vy2Qy0bFjR3788Ud8fX2tP87OzixdupRLly5x+vRpQkJC+P7773F0dKRLly688cYbODk5ceGCMbl44Sasjh07EhgYSFxcHJcvX7ZJsww8aNCggd3A8NixYzg4OPDMM89YA7TLly/zn//8x1pmCQkJhIaGkpubi5ubG/369WPatGncunWLy5cvl5pekff3/Pnz+Pj4WN8jT09PlixZwpkzZ8p1rVatWlmDKYvPPvuMZs2aMWLECAIDA21+hg4dytmzZ60Tz3bv3p309HQOHCg68GfXrl24ublZ+2veTjmAEYAW/H9R+Ke4WrGgoCCuXLnCiRMnrPsSExNJT0+3W1NYkOUcewM4AgICqF+/vs2z+Ouvv3L48OEi17W8XkuXgKp2V9Sk5eXlkX7TDRcyaftA8SNQ7Dly5IhNgCaDBISo25o2bcrEiROJiorigw8+YNy4cfj6+rJ79262bNmCp6cnhw4dsg7Lz87OLvO1p0yZwvjx45k5cyYDBw7k0KFDNh8U9erVY/LkycyfPx8PDw9CQ0PRWhMbG8uAAQPo0OHOLmVXWMeOHQkLC2PhwoVkZGSglOKrr75i+/btzJ49u8R+QM8++yyTJk3CZDLRv39/fvnlF6Kjo3F0dKRDhw44Ozvj7u7OjBkzmDx5Mh4eHnz22Wc4ODjQp08fwJjy4NKlS+zfvx8fHx88PDyYN28eo0ePto527NSpE6mpqXz00UccP36c2NhYu5Pz+vr6kpeXx4IFCxgwYAAXL15k1apV5OTkWKe86NatG1euXGHq1Kn8+c9/Jjc3l1WrVtGmTRs6depEw4YNS0wvb6AWGRnJyJEjmTp1KsOGDSMnJ4eVK1dy8eLFcs/DFRQUxFtvvWVtssvOzmbnzp0MGjTIbp+5Rx99lAULFpCQkEBAQACBgYGEhIQwbdo0nnnmGR588EGuX7/O119/zaZNm3jhhRdsms8rWg63o2fPnvj5+TF58mReeuklbt68yaJFi+jTp49N/8tjx47RtGlTm5GgZ86coUmTJnZrKN3d3YmIiCAmJgZHR0e8vb1ZvXo1JpPJZgQzwHfffYfJZLKZBqQq3RVB2i+XL3GdJtTPS+O+lj3LdW6rVq0IDAxkyZIlEqAJcZcYM2YMn3zyCatWrWLIkCG8/PLLZGdns2DBAsDoNP/OO++wYMECvvvuO4YMGVKm6wYHBxMbG0tMTAzbtm3D19eXF198kXnz5lmPiYiIwNXVlXXr1pGQkECLFi0YO3YskZGRlfJaC4uKiiImJob4+HjS0tK47777ePvtt/njH/9Y4nmhoaGsXLmSFStW8Omnn2IymXjooYeYPn269cP+3XffZdGiRcydO5fMzEyUUqxZs8Y6KnLEiBHs2bOHiRMnsnjxYgYOHIi3tzcJCQm89957bNiwgcuXL1v7Em7YsMFuTQlgHaG7fv16Nm/eTKtWrXj00UdxcnJi/fr15OTk0K5dO1avXs3y5cuty1EFBgYSFRWFs7Nzqenl5ePjw/r164mOjubZZ5+lfv36dOnShcWLF5f786Vv377Mnz+fo0ePEhQUxK5du0hPTy921v+mTZsSHBzMjh07eOWVVzCZTKxcuZI1a9aQkJDA8uXLcXJyon379ixevLjIklEVLYfb4eDgwKpVq5g/fz6zZs3CxcWF0NDQIoNvRowYwZAhQ1i4cKF1X2pqarHTl4BRY+7o6Mi6devIzMwkICCAhQsXFgk09+/fT58+fSpU3neCw+1McFddlFLewA9AO611UimH519JSeavSzeTUz+LSfOnl2ki27Nnz3Lffffd1khQIeqSU6dOlTgXkhCiar388svcvHnTZv48ceekpqbSu3dvNm3aVGpNZxn+PlZotvu7IgJpfk8bnlkylakLXi5TgJaYmMijjz5KdHR05WdOCCGEqIDIyEj27t1r7dMn7qz333+f0NDQalsSCu6SIO3y/6WQUcbhswUHCYwaNaqScyaEEEJUjJeXF5MnT5YKhUrw008/sXXrVuvE09XlruiT9sXyj0m5dT99xzQh2L/4xZILj+KUPmhCCCFqsjFjxlR3FuqkFi1aVGialTvtrqhJy8h1w/lWFq3aehd/TEaGdfFYCdCEEEIIUd3qfE3ajcwssvDAmV+5t3Hx6465u7uzZs0afv/730uAJkQxSlpORQgh7kaVOQCzztek/XjmLNn1PHB0Trc7aCAxMZFNmzYBxqzKEqAJYZ+zs7N1fikhhBCGrKws6tevXynXrvNB2v99d4p8B0dcGhf99m/pg2aZ4FAIUbwWLVqQkpJCZmZmpX5zFEKImi4/P5/c3FyuXr1KcnJymdZbrYg639zZzLsNzU4d5IEgX5v9BQcJbNiwocgCrEIIW5aJIS9cuGBdgFkIIe5WTk5OuLq64uXlVWSx+zvlrpjMtvAOGcUphBBCiCokk9na8+Unmzn17XGbfd98840EaEIIIYSo0ep8kHbsUA5/X78fgBs3bgDGLM07duyQAE0IIYQQNVadD9Ju1DPhVD+LxMREQkJCOHnyJAANGjSo5pwJIYQQQhSvUgcOKKX+DLwGOAPRWusVhdL9gTigEfBP4H+11jfvaCYcHPg5+zIRERF4enrSvHnzO3p5IYQQQojKUGk1aUqpe4A3gRDAH3haKVV4ldIPgcla6w4Yneom3Ol8XPzpDB9s+yuenp4kJCRIE6cQQgghaoXKrEl7BNittb4KoJT6KzAcmGfevhdw01ofMh8fD7wOrCp4EaVUY6BxoWu3KWsmvvjncry87pEATQghhBC1SmUGaa2BiwW2LwI9Skm3F3xNA+ZUNBP//e8PsoaNEEIIIWqdygzSHLGdo8wByCtHukU0Ri1bQfUAdyD5djMphBBCCFETVWaQlgz0KrDdCrhQKN2zhHQAtNZpQNqdz54QQgghRM1VmVNw7AJClVLNlVINgGHA3y2JWuv/AtlKqWDzrtHAjkrMjxBCCCFErVFpQZrWOgV4FdgDHAM+1lofVkp9oZTqZj5sFLBMKXUaMAHLKys/QgghhBC1Sa1cu1MIIYQQoq6r8ysOCCGEEELURhKkCSGEEELUQBKkCSGEEELUQJW6dmd1U0o5UY7VCYQQQgghKklyedcnr9NBGvAAcLy6MyGEEEKIu54fcKI8J9T1IC3D/G8vZHWC2qINsA8ps9pGyq32kTKrfaTMaidLuWWUdmBhdT1Iu2X+N1lrnVSdGRFlo5Sy/CplVotIudU+Uma1j5RZ7VSg3G6VdJw9MnBACCGEEKIGkiBNCCGEEKIGkiBNCCGEEKIGqutBWhrwuvlfUTukIWVWG6Uh5VbbpCFlVtukIWVWG6VRwXKTtTuFEEIIIWqgul6TJoQQQghRK0mQJoQQQghRA9WZedKUUn8GXgOcgWit9YpC6f5AHNAI+Cfwv+VdnkHcWWUos8EY7fgOwA/AWK31L1WeUWFVWpkVOO4x4B2tdbuqzJ+wrwzPmgLWAE2AS8BIedaqVxnKrAtGmbkAPwIRWuu0qs6nsKWUagQcAAYVnsuuInFInahJU0rdA7wJhAD+wNNKqQcKHfYhMFlr3QHjQ39ClWZS2CitzMz/0VcBj2mtLUtpzK36nAqLMj5nKKVaAlEYz5moZmV41hyArcBC87P2HfByNWRVmJXxWYsBZpvLTAPTqzSTogilVCDwNdChmEPKHYfUiSANeATYrbW+qrXOAP4KDLckKqXuBdy01ofMu+KB8CrPpSioxDLD+PY4SWudYt4+AXhVcR6FrdLKzCIOowZU1AyllVsXIENr/Xfz9gLAbg2pqDJledbqYdTIADQAsqowf8K+CcAk4ELhhIrGIXWlubM1cLHA9kWgRynpbaogX6J4JZaZ1joV2AKglHLD+GYfW5UZFEWU9pyhlHoW+BY4hKgpSiu39sAlpdR7QABwCphSddkTdpT6rAHPAzuVUtEYa0IGVk3WRHG01uPBZhmogioUh9SVmjRHoOBcIg5AXjnSRdUrU5kopTyA7cBxrfX6KsqbsK/EMlNK+QDDgPlVnC9RstKeNSegD7BKa90FOA8srbLcCXtKe9bcgPeAR7TWnsBK4P0qzaEorwrFIXUlSEsGPAtst8K2urG0dFH1Si0TpZQnsA+jqXN81WVNFKO0Mgs3px8FvgBaK6X2VV32RDFKK7dLwBmt9VHz9icUrbURVau0MvMBsrTWh83bazACbVFzVSgOqStB2i4gVCnVXCnVAOPbvKV/BVrr/wLZSqlg867RwI6qz6YooMQyU0rVAz4HNmmtp2mtZdbl6lfaczZHa91Ba+0PDAQuaK17VU9WRQEllhvGSLTmSik/8/bjwDdVnEdhq7QyOwu0Vb+1qw0GjlRxHkU5VDQOqRNBmrlz+avAHuAY8LHW+rBS6gulVDfzYaOAZUqp04AJWF4tmRVAmcrsjxgdmocrpY6Zf+KqL8eijM+ZqGFKKzetdRYwBHhXKfU90A94odoyLMpSZr8ATwGblFIngL8AY6srv6J4txuHyLJQQgghhBA1UJ2oSRNCCCGEqGskSBNCCCGEqIEkSBNCCCGEqIEkSBNCCCGEqIEkSBNCCCGEqIHqyrJQQogaRimVD5wEbhXYfdSydEox5zwFDNdaD7oD95+LsY5eCsZM3/WAn4BIrfV/KnC91sBftdYPKaXaAVFa62EF99+BPHsD54B/FdhtwpgI8y9a6/OlnD8bY3WOv91uXoQQ1U+CNCFEZeqrtf65Gu+/UWs92bKhlJoCfAyUe143rfUFwBKI3QsoO/vvhCzzhMAAKKUcMOZTehN4spRz+wH/voN5EUJUIwnShBBVTin1F2Ai4AI0BRZqrVcVOmYo8BrG+na3gBe11v80r+caA/gCzsBX5rSbZbj1V8Bb5uu3AVYB3hjr6K3XWr+tlHICYoFgIBdjLcuxwO8wagY9gDjgHqXUl+bXYdmfBDyhtf7GfI+NwP/TWq9SSr2KMXO8o/m4SHOAVxpXjMWZL5mv2QFYATTEWGbmGDACGIcRfL6tlLqFsebtIqA3Ri3id8CzWutrZbinEKIGkD5pQojKtKfAihHHlFItlFImYAIwUGsdgBFgLLZz7tsYgUw3YBa/rU24DPhGa90VCMAInp4vLSPm4GscxizuAB8Be7TWvhgBWYRSaiQQZL6Xn/ke54HOlutorW9hrCV7TmsdVmj/OswzvyulmgCPAB8rpf4HI6jsYa4l+wIj0LPHzfxe/UspdRn4FjgNzDCnT8AIKHsC7YF2wGNa6xUY66a+qLXeArwM3AS6aq39MNYJXFja+ySEqDmkJk0IUZnsNncqpQYBjyml7gf8MfpdFbYB2KKU2g78g98CuUFAD6XUOPO2Wwn3H6GUCjH/7oKxJuUEpZQ7RmD2BwCt9a9KqXjgUWAqRs1dormmbLN5SR7vMrzedcARpdTzGE2TW83XHoSxaPlR83KL9YAGxVzD2typlAoDPgQ+11qnm9NnAP2VUi8BHTBq2ey9f4OAxuZjLa//pzK8BiFEDSE1aUKIKmVuZjyG0a/ra4wmzSK01q8CIRi1Q08B/zQn1QPCtdb+5mAmEJhs7xoYfdL8zT8PaK1Ha60vYfztcyh0rCPgrLVOA/yA6RjB2kalVGRZXpt5EeVvMQKksfxWW1YPWFQgz90wgsTSrvclsBRIUEo1Mu/+BHga+C9GreK3dl6L5Z5TC9yzBzC8LK9DCFEzSJAmhKhq3YArwBvAToyABqVUPcsBSiknpVQS0EBrvRqIBDorpeoDXwLPKaUczNtbKT5Is0trfR04hDH6E3M/t/8B/mGu9foKOKC1ngu8D3QvdImbGP3h7HkXo7bLXWu937zvS2B8gUBrHvBBGbMbBVwHXjdvhwHztNYbzduBGAFZ4Xx9CUxWSrkopRzN+XqrjPcUQtQAEqQJIaraTowpJTRwCvDCCNraWw4wDwKYhtGf61sgAWMKihvAs4A7xjQVJ8z/2uvTVppRQKhS6l/AYeBTIB7YAXwPnFRKHcUYufl6oXP/DWQrpQ5TtBZrK8ZghIJ9zuKAbcAhpdT3GH3cnipLJrXWuRhB6GSllA/wCkYz8L+ANcBefnvvtgJvKaXGAPMxBih8Z86vA/BCWe4phKgZHPLz86s7D0IIIYQQohCpSRNCCCGEqIEkSBNCCCGEqIEkSBNCCCGEqIEkSBNCCCGEqIEkSBNCCCGEqIEkSBNCCCGEqIEkSBNCCCGEqIEkSBNCCCGEqIH+P9G7zHrdPiOSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 648x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 9))\n",
    "for d in disp:\n",
    "    d.plot(ax=ax, linestyle=\"--\")\n",
    "ax.plot([0, 1], [0, 1], linestyle=\"--\", color=\"k\")\n",
    "ax.axis(\"square\")\n",
    "fig.suptitle(\"Comparison of over-sampling methods \\nwith a RandomForestClassifier\")\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([0, 1])\n",
    "sns.despine(offset=10, ax=ax)\n",
    "plt.legend(loc=\"lower right\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72edb0b6",
   "metadata": {},
   "source": [
    "- L'AUC n'étant pas la métrique la plus importante pour nous regardons le f3_score notre métrique métier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "817078ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T16:36:44.810207Z",
     "start_time": "2023-03-22T16:36:44.738694Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e0b7ee0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T16:36:45.440740Z",
     "start_time": "2023-03-22T16:36:45.369752Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),'f3_score': make_scorer(fbeta_score, beta=3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76db0be0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T16:36:47.206399Z",
     "start_time": "2023-03-22T16:36:47.134413Z"
    }
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96f73108",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T18:52:59.906389Z",
     "start_time": "2023-02-28T18:52:14.872088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean f3_score: 0.011\n",
      "Mean accuracy: 0.914\n"
     ]
    }
   ],
   "source": [
    "#Accuracy ROC AUC sans re-équilibrage\n",
    "classifier = classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "scores = cross_validate(classifier, X, y, scoring=scoring, cv=cv, return_train_score=True, n_jobs=-1)\n",
    "print('Mean f3_score: %.3f' % mean(scores['test_f3_score']))\n",
    "print('Mean accuracy: %.3f' % mean(scores['test_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4c25e44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T18:52:59.988135Z",
     "start_time": "2023-02-28T18:52:59.910510Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "pipeline = [\n",
    "    make_pipeline(FunctionSampler(), classifier),\n",
    "    make_pipeline(RandomOverSampler(random_state=42), classifier),\n",
    "    make_pipeline(ADASYN(random_state=42), classifier),\n",
    "    make_pipeline(SMOTE(random_state=42), classifier)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d41dda4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T18:53:51.989585Z",
     "start_time": "2023-02-28T18:52:59.990928Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec249577269c47bea0d692298d4a50d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FunctionSampler\n",
      "Mean f3_score: 0.011\n",
      "Std f3_score: 0.004\n",
      "Mean accuracy: 0.914 \n",
      "\n",
      "RandomOverSampler\n",
      "Mean f3_score: 0.216\n",
      "Std f3_score: 0.017\n",
      "Mean accuracy: 0.738 \n",
      "\n",
      "ADASYN\n",
      "Mean f3_score: 0.282\n",
      "Std f3_score: 0.012\n",
      "Mean accuracy: 0.659 \n",
      "\n",
      "SMOTE\n",
      "Mean f3_score: 0.269\n",
      "Std f3_score: 0.009\n",
      "Mean accuracy: 0.665 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "metric_values = {}\n",
    "for model in tqdm(pipeline):\n",
    "    \n",
    "    scores = cross_validate(model, X, y, scoring=scoring, cv=cv, n_jobs=-1)\n",
    "    \n",
    "    metric_values[f\"{model[0].__class__.__name__}\"] = {'test_f3_score': scores['test_f3_score'],\n",
    "                                                      'test_accuracy': scores['test_accuracy']}\n",
    "    \n",
    "    print(f\"{model[0].__class__.__name__}\")\n",
    "    print('Mean f3_score: %.3f' % mean(scores['test_f3_score']))\n",
    "    print('Std f3_score: %.3f' % std(scores['test_f3_score']))\n",
    "    print('Mean accuracy: %.3f' % mean(scores['test_accuracy']), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f021fdca",
   "metadata": {},
   "source": [
    "## Optimisation de SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c6f2262",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T19:08:12.665307Z",
     "start_time": "2023-02-28T18:53:51.999190Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "919003413700413f862019a7c2129184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> k=1, Mean acccuracy: 0.709, Mean f3_score: 0.241712\n",
      "> k=2, Mean acccuracy: 0.688, Mean f3_score: 0.257604\n",
      "> k=3, Mean acccuracy: 0.676, Mean f3_score: 0.262488\n",
      "> k=4, Mean acccuracy: 0.669, Mean f3_score: 0.264810\n",
      "> k=5, Mean acccuracy: 0.666, Mean f3_score: 0.272404\n",
      "> k=6, Mean acccuracy: 0.660, Mean f3_score: 0.270603\n",
      "> k=7, Mean acccuracy: 0.657, Mean f3_score: 0.276019\n",
      "> k=8, Mean acccuracy: 0.655, Mean f3_score: 0.282885\n",
      "> k=9, Mean acccuracy: 0.652, Mean f3_score: 0.282345\n",
      "> k=10, Mean acccuracy: 0.650, Mean f3_score: 0.286847\n",
      "> k=11, Mean acccuracy: 0.649, Mean f3_score: 0.289894\n",
      "> k=12, Mean acccuracy: 0.647, Mean f3_score: 0.287630\n",
      "> k=13, Mean acccuracy: 0.644, Mean f3_score: 0.289089\n",
      "> k=14, Mean acccuracy: 0.642, Mean f3_score: 0.292204\n",
      "> k=15, Mean acccuracy: 0.641, Mean f3_score: 0.291916\n",
      "> k=16, Mean acccuracy: 0.639, Mean f3_score: 0.289708\n",
      "> k=17, Mean acccuracy: 0.637, Mean f3_score: 0.294162\n",
      "> k=18, Mean acccuracy: 0.637, Mean f3_score: 0.294469\n",
      "> k=19, Mean acccuracy: 0.635, Mean f3_score: 0.295860\n",
      "> k=20, Mean acccuracy: 0.636, Mean f3_score: 0.299138\n"
     ]
    }
   ],
   "source": [
    "#SMOTE optimization\n",
    "k_values = range(1, 21)\n",
    "test_f3_score_means = []\n",
    "test_accuracy_means =[]\n",
    "\n",
    "for k in tqdm(k_values):\n",
    "    # define pipeline\n",
    "    model = KNeighborsClassifier(n_neighbors=5)\n",
    "    over = SMOTE(k_neighbors=k, random_state=1)\n",
    "    \n",
    "    steps = [('over', over), ('model', model)]\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    # evaluate pipeline\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "    scores = cross_validate(pipeline, X, y, scoring=scoring, cv=cv, n_jobs=-1)\n",
    "    \n",
    "    mean_f3_score = mean(scores['test_f3_score'])\n",
    "    mean_accuracy = mean(scores['test_accuracy'])\n",
    "    \n",
    "    test_f3_score_means.append(mean_f3_score)\n",
    "    test_accuracy_means.append(mean_accuracy)\n",
    "        \n",
    "    print('> k=%d, Mean acccuracy: %.3f, Mean f3_score: %3f' % (k, mean_accuracy, mean_f3_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44971073",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T19:08:13.539817Z",
     "start_time": "2023-02-28T19:08:12.688118Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_accuracy</th>\n",
       "      <th>mean_f3_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k_values</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.709041</td>\n",
       "      <td>0.241712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.687566</td>\n",
       "      <td>0.257604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.675902</td>\n",
       "      <td>0.262488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.668954</td>\n",
       "      <td>0.264810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.665507</td>\n",
       "      <td>0.272404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mean_accuracy  mean_f3_score\n",
       "k_values                              \n",
       "1.0            0.709041       0.241712\n",
       "2.0            0.687566       0.257604\n",
       "3.0            0.675902       0.262488\n",
       "4.0            0.668954       0.264810\n",
       "5.0            0.665507       0.272404"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([k_values, test_accuracy_means, test_f3_score_means]).T\n",
    "df = df.rename(columns={0:'k_values', 1:'mean_accuracy', 2:'mean_f3_score'})\n",
    "df.set_index('k_values', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8106d27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T19:08:13.941668Z",
     "start_time": "2023-02-28T19:08:13.542522Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "#plt.plot(k_values, Scores) #.plot(ax=ax, linestyle=\"--\")\n",
    "df.plot(ax=ax)\n",
    "ax.set_xlabel(\"Nombre de k_neighbors\")\n",
    "ax.set_ylabel(\"Mean metricks\")\n",
    "fig.suptitle(\"Mean metricks vs SMOTE(k_neighbors)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a755ef",
   "metadata": {},
   "source": [
    "-  $k_neighbors = 17$ semble convenir pour le moment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8c8f90",
   "metadata": {},
   "source": [
    "# Modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f7326d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T16:35:57.831206Z",
     "start_time": "2023-03-22T16:35:56.802143Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "172fd703",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T16:35:58.485367Z",
     "start_time": "2023-03-22T16:35:58.409460Z"
    }
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8083cbc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T16:35:59.619947Z",
     "start_time": "2023-03-22T16:35:59.546304Z"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"file://\" + PROJECT_ROOT + \"/mlruns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4e1a23",
   "metadata": {},
   "source": [
    "## Preparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "986a57d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-20T19:28:53.183272Z",
     "start_time": "2023-03-20T19:28:47.478608Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10% de la classe 0 : 28268\n",
      "10% de la classe 1 : 2482\n",
      "\n",
      "Train shape: (30750, 375), test shape: (0, 375)\n",
      "Nombre de variables normalisés : 251\n",
      "Train Dimension: \n",
      "X_train : (23062, 374) \n",
      "X_test : (7688, 374) \n",
      "y_train : (23062,) \n",
      "y_test : (7688,)\n"
     ]
    }
   ],
   "source": [
    "#Reduction des données pour optimiser les modèles et les comparer.\n",
    "nb_class_1 = int(len(data[data.TARGET == 1])*10/100)\n",
    "nb_class_0 = int(len(data[data.TARGET == 0])*10/100)\n",
    "print(f\"10% de la classe 0 : {nb_class_0}\\n10% de la classe 1 : {nb_class_1}\\n\")\n",
    "\n",
    "df = pd.concat([\n",
    "         data[data.TARGET == 0].sample(nb_class_0, random_state=42), \n",
    "         data[data.TARGET == 1].sample(nb_class_1, random_state=42),\n",
    "    ], ignore_index=True\n",
    ")\n",
    "\n",
    "# Separation des données\n",
    "train_df = df[df['TARGET'].notnull()]\n",
    "test_df = df[df['TARGET'].isnull()]\n",
    "print(\"Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "\n",
    "#imputation\n",
    "train_df.fillna(0, inplace=True)\n",
    "test_df.fillna(0, inplace=True)\n",
    "train_df.isna().sum().sum()\n",
    "\n",
    "train_df = remove_infite(train_df)\n",
    "test_df = remove_infite(test_df)\n",
    "\n",
    "#Feature à normaliser\n",
    "var_to_norm = []\n",
    "for var in train_df.columns:\n",
    "    \n",
    "    if len(train_df[var].value_counts().values.tolist()) > 2:\n",
    "        var_to_norm.append(var)\n",
    "        \n",
    "scaler = StandardScaler()\n",
    "train_df[var_to_norm] = scaler.fit_transform(train_df[var_to_norm])\n",
    "print(\"Nombre de variables normalisés : {}\".format(len(var_to_norm)))\n",
    "\n",
    "y = train_df['TARGET']\n",
    "del train_df['TARGET']\n",
    "del test_df['TARGET']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df, y, stratify=y, random_state=42)\n",
    "print(f\"Train Dimension: \\nX_train : {X_train.shape} \\nX_test : {X_test.shape} \\ny_train : {y_train.shape} \\ny_test : {y_test.shape}\")\n",
    "\n",
    "X = train_df.values\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5901f008",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T20:09:15.355826Z",
     "start_time": "2023-03-22T20:09:15.264111Z"
    }
   },
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=1001, k_neighbors=17)\n",
    "#X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0da0a965",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-20T19:28:58.046857Z",
     "start_time": "2023-03-20T19:28:57.924049Z"
    }
   },
   "outputs": [],
   "source": [
    "#y_train_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d1530c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-20T19:28:58.748901Z",
     "start_time": "2023-03-20T19:28:58.595953Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    21201\n",
       "1.0     1861\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ef9d5d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-20T19:28:59.753628Z",
     "start_time": "2023-03-20T19:28:59.641328Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    7067\n",
       "1.0     621\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7d89e81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T20:07:30.868998Z",
     "start_time": "2023-03-22T20:07:30.783299Z"
    }
   },
   "outputs": [],
   "source": [
    "proba_values = []\n",
    "def custom_metric(y_true, y_pred_proba, proba_values=proba_values, return_proba=False, in_model=False):\n",
    "    \"\"\"Cherche le seuil de probabilité qui minimise le score métier - 10FN + FP\n",
    "    et calcule le f3_score avec les labels prédits et return ce score\"\"\"\n",
    "    \n",
    "    count = 0\n",
    "    for threshold in np.arange(0.2, 0.9, 0.15):\n",
    "        label_pred_threshold = np.where(y_pred_proba >= threshold, 1, 0)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, label_pred_threshold).ravel()\n",
    "        f3_score = fbeta_score(y_true, label_pred_threshold, beta=sqrt(10))\n",
    "        acc = accuracy_score(y_true, label_pred_threshold)\n",
    "        #score = mean([acc, f3_score])\n",
    "        \n",
    "        if count >= 10*fn + fp - f3_score or count == 0:\n",
    "            count = 10*fn + fp - f3_score\n",
    "            \n",
    "            threshold_f3 = threshold\n",
    "            proba_values.append(threshold)\n",
    "            #print(count)\n",
    "        #else:\n",
    "            #print(\"not valid\", count, threshold, threshold_f3)\n",
    "    label_pred_threshold = np.where(y_pred_proba >= threshold_f3, 1, 0)\n",
    "    f3_score = fbeta_score(y_true, label_pred_threshold, beta=sqrt(10))\n",
    "    acc = accuracy_score(y_true, label_pred_threshold)\n",
    "    score = mean([acc, f3_score])\n",
    "    if not in_model:\n",
    "        print(f\"\\nPour le seuil {np.round(threshold_f3, 3)}, le f3_score est : {np.round(f3_score, 3)} et le mean score est : {np.round(score, 3)}\")\n",
    "    \n",
    "    if return_proba:\n",
    "        return score, threshold_f3\n",
    "    else:\n",
    "        return f3_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29c2747c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T20:07:31.810165Z",
     "start_time": "2023-03-22T20:07:31.739298Z"
    }
   },
   "outputs": [],
   "source": [
    "def custom_score(y_true, y_pred_proba):\n",
    "    \n",
    "    #y_pred_proba = estimator.predict_proba(X)\n",
    "    score = custom_metric(y_true, y_pred_proba, in_model=True)\n",
    "    return score\n",
    "\n",
    "proba_values = []\n",
    "custom_score = make_scorer(custom_score, needs_proba=True)                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "948f1859",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T20:05:28.627261Z",
     "start_time": "2023-03-22T20:04:51.120428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% de la classe 0 : 282682\n",
      "100% de la classe 1 : 24825\n",
      "\n",
      "Train shape: (307507, 375), test shape: (48744, 375)\n",
      "Nombre de variables normalisés : 251\n",
      "Train Dimension: \n",
      "X_train : (230629, 374) \n",
      "X_test : (76877, 374) \n",
      "y_train : (230629,) \n",
      "y_test : (76877,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, feature_names = udf.data_reader(data, 100,)# save_test_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c33020a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T16:47:00.658836Z",
     "start_time": "2023-03-22T16:46:57.177895Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>...</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Refused_MIN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Sentproposal_MIN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Sentproposal_MAX</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Signed_MAX</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Signed_SUM</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_MIN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_MAX</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_MEAN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_SUM</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_VAR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100001</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.075102</td>\n",
       "      <td>-0.451695</td>\n",
       "      <td>-0.146668</td>\n",
       "      <td>-0.734183</td>\n",
       "      <td>-0.161753</td>\n",
       "      <td>-0.052189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.045826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100005</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.934825</td>\n",
       "      <td>-0.671813</td>\n",
       "      <td>1.079459</td>\n",
       "      <td>-0.464475</td>\n",
       "      <td>-1.089349</td>\n",
       "      <td>-1.173430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.045826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100013</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>0.159595</td>\n",
       "      <td>2.943833</td>\n",
       "      <td>-0.127871</td>\n",
       "      <td>-0.916815</td>\n",
       "      <td>-1.084148</td>\n",
       "      <td>0.797684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.045826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100028</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.192118</td>\n",
       "      <td>2.424820</td>\n",
       "      <td>1.511669</td>\n",
       "      <td>0.399884</td>\n",
       "      <td>0.472288</td>\n",
       "      <td>0.038503</td>\n",
       "      <td>0.847643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.045826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100038</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.807294</td>\n",
       "      <td>0.065770</td>\n",
       "      <td>0.342157</td>\n",
       "      <td>-0.783588</td>\n",
       "      <td>0.686772</td>\n",
       "      <td>-0.102803</td>\n",
       "      <td>0.279926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.045826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 374 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            CODE_GENDER  FLAG_OWN_CAR  FLAG_OWN_REALTY  CNT_CHILDREN  \\\n",
       "SK_ID_CURR                                                             \n",
       "100001                1             0                0     -0.577530   \n",
       "100005                0             0                0     -0.577530   \n",
       "100013                0             1                0     -0.577530   \n",
       "100028                1             0                0      2.192118   \n",
       "100038                0             1                1      0.807294   \n",
       "\n",
       "            AMT_CREDIT  AMT_ANNUITY  REGION_POPULATION_RELATIVE  DAYS_BIRTH  \\\n",
       "SK_ID_CURR                                                                    \n",
       "100001       -0.075102    -0.451695                   -0.146668   -0.734183   \n",
       "100005       -0.934825    -0.671813                    1.079459   -0.464475   \n",
       "100013        0.159595     2.943833                   -0.127871   -0.916815   \n",
       "100028        2.424820     1.511669                    0.399884    0.472288   \n",
       "100038        0.065770     0.342157                   -0.783588    0.686772   \n",
       "\n",
       "            DAYS_EMPLOYED  DAYS_REGISTRATION  ...  \\\n",
       "SK_ID_CURR                                    ...   \n",
       "100001          -0.161753          -0.052189  ...   \n",
       "100005          -1.089349          -1.173430  ...   \n",
       "100013          -1.084148           0.797684  ...   \n",
       "100028           0.038503           0.847643  ...   \n",
       "100038          -0.102803           0.279926  ...   \n",
       "\n",
       "            CC_NAME_CONTRACT_STATUS_Refused_MIN  \\\n",
       "SK_ID_CURR                                        \n",
       "100001                                      0.0   \n",
       "100005                                      0.0   \n",
       "100013                                      0.0   \n",
       "100028                                      0.0   \n",
       "100038                                      0.0   \n",
       "\n",
       "            CC_NAME_CONTRACT_STATUS_Sentproposal_MIN  \\\n",
       "SK_ID_CURR                                             \n",
       "100001                                           0.0   \n",
       "100005                                           0.0   \n",
       "100013                                           0.0   \n",
       "100028                                           0.0   \n",
       "100038                                           0.0   \n",
       "\n",
       "            CC_NAME_CONTRACT_STATUS_Sentproposal_MAX  \\\n",
       "SK_ID_CURR                                             \n",
       "100001                                           0.0   \n",
       "100005                                           0.0   \n",
       "100013                                           0.0   \n",
       "100028                                           0.0   \n",
       "100038                                           0.0   \n",
       "\n",
       "            CC_NAME_CONTRACT_STATUS_Signed_MAX  \\\n",
       "SK_ID_CURR                                       \n",
       "100001                                     0.0   \n",
       "100005                                     0.0   \n",
       "100013                                     0.0   \n",
       "100028                                     0.0   \n",
       "100038                                     0.0   \n",
       "\n",
       "            CC_NAME_CONTRACT_STATUS_Signed_SUM  \\\n",
       "SK_ID_CURR                                       \n",
       "100001                               -0.045826   \n",
       "100005                               -0.045826   \n",
       "100013                               -0.045826   \n",
       "100028                               -0.045826   \n",
       "100038                               -0.045826   \n",
       "\n",
       "            CC_NAME_CONTRACT_STATUS_nan_MIN  CC_NAME_CONTRACT_STATUS_nan_MAX  \\\n",
       "SK_ID_CURR                                                                     \n",
       "100001                                  0.0                              0.0   \n",
       "100005                                  0.0                              0.0   \n",
       "100013                                  0.0                              0.0   \n",
       "100028                                  0.0                              0.0   \n",
       "100038                                  0.0                              0.0   \n",
       "\n",
       "            CC_NAME_CONTRACT_STATUS_nan_MEAN  CC_NAME_CONTRACT_STATUS_nan_SUM  \\\n",
       "SK_ID_CURR                                                                      \n",
       "100001                                   0.0                              0.0   \n",
       "100005                                   0.0                              0.0   \n",
       "100013                                   0.0                              0.0   \n",
       "100028                                   0.0                              0.0   \n",
       "100038                                   0.0                              0.0   \n",
       "\n",
       "            CC_NAME_CONTRACT_STATUS_nan_VAR  \n",
       "SK_ID_CURR                                   \n",
       "100001                                  0.0  \n",
       "100005                                  0.0  \n",
       "100013                                  0.0  \n",
       "100028                                  0.0  \n",
       "100038                                  0.0  \n",
       "\n",
       "[5 rows x 374 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"/Users/kone/Desktop/Oc_Formation/Projets/Projet7/openclassrooms_projects7/model_and_data/test_df.csv\", index_col=[0])\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3516f4f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T16:48:03.184123Z",
     "start_time": "2023-03-22T16:48:03.089273Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>...</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Refused_MIN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Sentproposal_MIN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Sentproposal_MAX</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Signed_MAX</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Signed_SUM</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_MIN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_MAX</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_MEAN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_SUM</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_VAR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100001</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.57753</td>\n",
       "      <td>-0.075102</td>\n",
       "      <td>-0.451695</td>\n",
       "      <td>-0.146668</td>\n",
       "      <td>-0.734183</td>\n",
       "      <td>-0.161753</td>\n",
       "      <td>-0.052189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.045826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 374 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            CODE_GENDER  FLAG_OWN_CAR  FLAG_OWN_REALTY  CNT_CHILDREN  \\\n",
       "SK_ID_CURR                                                             \n",
       "100001                1             0                0      -0.57753   \n",
       "\n",
       "            AMT_CREDIT  AMT_ANNUITY  REGION_POPULATION_RELATIVE  DAYS_BIRTH  \\\n",
       "SK_ID_CURR                                                                    \n",
       "100001       -0.075102    -0.451695                   -0.146668   -0.734183   \n",
       "\n",
       "            DAYS_EMPLOYED  DAYS_REGISTRATION  ...  \\\n",
       "SK_ID_CURR                                    ...   \n",
       "100001          -0.161753          -0.052189  ...   \n",
       "\n",
       "            CC_NAME_CONTRACT_STATUS_Refused_MIN  \\\n",
       "SK_ID_CURR                                        \n",
       "100001                                      0.0   \n",
       "\n",
       "            CC_NAME_CONTRACT_STATUS_Sentproposal_MIN  \\\n",
       "SK_ID_CURR                                             \n",
       "100001                                           0.0   \n",
       "\n",
       "            CC_NAME_CONTRACT_STATUS_Sentproposal_MAX  \\\n",
       "SK_ID_CURR                                             \n",
       "100001                                           0.0   \n",
       "\n",
       "            CC_NAME_CONTRACT_STATUS_Signed_MAX  \\\n",
       "SK_ID_CURR                                       \n",
       "100001                                     0.0   \n",
       "\n",
       "            CC_NAME_CONTRACT_STATUS_Signed_SUM  \\\n",
       "SK_ID_CURR                                       \n",
       "100001                               -0.045826   \n",
       "\n",
       "            CC_NAME_CONTRACT_STATUS_nan_MIN  CC_NAME_CONTRACT_STATUS_nan_MAX  \\\n",
       "SK_ID_CURR                                                                     \n",
       "100001                                  0.0                              0.0   \n",
       "\n",
       "            CC_NAME_CONTRACT_STATUS_nan_MEAN  CC_NAME_CONTRACT_STATUS_nan_SUM  \\\n",
       "SK_ID_CURR                                                                      \n",
       "100001                                   0.0                              0.0   \n",
       "\n",
       "            CC_NAME_CONTRACT_STATUS_nan_VAR  \n",
       "SK_ID_CURR                                   \n",
       "100001                                  0.0  \n",
       "\n",
       "[1 rows x 374 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = test_df[test_df.index == 100001]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40ffad5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T17:48:54.370289Z",
     "start_time": "2023-03-22T17:48:54.271035Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predic_proba = [1] #model.predict_proba(row)[:,1]\n",
    "predic_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16f5cd1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T17:58:13.850538Z",
     "start_time": "2023-03-22T17:48:55.223414Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rm/h7csftjd5bs95gx889r84c2r0000gn/T/ipykernel_3421/3013438505.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m result = permutation_importance(\n\u001b[0m\u001b[1;32m      2\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredic_proba\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_repeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/inspection/_permutation_importance.py\u001b[0m in \u001b[0;36mpermutation_importance\u001b[0;34m(estimator, X, y, scoring, n_repeats, n_jobs, random_state, sample_weight, max_samples)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0mbaseline_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_weights_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m     scores = Parallel(n_jobs=n_jobs)(\n\u001b[0m\u001b[1;32m    260\u001b[0m         delayed(_calculate_permutation_scores)(\n\u001b[1;32m    261\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/oc_project_env/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/oc_project_env/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result = permutation_importance(\n",
    "            model, row, predic_proba,n_repeats=5, random_state=42, n_jobs=-1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2d176e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19fc9960",
   "metadata": {},
   "source": [
    "## Base-line\n",
    "\n",
    "### Conscturction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18debf25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T16:37:34.690591Z",
     "start_time": "2023-03-22T16:37:31.368905Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;smote&#x27;, SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 StackingClassifier(cv=StratifiedKFold(n_splits=5,\n",
       "        random_state=RandomState(MT19937) at 0x7F9DB5308E40, shuffle=False),\n",
       "                                    estimators=[(&#x27;LogisticRegression&#x27;,\n",
       "                                                 LogisticRegression(C=6.681553108313681e-08,\n",
       "                                                                    n_jobs=-1,\n",
       "                                                                    random_state=42,\n",
       "                                                                    tol=0.0002329433780056682))],\n",
       "                                    final_estimator=RandomForestClassifier(max_depth=20,\n",
       "                                                                           min_samples_leaf=10,\n",
       "                                                                           min_samples_split=6,\n",
       "                                                                           n_estimators=882),\n",
       "                                    n_jobs=-1, passthrough=True,\n",
       "                                    stack_method=&#x27;predict_proba&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;smote&#x27;, SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 StackingClassifier(cv=StratifiedKFold(n_splits=5,\n",
       "        random_state=RandomState(MT19937) at 0x7F9DB5308E40, shuffle=False),\n",
       "                                    estimators=[(&#x27;LogisticRegression&#x27;,\n",
       "                                                 LogisticRegression(C=6.681553108313681e-08,\n",
       "                                                                    n_jobs=-1,\n",
       "                                                                    random_state=42,\n",
       "                                                                    tol=0.0002329433780056682))],\n",
       "                                    final_estimator=RandomForestClassifier(max_depth=20,\n",
       "                                                                           min_samples_leaf=10,\n",
       "                                                                           min_samples_split=6,\n",
       "                                                                           n_estimators=882),\n",
       "                                    n_jobs=-1, passthrough=True,\n",
       "                                    stack_method=&#x27;predict_proba&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE(k_neighbors=17, random_state=1001)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">model: StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(cv=StratifiedKFold(n_splits=5,\n",
       "        random_state=RandomState(MT19937) at 0x7F9DB5308E40, shuffle=False),\n",
       "                   estimators=[(&#x27;LogisticRegression&#x27;,\n",
       "                                LogisticRegression(C=6.681553108313681e-08,\n",
       "                                                   n_jobs=-1, random_state=42,\n",
       "                                                   tol=0.0002329433780056682))],\n",
       "                   final_estimator=RandomForestClassifier(max_depth=20,\n",
       "                                                          min_samples_leaf=10,\n",
       "                                                          min_samples_split=6,\n",
       "                                                          n_estimators=882),\n",
       "                   n_jobs=-1, passthrough=True, stack_method=&#x27;predict_proba&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>LogisticRegression</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=6.681553108313681e-08, n_jobs=-1, random_state=42,\n",
       "                   tol=0.0002329433780056682)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=20, min_samples_leaf=10, min_samples_split=6,\n",
       "                       n_estimators=882)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('smote', SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                ('model',\n",
       "                 StackingClassifier(cv=StratifiedKFold(n_splits=5,\n",
       "        random_state=RandomState(MT19937) at 0x7F9DB5308E40, shuffle=False),\n",
       "                                    estimators=[('LogisticRegression',\n",
       "                                                 LogisticRegression(C=6.681553108313681e-08,\n",
       "                                                                    n_jobs=-1,\n",
       "                                                                    random_state=42,\n",
       "                                                                    tol=0.0002329433780056682))],\n",
       "                                    final_estimator=RandomForestClassifier(max_depth=20,\n",
       "                                                                           min_samples_leaf=10,\n",
       "                                                                           min_samples_split=6,\n",
       "                                                                           n_estimators=882),\n",
       "                                    n_jobs=-1, passthrough=True,\n",
       "                                    stack_method='predict_proba'))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle as p\n",
    "model_path = \"/Users/kone/Desktop/Oc_Formation/Projets/Projet7/openclassrooms_projects7/model_and_data/model.pkl\"\n",
    "\n",
    "model = p.load(open(model_path, 'rb'))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "006c166c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T20:30:29.542226Z",
     "start_time": "2023-03-21T20:29:43.317110Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66382313",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T20:30:38.378955Z",
     "start_time": "2023-03-21T20:30:37.537560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pour le seuil 0.2, le f3_score est : 0.532 et le mean score est : 0.587\n"
     ]
    }
   ],
   "source": [
    "threshold_f3 = custom_metric(y_test, y_pred_proba, return_proba=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52dd8328",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T20:31:08.562404Z",
     "start_time": "2023-03-21T20:30:41.714256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.641349\n",
      "f3_score : 0.532339 \n",
      "\n",
      "Mean evalation score : 0.586844\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(model, X_test, y_test, threshold_f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a844d241",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T22:19:50.404752Z",
     "start_time": "2023-03-09T22:19:50.332779Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ac28c1f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T22:15:14.177714Z",
     "start_time": "2023-03-09T22:15:13.340038Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;smote&#x27;, SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 DummyClassifier(random_state=42, strategy=&#x27;uniform&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;smote&#x27;, SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 DummyClassifier(random_state=42, strategy=&#x27;uniform&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" ><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE(k_neighbors=17, random_state=1001)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" ><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DummyClassifier</label><div class=\"sk-toggleable__content\"><pre>DummyClassifier(random_state=42, strategy=&#x27;uniform&#x27;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('smote', SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                ('model',\n",
       "                 DummyClassifier(random_state=42, strategy='uniform'))])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Construction d'un modèle base-line avec avec la strategie uniforme\n",
    "dummy_classifier = DummyClassifier(strategy='uniform', random_state=42)\n",
    "dummy_smote = Pipeline([('smote', smote), ('model', dummy_classifier)])\n",
    "dummy_smote.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1b6598de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T22:19:56.501620Z",
     "start_time": "2023-03-09T22:19:56.421007Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_proba = dummy_classifier.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6c790e70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T22:19:57.556774Z",
     "start_time": "2023-03-09T22:19:57.420311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.0 et le mean score est : 0.46\n"
     ]
    }
   ],
   "source": [
    "threshold_f3 = custom_metric(y_test, y_pred_proba, return_proba=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5e099f9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-20T20:13:53.383208Z",
     "start_time": "2023-03-20T20:13:26.695630Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.724339\n",
      "f3_score : 0.709340 \n",
      "\n",
      "Mean evalation score : 0.716840\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(model, X_test, y_test, threshold_f3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8242f3",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7295dbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T20:07:15.726953Z",
     "start_time": "2023-03-22T20:07:15.638395Z"
    }
   },
   "outputs": [],
   "source": [
    "#Fonction pour l'evaluation des modèles\n",
    "def evaluate_model(model, X_test, y_test, threshold):\n",
    "    \"\"\"prend en paramètre le modèle, les données de test et un seuil de classification\n",
    "    affiche le résultat de l'evaluation\"\"\"\n",
    "    #custom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\n",
    "    sns.set_theme(style=\"ticks\") #rc=custom_params)\n",
    "\n",
    "    # prediction des labels pour un seuil de classification\n",
    "    pred_proba = model.predict_proba(X_test)[:,1]\n",
    "    label_pred_threshold = np.where(pred_proba >= threshold, 1, 0)\n",
    "    \n",
    "    #Evaluation du modèle avec le seuil de classification précédent\n",
    "    acc = accuracy_score(y_test, label_pred_threshold)\n",
    "    f3_score = fbeta_score(beta=sqrt(10), y_true=y_test, y_pred=label_pred_threshold)\n",
    "    print('Accuracy score : %3f' % acc)\n",
    "    print('f3_score : %3f' % f3_score, \"\\n\")\n",
    "    print('Mean evalation score : %3f' % mean([acc, f3_score]))\n",
    "    \n",
    "    conf_mat = confusion_matrix(y_test, label_pred_threshold, normalize='true')\n",
    "    \n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat, display_labels=model.classes_)\n",
    "    disp.plot(cmap='Blues', values_format='.2f')\n",
    "    #conf_mat_df = pd.DataFrame(conf_mat, columns=range(2), index=range(2))\n",
    "    #sns.heatmap(conf_mat_df, annot=True, annot_kws={\"size\": 16}, fmt='g', cmap='Blues', cbar=False)\n",
    "    plt.title('Confusion matrix', fontsize=16, fontweight='bold')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5f969a7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T22:19:59.872877Z",
     "start_time": "2023-03-09T22:19:59.641955Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.919225\n",
      "f3_score : 0.000000 \n",
      "\n",
      "Mean evalation score : 0.459612\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(dummy_classifier, X_test, y_test, threshold_f3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc0ea5c",
   "metadata": {},
   "source": [
    "## KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d1f47f58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T22:20:02.371561Z",
     "start_time": "2023-03-09T22:20:01.121658Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-17 {color: black;background-color: white;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;smote&#x27;, SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                (&#x27;knn&#x27;, KNeighborsClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-49\" type=\"checkbox\" ><label for=\"sk-estimator-id-49\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;smote&#x27;, SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                (&#x27;knn&#x27;, KNeighborsClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-50\" type=\"checkbox\" ><label for=\"sk-estimator-id-50\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE(k_neighbors=17, random_state=1001)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-51\" type=\"checkbox\" ><label for=\"sk-estimator-id-51\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('smote', SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                ('knn', KNeighborsClassifier())])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn_smote = Pipeline([('smote', smote), ('knn', knn)])\n",
    "knn_smote.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fcf616e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T22:20:09.099761Z",
     "start_time": "2023-03-09T22:20:03.831865Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.413 et le mean score est : 0.486\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn_smote.predict_proba(X_test)[:,1]\n",
    "threshold = custom_metric(y_test, y_pred, return_proba=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "22ac5930",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T22:15:54.601711Z",
     "start_time": "2023-03-09T22:15:50.400400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.559834\n",
      "f3_score : 0.412741 \n",
      "\n",
      "Mean evalation score : 0.486287\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(knn_smote, X_test, y_test, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a8b393c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T20:08:34.571529Z",
     "start_time": "2023-03-22T20:08:34.448982Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "def model_optimization(\n",
    "    model, param_grid,\n",
    "    X_train=X_train, \n",
    "    y_train=y_train, \n",
    "    factor=3\n",
    "):\n",
    "    \"\"\"prend en paramètre le modèle, les données de train reéquilibrées et de test\n",
    "    montre les performances du model après optimisation\"\"\"\n",
    "    \n",
    "    X_train = X_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    \n",
    "    #définition du pipeline de randomsearchcv\n",
    "    model_grid = HalvingGridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv, \n",
    "        verbose=1, \n",
    "        scoring=custom_score,\n",
    "        random_state=42,\n",
    "        factor=factor\n",
    "    )\n",
    "    \n",
    "    model_pipeline = Pipeline([('smote', smote), ('model_grid', model_grid)])\n",
    "    model_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    best_prarams = model_pipeline['model_grid'].best_params_\n",
    "    print(f\"Best parameters: {best_prarams}\")\n",
    "    \n",
    "    best_model = Pipeline([('smote', smote), ('model', model.set_params(**best_prarams))])\n",
    "    best_model.fit(X_train, y_train)\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "def best_model_evaluation(best_model, X_test=X_test, y_test=y_test):\n",
    "    \n",
    "    X_test = X_test.rename(columns=lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    \n",
    "    y_pred_proba = best_model.predict_proba(X_test)[:,1]\n",
    "    threshold = custom_metric(y_test, y_pred_proba, return_proba=True)[1]\n",
    "    evaluate_model(best_model, X_test, y_test, threshold)\n",
    "    \n",
    "def construct_model(model, model_params, X_train=X_train, y_train=y_train):\n",
    "    \n",
    "    X_train = X_train.rename(columns=lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    model_smote = Pipeline([('smote', smote), ('model', model.set_params(**model_params))])\n",
    "    \n",
    "    return model_smote.fit(X_train, y_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46995b0c",
   "metadata": {},
   "source": [
    "### Optimisation & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "10bda8d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T22:23:48.990943Z",
     "start_time": "2023-03-09T22:23:48.294146Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/03/09 23:23:48 INFO mlflow.tracking.fluent: Experiment with name 'KNeighborsClassifier(1) Hyperparameter Tuning' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'205842512423992445'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_id = dict(mlflow.set_experiment(\"KNeighborsClassifier(1) Hyperparameter Tuning\"))['experiment_id']\n",
    "experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "db845da3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T19:39:25.461648Z",
     "start_time": "2023-03-13T19:39:24.516514Z"
    }
   },
   "outputs": [],
   "source": [
    "def mlflow_hyperparameter_tuning(experiment_id, params, scores):\n",
    "    \n",
    "    with mlflow.start_run(experiment_id=experiment_id):\n",
    "    \n",
    "        for param_name, val in params.items():\n",
    "            mlflow.log_param(param_name, val)\n",
    "        \n",
    "        mlflow.log_metric(\"Mean F3_score\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5b25f644",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T23:05:25.430874Z",
     "start_time": "2023-03-09T22:34:27.902850Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-09 23:34:28,480]\u001b[0m A new study created in memory with name: Hyperparameters optimization\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:34:57,559]\u001b[0m Trial 0 finished with value: 0.410662122128674 and parameters: {'n_neighbors': 86}. Best is trial 0 with value: 0.410662122128674.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:35:23,936]\u001b[0m Trial 1 finished with value: 0.4200960882931901 and parameters: {'n_neighbors': 179}. Best is trial 1 with value: 0.4200960882931901.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:35:43,310]\u001b[0m Trial 2 finished with value: 0.4233719556912277 and parameters: {'n_neighbors': 282}. Best is trial 2 with value: 0.4233719556912277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:36:05,040]\u001b[0m Trial 3 finished with value: 0.4202528695552584 and parameters: {'n_neighbors': 231}. Best is trial 2 with value: 0.4233719556912277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:36:24,011]\u001b[0m Trial 4 finished with value: 0.41813404416900646 and parameters: {'n_neighbors': 100}. Best is trial 2 with value: 0.4233719556912277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:36:42,822]\u001b[0m Trial 5 finished with value: 0.4263044966862872 and parameters: {'n_neighbors': 290}. Best is trial 5 with value: 0.4263044966862872.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:37:01,513]\u001b[0m Trial 6 finished with value: 0.42643910256664713 and parameters: {'n_neighbors': 188}. Best is trial 6 with value: 0.42643910256664713.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:37:19,581]\u001b[0m Trial 7 finished with value: 0.4256806858224092 and parameters: {'n_neighbors': 160}. Best is trial 6 with value: 0.42643910256664713.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:37:37,938]\u001b[0m Trial 8 finished with value: 0.4039176722383611 and parameters: {'n_neighbors': 58}. Best is trial 6 with value: 0.42643910256664713.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:37:56,327]\u001b[0m Trial 9 finished with value: 0.4198233003594639 and parameters: {'n_neighbors': 233}. Best is trial 6 with value: 0.42643910256664713.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:38:12,634]\u001b[0m Trial 10 finished with value: 0.3812061135968575 and parameters: {'n_neighbors': 19}. Best is trial 6 with value: 0.42643910256664713.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:38:31,036]\u001b[0m Trial 11 finished with value: 0.422101318609036 and parameters: {'n_neighbors': 299}. Best is trial 6 with value: 0.42643910256664713.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:38:48,664]\u001b[0m Trial 12 finished with value: 0.4240465701569134 and parameters: {'n_neighbors': 221}. Best is trial 6 with value: 0.42643910256664713.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:39:05,957]\u001b[0m Trial 13 finished with value: 0.4175584465078626 and parameters: {'n_neighbors': 127}. Best is trial 6 with value: 0.42643910256664713.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:39:26,779]\u001b[0m Trial 14 finished with value: 0.42191326107065813 and parameters: {'n_neighbors': 266}. Best is trial 6 with value: 0.42643910256664713.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:39:46,742]\u001b[0m Trial 15 finished with value: 0.4278028443492385 and parameters: {'n_neighbors': 190}. Best is trial 15 with value: 0.4278028443492385.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:40:05,741]\u001b[0m Trial 16 finished with value: 0.42572446271417413 and parameters: {'n_neighbors': 192}. Best is trial 15 with value: 0.4278028443492385.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:40:25,151]\u001b[0m Trial 17 finished with value: 0.42576167389742975 and parameters: {'n_neighbors': 196}. Best is trial 15 with value: 0.4278028443492385.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:40:42,077]\u001b[0m Trial 18 finished with value: 0.41515332132072924 and parameters: {'n_neighbors': 129}. Best is trial 15 with value: 0.4278028443492385.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:40:59,138]\u001b[0m Trial 19 finished with value: 0.42557349176993275 and parameters: {'n_neighbors': 145}. Best is trial 15 with value: 0.4278028443492385.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:41:16,242]\u001b[0m Trial 20 finished with value: 0.4254938927427122 and parameters: {'n_neighbors': 211}. Best is trial 15 with value: 0.4278028443492385.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:41:33,796]\u001b[0m Trial 21 finished with value: 0.4217530879335101 and parameters: {'n_neighbors': 255}. Best is trial 15 with value: 0.4278028443492385.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:41:50,282]\u001b[0m Trial 22 finished with value: 0.4257336411509285 and parameters: {'n_neighbors': 167}. Best is trial 15 with value: 0.4278028443492385.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:42:07,655]\u001b[0m Trial 23 finished with value: 0.42294416720386 and parameters: {'n_neighbors': 251}. Best is trial 15 with value: 0.4278028443492385.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:42:25,544]\u001b[0m Trial 24 finished with value: 0.4264536919416678 and parameters: {'n_neighbors': 204}. Best is trial 15 with value: 0.4278028443492385.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:42:44,152]\u001b[0m Trial 25 finished with value: 0.4279717441320986 and parameters: {'n_neighbors': 200}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:43:01,623]\u001b[0m Trial 26 finished with value: 0.42482606345350293 and parameters: {'n_neighbors': 213}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:43:18,581]\u001b[0m Trial 27 finished with value: 0.42562592199681903 and parameters: {'n_neighbors': 166}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:43:36,184]\u001b[0m Trial 28 finished with value: 0.41515332132072924 and parameters: {'n_neighbors': 129}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:43:52,059]\u001b[0m Trial 29 finished with value: 0.40585167305679876 and parameters: {'n_neighbors': 76}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:44:11,881]\u001b[0m Trial 30 finished with value: 0.42279302701725713 and parameters: {'n_neighbors': 245}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:44:29,555]\u001b[0m Trial 31 finished with value: 0.42396949490963154 and parameters: {'n_neighbors': 194}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:44:48,346]\u001b[0m Trial 32 finished with value: 0.421949886341175 and parameters: {'n_neighbors': 183}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:45:06,583]\u001b[0m Trial 33 finished with value: 0.4245634446451598 and parameters: {'n_neighbors': 209}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:45:23,116]\u001b[0m Trial 34 finished with value: 0.42579669145665777 and parameters: {'n_neighbors': 151}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:45:39,742]\u001b[0m Trial 35 finished with value: 0.4200960882931901 and parameters: {'n_neighbors': 179}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:45:58,897]\u001b[0m Trial 36 finished with value: 0.4235249164184591 and parameters: {'n_neighbors': 271}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:46:16,318]\u001b[0m Trial 37 finished with value: 0.42478254809113764 and parameters: {'n_neighbors': 225}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:46:34,307]\u001b[0m Trial 38 finished with value: 0.4194809783332246 and parameters: {'n_neighbors': 106}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:46:52,299]\u001b[0m Trial 39 finished with value: 0.4243266627081666 and parameters: {'n_neighbors': 176}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:47:09,798]\u001b[0m Trial 40 finished with value: 0.4236770383425184 and parameters: {'n_neighbors': 241}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:47:27,977]\u001b[0m Trial 41 finished with value: 0.42783992585880276 and parameters: {'n_neighbors': 286}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:47:46,061]\u001b[0m Trial 42 finished with value: 0.42518500569735973 and parameters: {'n_neighbors': 281}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:48:03,649]\u001b[0m Trial 43 finished with value: 0.4275632483712 and parameters: {'n_neighbors': 206}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:48:22,826]\u001b[0m Trial 44 finished with value: 0.4268583480105984 and parameters: {'n_neighbors': 202}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:48:44,833]\u001b[0m Trial 45 finished with value: 0.42000904231483516 and parameters: {'n_neighbors': 232}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-09 23:49:01,834]\u001b[0m Trial 46 finished with value: 0.4199309583598458 and parameters: {'n_neighbors': 144}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:49:19,674]\u001b[0m Trial 47 finished with value: 0.420237388326887 and parameters: {'n_neighbors': 262}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:49:37,155]\u001b[0m Trial 48 finished with value: 0.4209030084953465 and parameters: {'n_neighbors': 228}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:49:56,580]\u001b[0m Trial 49 finished with value: 0.4241910294054311 and parameters: {'n_neighbors': 300}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:50:14,875]\u001b[0m Trial 50 finished with value: 0.4233719556912277 and parameters: {'n_neighbors': 282}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:50:32,880]\u001b[0m Trial 51 finished with value: 0.4279717441320986 and parameters: {'n_neighbors': 200}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:50:49,969]\u001b[0m Trial 52 finished with value: 0.42329261511032756 and parameters: {'n_neighbors': 199}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:51:08,741]\u001b[0m Trial 53 finished with value: 0.4240465701569134 and parameters: {'n_neighbors': 221}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:51:24,720]\u001b[0m Trial 54 finished with value: 0.39220442010218737 and parameters: {'n_neighbors': 18}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:51:41,416]\u001b[0m Trial 55 finished with value: 0.4258434029690882 and parameters: {'n_neighbors': 155}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:51:58,072]\u001b[0m Trial 56 finished with value: 0.42266460998218863 and parameters: {'n_neighbors': 173}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:52:17,368]\u001b[0m Trial 57 finished with value: 0.42643910256664713 and parameters: {'n_neighbors': 188}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:52:35,121]\u001b[0m Trial 58 finished with value: 0.42643665520930485 and parameters: {'n_neighbors': 215}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:52:52,082]\u001b[0m Trial 59 finished with value: 0.42423439765529497 and parameters: {'n_neighbors': 198}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:53:08,937]\u001b[0m Trial 60 finished with value: 0.4218488058709352 and parameters: {'n_neighbors': 163}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:53:28,682]\u001b[0m Trial 61 finished with value: 0.4254938927427122 and parameters: {'n_neighbors': 211}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:53:47,648]\u001b[0m Trial 62 finished with value: 0.4264536919416678 and parameters: {'n_neighbors': 204}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:54:06,221]\u001b[0m Trial 63 finished with value: 0.42378801380971554 and parameters: {'n_neighbors': 242}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:54:23,290]\u001b[0m Trial 64 finished with value: 0.4147474168437123 and parameters: {'n_neighbors': 35}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:54:41,487]\u001b[0m Trial 65 finished with value: 0.42744929410117827 and parameters: {'n_neighbors': 191}. Best is trial 25 with value: 0.4279717441320986.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:54:58,591]\u001b[0m Trial 66 finished with value: 0.4282242711367899 and parameters: {'n_neighbors': 187}. Best is trial 66 with value: 0.4282242711367899.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:55:20,350]\u001b[0m Trial 67 finished with value: 0.4282242711367899 and parameters: {'n_neighbors': 187}. Best is trial 66 with value: 0.4282242711367899.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:55:41,434]\u001b[0m Trial 68 finished with value: 0.42215459159484936 and parameters: {'n_neighbors': 142}. Best is trial 66 with value: 0.4282242711367899.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:56:03,127]\u001b[0m Trial 69 finished with value: 0.42489558549500545 and parameters: {'n_neighbors': 172}. Best is trial 66 with value: 0.4282242711367899.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:56:22,346]\u001b[0m Trial 70 finished with value: 0.42643910256664713 and parameters: {'n_neighbors': 188}. Best is trial 66 with value: 0.4282242711367899.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:56:41,171]\u001b[0m Trial 71 finished with value: 0.4227343476726717 and parameters: {'n_neighbors': 184}. Best is trial 66 with value: 0.4282242711367899.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:57:00,674]\u001b[0m Trial 72 finished with value: 0.41721404603123957 and parameters: {'n_neighbors': 111}. Best is trial 66 with value: 0.4282242711367899.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:57:20,126]\u001b[0m Trial 73 finished with value: 0.4241799279123618 and parameters: {'n_neighbors': 158}. Best is trial 66 with value: 0.4282242711367899.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:57:37,887]\u001b[0m Trial 74 finished with value: 0.42572446271417413 and parameters: {'n_neighbors': 192}. Best is trial 66 with value: 0.4282242711367899.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:57:55,653]\u001b[0m Trial 75 finished with value: 0.4200960882931901 and parameters: {'n_neighbors': 179}. Best is trial 66 with value: 0.4282242711367899.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:58:14,611]\u001b[0m Trial 76 finished with value: 0.4251994211184441 and parameters: {'n_neighbors': 217}. Best is trial 66 with value: 0.4282242711367899.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:58:35,300]\u001b[0m Trial 77 finished with value: 0.42249158787189484 and parameters: {'n_neighbors': 169}. Best is trial 66 with value: 0.4282242711367899.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:58:53,331]\u001b[0m Trial 78 finished with value: 0.41949637506154397 and parameters: {'n_neighbors': 229}. Best is trial 66 with value: 0.4282242711367899.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:59:10,748]\u001b[0m Trial 79 finished with value: 0.42197551839812597 and parameters: {'n_neighbors': 237}. Best is trial 66 with value: 0.4282242711367899.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:59:28,834]\u001b[0m Trial 80 finished with value: 0.4198550046858866 and parameters: {'n_neighbors': 254}. Best is trial 66 with value: 0.4282242711367899.\u001b[0m\n",
      "\u001b[32m[I 2023-03-09 23:59:46,104]\u001b[0m Trial 81 finished with value: 0.4279717441320986 and parameters: {'n_neighbors': 200}. Best is trial 66 with value: 0.4282242711367899.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 00:00:04,120]\u001b[0m Trial 82 finished with value: 0.4264708159653462 and parameters: {'n_neighbors': 207}. Best is trial 66 with value: 0.4282242711367899.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 00:00:23,702]\u001b[0m Trial 83 finished with value: 0.4255886925546818 and parameters: {'n_neighbors': 193}. Best is trial 66 with value: 0.4282242711367899.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 00:00:43,367]\u001b[0m Trial 84 finished with value: 0.4227343476726717 and parameters: {'n_neighbors': 184}. Best is trial 66 with value: 0.4282242711367899.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 00:01:01,464]\u001b[0m Trial 85 finished with value: 0.4279717441320986 and parameters: {'n_neighbors': 200}. Best is trial 66 with value: 0.4282242711367899.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 00:01:20,840]\u001b[0m Trial 86 finished with value: 0.4255574860589295 and parameters: {'n_neighbors': 220}. Best is trial 66 with value: 0.4282242711367899.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 00:01:39,360]\u001b[0m Trial 87 finished with value: 0.4275632483712 and parameters: {'n_neighbors': 206}. Best is trial 66 with value: 0.4282242711367899.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 00:01:56,425]\u001b[0m Trial 88 finished with value: 0.42491266861853305 and parameters: {'n_neighbors': 180}. Best is trial 66 with value: 0.4282242711367899.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 00:02:13,771]\u001b[0m Trial 89 finished with value: 0.42423439765529497 and parameters: {'n_neighbors': 198}. Best is trial 66 with value: 0.4282242711367899.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 00:02:31,447]\u001b[0m Trial 90 finished with value: 0.4166727076090037 and parameters: {'n_neighbors': 134}. Best is trial 66 with value: 0.4282242711367899.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 00:02:48,475]\u001b[0m Trial 91 finished with value: 0.4264708159653462 and parameters: {'n_neighbors': 207}. Best is trial 66 with value: 0.4282242711367899.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 00:03:06,629]\u001b[0m Trial 92 finished with value: 0.4257529411581835 and parameters: {'n_neighbors': 291}. Best is trial 66 with value: 0.4282242711367899.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-10 00:03:23,805]\u001b[0m Trial 93 finished with value: 0.4238012875961673 and parameters: {'n_neighbors': 214}. Best is trial 66 with value: 0.4282242711367899.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 00:03:40,941]\u001b[0m Trial 94 finished with value: 0.4279717441320986 and parameters: {'n_neighbors': 200}. Best is trial 66 with value: 0.4282242711367899.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 00:04:02,447]\u001b[0m Trial 95 finished with value: 0.4205102535646459 and parameters: {'n_neighbors': 224}. Best is trial 66 with value: 0.4282242711367899.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 00:04:20,737]\u001b[0m Trial 96 finished with value: 0.42329261511032756 and parameters: {'n_neighbors': 199}. Best is trial 66 with value: 0.4282242711367899.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 00:04:40,462]\u001b[0m Trial 97 finished with value: 0.4215730441032314 and parameters: {'n_neighbors': 174}. Best is trial 66 with value: 0.4282242711367899.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 00:05:02,955]\u001b[0m Trial 98 finished with value: 0.42115745505600294 and parameters: {'n_neighbors': 164}. Best is trial 66 with value: 0.4282242711367899.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 00:05:25,341]\u001b[0m Trial 99 finished with value: 0.42393466558561055 and parameters: {'n_neighbors': 270}. Best is trial 66 with value: 0.4282242711367899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.4282242711367899\n",
      "\n",
      "Optimized parameters: {'n_neighbors': 187}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def knn_objective(trial):\n",
    "    params = {'n_neighbors' :trial.suggest_int('n_neighbors', 1, 300)}\n",
    "    \n",
    "    knn = KNeighborsClassifier(**params)\n",
    "    model_smote = Pipeline([('smote', smote), ('knn', knn)])\n",
    "    scores = cross_val_score(\n",
    "        model_smote, X_train, y_train, cv=cv,\n",
    "        scoring=custom_score,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    \n",
    "    #send result to mflow\n",
    "    mlflow_hyperparameter_tuning(experiment_id, params, scores)\n",
    "    return scores.mean()\n",
    "\n",
    "knn_params = udf.tune(knn_objective, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "126e3e4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T23:05:46.881151Z",
     "start_time": "2023-03-09T23:05:44.332250Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-19 {color: black;background-color: white;}#sk-container-id-19 pre{padding: 0;}#sk-container-id-19 div.sk-toggleable {background-color: white;}#sk-container-id-19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-19 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-19 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-19 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-19 div.sk-item {position: relative;z-index: 1;}#sk-container-id-19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-19 div.sk-item::before, #sk-container-id-19 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-19 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-19 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-19 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-19 div.sk-label-container {text-align: center;}#sk-container-id-19 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-19 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;smote&#x27;, SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                (&#x27;model&#x27;, KNeighborsClassifier(n_neighbors=187))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-55\" type=\"checkbox\" ><label for=\"sk-estimator-id-55\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;smote&#x27;, SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                (&#x27;model&#x27;, KNeighborsClassifier(n_neighbors=187))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-56\" type=\"checkbox\" ><label for=\"sk-estimator-id-56\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE(k_neighbors=17, random_state=1001)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-57\" type=\"checkbox\" ><label for=\"sk-estimator-id-57\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=187)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('smote', SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                ('model', KNeighborsClassifier(n_neighbors=187))])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#knn_params = {'n_neighbors': 10}\n",
    "knn_optimized = construct_model(knn, knn_params)\n",
    "knn_optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cf0e833d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T23:06:14.105180Z",
     "start_time": "2023-03-09T23:06:03.900004Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.43 et le mean score est : 0.528\n",
      "Accuracy score : 0.626171\n",
      "f3_score : 0.430127 \n",
      "\n",
      "Mean evalation score : 0.528149\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model_evaluation(knn_optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6566cb6",
   "metadata": {},
   "source": [
    "## RandomforestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2adde500",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T20:09:22.948666Z",
     "start_time": "2023-03-22T20:09:22.742105Z"
    }
   },
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_jobs=-1)\n",
    "forest_smote = Pipeline([('smote', smote), ('model', forest)])\n",
    "#forest_smote.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "61f2b676",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-15T21:00:36.008440Z",
     "start_time": "2023-03-15T21:00:35.503418Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pour le seuil 0.2, le f3_score est : 0.485 et le mean score est : 0.567\n"
     ]
    }
   ],
   "source": [
    "y_pred = forest_smote.predict_proba(X_test)[:,1]\n",
    "threshold_f3 = custom_metric(y_test, y_pred, return_proba=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c75371a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-15T21:00:37.910977Z",
     "start_time": "2023-03-15T21:00:37.200772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.648283\n",
      "f3_score : 0.484992 \n",
      "\n",
      "Mean evalation score : 0.566637\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(forest_smote, X_test, y_test, threshold_f3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39f4bda",
   "metadata": {},
   "source": [
    "### Optimisation & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "bce805c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-15T21:00:58.283817Z",
     "start_time": "2023-03-15T21:00:58.051855Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'560907910543854535'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_id = dict(mlflow.set_experiment(\"Random forest Hyperparameter Tuning\"))['experiment_id']\n",
    "experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ed2ff8f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-16T12:24:36.481078Z",
     "start_time": "2023-03-15T21:16:48.499053Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-15 22:16:49,192]\u001b[0m A new study created in memory with name: Hyperparameters optimization\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 22:37:26,121]\u001b[0m Trial 0 finished with value: 0.4994731836761683 and parameters: {'n_estimators': 1980, 'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 0 with value: 0.4994731836761683.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 22:52:02,481]\u001b[0m Trial 1 finished with value: 0.5079081012071365 and parameters: {'n_estimators': 1701, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 1 with value: 0.5079081012071365.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 23:05:21,068]\u001b[0m Trial 2 finished with value: 0.48678875750706324 and parameters: {'n_estimators': 1485, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 1 with value: 0.5079081012071365.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 23:11:51,099]\u001b[0m Trial 3 finished with value: 0.38086833081670735 and parameters: {'n_estimators': 1280, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 1 with value: 0.5079081012071365.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 23:18:55,351]\u001b[0m Trial 4 finished with value: 0.38659477020629907 and parameters: {'n_estimators': 1400, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 1 with value: 0.5079081012071365.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 23:24:20,267]\u001b[0m Trial 5 finished with value: 0.498939616691639 and parameters: {'n_estimators': 718, 'max_depth': 110, 'min_samples_split': 5, 'min_samples_leaf': 6, 'bootstrap': True}. Best is trial 1 with value: 0.5079081012071365.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 23:33:08,641]\u001b[0m Trial 6 finished with value: 0.4985949149855745 and parameters: {'n_estimators': 1143, 'max_depth': 80, 'min_samples_split': 3, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 1 with value: 0.5079081012071365.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 23:42:08,455]\u001b[0m Trial 7 finished with value: 0.492685334851698 and parameters: {'n_estimators': 1134, 'max_depth': 60, 'min_samples_split': 9, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 1 with value: 0.5079081012071365.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 23:50:27,498]\u001b[0m Trial 8 finished with value: 0.5049098751380502 and parameters: {'n_estimators': 1163, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 8, 'bootstrap': True}. Best is trial 1 with value: 0.5079081012071365.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 23:55:33,150]\u001b[0m Trial 9 finished with value: 0.4861336098901957 and parameters: {'n_estimators': 439, 'max_depth': 90, 'min_samples_split': 3, 'min_samples_leaf': 8, 'bootstrap': False}. Best is trial 1 with value: 0.5079081012071365.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 00:16:53,146]\u001b[0m Trial 10 finished with value: 0.49145559363271396 and parameters: {'n_estimators': 1947, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 10, 'bootstrap': False}. Best is trial 1 with value: 0.5079081012071365.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 00:35:28,522]\u001b[0m Trial 11 finished with value: 0.4829400404126794 and parameters: {'n_estimators': 1659, 'max_depth': 40, 'min_samples_split': 5, 'min_samples_leaf': 8, 'bootstrap': False}. Best is trial 1 with value: 0.5079081012071365.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 00:41:29,608]\u001b[0m Trial 12 finished with value: 0.5058069704005205 and parameters: {'n_estimators': 826, 'max_depth': 80, 'min_samples_split': 6, 'min_samples_leaf': 8, 'bootstrap': True}. Best is trial 1 with value: 0.5079081012071365.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 00:47:01,842]\u001b[0m Trial 13 finished with value: 0.501820025282362 and parameters: {'n_estimators': 761, 'max_depth': 70, 'min_samples_split': 7, 'min_samples_leaf': 7, 'bootstrap': True}. Best is trial 1 with value: 0.5079081012071365.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 00:53:11,276]\u001b[0m Trial 14 finished with value: 0.5068429256869063 and parameters: {'n_estimators': 866, 'max_depth': 70, 'min_samples_split': 8, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 1 with value: 0.5079081012071365.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 00:56:07,064]\u001b[0m Trial 15 finished with value: 0.4932642780901372 and parameters: {'n_estimators': 265, 'max_depth': 50, 'min_samples_split': 9, 'min_samples_leaf': 10, 'bootstrap': False}. Best is trial 1 with value: 0.5079081012071365.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 01:07:58,481]\u001b[0m Trial 16 finished with value: 0.5015603445160075 and parameters: {'n_estimators': 1628, 'max_depth': 60, 'min_samples_split': 8, 'min_samples_leaf': 6, 'bootstrap': True}. Best is trial 1 with value: 0.5079081012071365.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 01:13:54,468]\u001b[0m Trial 17 finished with value: 0.5062478990170215 and parameters: {'n_estimators': 843, 'max_depth': 40, 'min_samples_split': 4, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 1 with value: 0.5079081012071365.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 01:25:18,003]\u001b[0m Trial 18 finished with value: 0.4731618880920859 and parameters: {'n_estimators': 980, 'max_depth': 70, 'min_samples_split': 8, 'min_samples_leaf': 6, 'bootstrap': False}. Best is trial 1 with value: 0.5079081012071365.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 01:37:47,840]\u001b[0m Trial 19 finished with value: 0.5089824636915452 and parameters: {'n_estimators': 1791, 'max_depth': 60, 'min_samples_split': 6, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 19 with value: 0.5089824636915452.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 01:50:28,900]\u001b[0m Trial 20 finished with value: 0.5092754180231764 and parameters: {'n_estimators': 1810, 'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 20 with value: 0.5092754180231764.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 02:02:47,107]\u001b[0m Trial 21 finished with value: 0.5091703755824581 and parameters: {'n_estimators': 1782, 'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 20 with value: 0.5092754180231764.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 02:15:56,623]\u001b[0m Trial 22 finished with value: 0.5059119564760591 and parameters: {'n_estimators': 1834, 'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 7, 'bootstrap': True}. Best is trial 20 with value: 0.5092754180231764.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 02:28:32,453]\u001b[0m Trial 23 finished with value: 0.5088244907824563 and parameters: {'n_estimators': 1781, 'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 20 with value: 0.5092754180231764.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 02:38:56,001]\u001b[0m Trial 24 finished with value: 0.5026887991359204 and parameters: {'n_estimators': 1512, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 7, 'bootstrap': True}. Best is trial 20 with value: 0.5092754180231764.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 02:51:47,576]\u001b[0m Trial 25 finished with value: 0.5086415775088137 and parameters: {'n_estimators': 1865, 'max_depth': 40, 'min_samples_split': 4, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 20 with value: 0.5092754180231764.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 03:02:07,220]\u001b[0m Trial 26 finished with value: 0.5084693580556594 and parameters: {'n_estimators': 1546, 'max_depth': 20, 'min_samples_split': 7, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 20 with value: 0.5092754180231764.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 03:17:20,242]\u001b[0m Trial 27 finished with value: 0.47873244493241074 and parameters: {'n_estimators': 1333, 'max_depth': 60, 'min_samples_split': 4, 'min_samples_leaf': 7, 'bootstrap': False}. Best is trial 20 with value: 0.5092754180231764.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 03:29:48,489]\u001b[0m Trial 28 finished with value: 0.507198542796654 and parameters: {'n_estimators': 1784, 'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 8, 'bootstrap': True}. Best is trial 20 with value: 0.5092754180231764.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 03:45:01,243]\u001b[0m Trial 29 finished with value: 0.502075333269974 and parameters: {'n_estimators': 1967, 'max_depth': 40, 'min_samples_split': 7, 'min_samples_leaf': 5, 'bootstrap': True}. Best is trial 20 with value: 0.5092754180231764.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 03:58:54,409]\u001b[0m Trial 30 finished with value: 0.5102124522288979 and parameters: {'n_estimators': 1949, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 30 with value: 0.5102124522288979.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-16 04:12:11,104]\u001b[0m Trial 31 finished with value: 0.5091095157382651 and parameters: {'n_estimators': 1998, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 30 with value: 0.5102124522288979.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 04:21:53,423]\u001b[0m Trial 32 finished with value: 0.38688776107396927 and parameters: {'n_estimators': 1999, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 30 with value: 0.5102124522288979.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 04:33:01,066]\u001b[0m Trial 33 finished with value: 0.5109413888108685 and parameters: {'n_estimators': 1684, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 04:44:00,827]\u001b[0m Trial 34 finished with value: 0.5082543420883432 and parameters: {'n_estimators': 1676, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 04:51:30,436]\u001b[0m Trial 35 finished with value: 0.3859738414787421 and parameters: {'n_estimators': 1562, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 05:01:22,506]\u001b[0m Trial 36 finished with value: 0.5089479735656024 and parameters: {'n_estimators': 1427, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 05:10:21,692]\u001b[0m Trial 37 finished with value: 0.38623703552058497 and parameters: {'n_estimators': 1891, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 05:21:49,101]\u001b[0m Trial 38 finished with value: 0.5073937223075012 and parameters: {'n_estimators': 1737, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 05:33:06,254]\u001b[0m Trial 39 finished with value: 0.5067134923753289 and parameters: {'n_estimators': 1595, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 8, 'bootstrap': True}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 05:44:48,389]\u001b[0m Trial 40 finished with value: 0.509061276298939 and parameters: {'n_estimators': 1713, 'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 05:57:17,560]\u001b[0m Trial 41 finished with value: 0.5097915212495332 and parameters: {'n_estimators': 1910, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 06:06:24,168]\u001b[0m Trial 42 finished with value: 0.3867148061154989 and parameters: {'n_estimators': 1883, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 06:19:05,952]\u001b[0m Trial 43 finished with value: 0.508736087079817 and parameters: {'n_estimators': 1896, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 06:30:55,763]\u001b[0m Trial 44 finished with value: 0.509655071451647 and parameters: {'n_estimators': 1725, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 06:46:15,445]\u001b[0m Trial 45 finished with value: 0.440099817596593 and parameters: {'n_estimators': 1237, 'max_depth': 40, 'min_samples_split': 5, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 06:50:14,080]\u001b[0m Trial 46 finished with value: 0.5093664765574805 and parameters: {'n_estimators': 604, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 06:52:36,907]\u001b[0m Trial 47 finished with value: 0.3908992706041075 and parameters: {'n_estimators': 474, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 06:59:51,336]\u001b[0m Trial 48 finished with value: 0.4911727872654339 and parameters: {'n_estimators': 1003, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 07:17:34,741]\u001b[0m Trial 49 finished with value: 0.46218973314899703 and parameters: {'n_estimators': 1463, 'max_depth': 110, 'min_samples_split': 4, 'min_samples_leaf': 4, 'bootstrap': False}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 07:20:33,786]\u001b[0m Trial 50 finished with value: 0.3899549489570999 and parameters: {'n_estimators': 566, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 07:24:37,297]\u001b[0m Trial 51 finished with value: 0.5083839409633303 and parameters: {'n_estimators': 616, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 07:26:17,908]\u001b[0m Trial 52 finished with value: 0.5061795068060565 and parameters: {'n_estimators': 241, 'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 07:38:15,597]\u001b[0m Trial 53 finished with value: 0.506919680561392 and parameters: {'n_estimators': 1666, 'max_depth': 40, 'min_samples_split': 7, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 07:50:37,801]\u001b[0m Trial 54 finished with value: 0.5089645880540549 and parameters: {'n_estimators': 1825, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 08:03:44,830]\u001b[0m Trial 55 finished with value: 0.5064552876907263 and parameters: {'n_estimators': 1939, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 8, 'bootstrap': True}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 08:15:45,092]\u001b[0m Trial 56 finished with value: 0.5098296174073037 and parameters: {'n_estimators': 1747, 'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 08:22:28,708]\u001b[0m Trial 57 finished with value: 0.38528135909248673 and parameters: {'n_estimators': 1368, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 08:40:45,623]\u001b[0m Trial 58 finished with value: 0.48785227228663475 and parameters: {'n_estimators': 1742, 'max_depth': 20, 'min_samples_split': 10, 'min_samples_leaf': 9, 'bootstrap': False}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 08:55:47,514]\u001b[0m Trial 59 finished with value: 0.5077363937588458 and parameters: {'n_estimators': 1617, 'max_depth': 40, 'min_samples_split': 7, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 09:04:40,574]\u001b[0m Trial 60 finished with value: 0.5103324529238664 and parameters: {'n_estimators': 1212, 'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 09:12:14,811]\u001b[0m Trial 61 finished with value: 0.5108642364069113 and parameters: {'n_estimators': 1043, 'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 09:19:33,361]\u001b[0m Trial 62 finished with value: 0.5100844641655061 and parameters: {'n_estimators': 1021, 'max_depth': 30, 'min_samples_split': 9, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-16 09:27:17,796]\u001b[0m Trial 63 finished with value: 0.5097595906190076 and parameters: {'n_estimators': 1069, 'max_depth': 50, 'min_samples_split': 9, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 09:36:42,980]\u001b[0m Trial 64 finished with value: 0.5004483114810736 and parameters: {'n_estimators': 1202, 'max_depth': 30, 'min_samples_split': 8, 'min_samples_leaf': 5, 'bootstrap': True}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 09:43:12,164]\u001b[0m Trial 65 finished with value: 0.508335569059112 and parameters: {'n_estimators': 924, 'max_depth': 90, 'min_samples_split': 8, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 09:50:56,578]\u001b[0m Trial 66 finished with value: 0.5078994125047203 and parameters: {'n_estimators': 1073, 'max_depth': 40, 'min_samples_split': 9, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 09:56:33,469]\u001b[0m Trial 67 finished with value: 0.5092550359142785 and parameters: {'n_estimators': 788, 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 10:09:19,534]\u001b[0m Trial 68 finished with value: 0.4847956306668362 and parameters: {'n_estimators': 1111, 'max_depth': 50, 'min_samples_split': 8, 'min_samples_leaf': 9, 'bootstrap': False}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 10:15:52,553]\u001b[0m Trial 69 finished with value: 0.508760733905819 and parameters: {'n_estimators': 918, 'max_depth': 20, 'min_samples_split': 7, 'min_samples_leaf': 8, 'bootstrap': True}. Best is trial 33 with value: 0.5109413888108685.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 10:23:25,805]\u001b[0m Trial 70 finished with value: 0.5112689828613983 and parameters: {'n_estimators': 1032, 'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 70 with value: 0.5112689828613983.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 10:30:42,911]\u001b[0m Trial 71 finished with value: 0.5098733777373109 and parameters: {'n_estimators': 1014, 'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 70 with value: 0.5112689828613983.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 10:38:13,493]\u001b[0m Trial 72 finished with value: 0.5079855543920762 and parameters: {'n_estimators': 1001, 'max_depth': 40, 'min_samples_split': 7, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 70 with value: 0.5112689828613983.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 10:46:32,197]\u001b[0m Trial 73 finished with value: 0.5090974650090303 and parameters: {'n_estimators': 1155, 'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 70 with value: 0.5112689828613983.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 10:55:45,292]\u001b[0m Trial 74 finished with value: 0.5087939467687141 and parameters: {'n_estimators': 1294, 'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 70 with value: 0.5112689828613983.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 11:02:15,110]\u001b[0m Trial 75 finished with value: 0.5091692525219831 and parameters: {'n_estimators': 905, 'max_depth': 40, 'min_samples_split': 8, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 70 with value: 0.5112689828613983.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 11:10:02,003]\u001b[0m Trial 76 finished with value: 0.5087111375702664 and parameters: {'n_estimators': 1039, 'max_depth': 30, 'min_samples_split': 9, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 70 with value: 0.5112689828613983.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 11:15:32,051]\u001b[0m Trial 77 finished with value: 0.5056235140013217 and parameters: {'n_estimators': 726, 'max_depth': 50, 'min_samples_split': 7, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 70 with value: 0.5112689828613983.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 11:22:28,766]\u001b[0m Trial 78 finished with value: 0.5090214183004269 and parameters: {'n_estimators': 974, 'max_depth': 30, 'min_samples_split': 8, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 70 with value: 0.5112689828613983.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 11:31:23,287]\u001b[0m Trial 79 finished with value: 0.5070185404599152 and parameters: {'n_estimators': 1219, 'max_depth': 40, 'min_samples_split': 7, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 70 with value: 0.5112689828613983.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 11:37:18,557]\u001b[0m Trial 80 finished with value: 0.5120098146934623 and parameters: {'n_estimators': 866, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 80 with value: 0.5120098146934623.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 11:42:56,627]\u001b[0m Trial 81 finished with value: 0.511022603853158 and parameters: {'n_estimators': 806, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 80 with value: 0.5120098146934623.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 11:48:35,282]\u001b[0m Trial 82 finished with value: 0.5117536696583826 and parameters: {'n_estimators': 823, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 80 with value: 0.5120098146934623.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 11:54:29,199]\u001b[0m Trial 83 finished with value: 0.5122177494775698 and parameters: {'n_estimators': 856, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 83 with value: 0.5122177494775698.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 11:58:30,523]\u001b[0m Trial 84 finished with value: 0.38153186205689676 and parameters: {'n_estimators': 790, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 83 with value: 0.5122177494775698.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:03:09,999]\u001b[0m Trial 85 finished with value: 0.5104384241660778 and parameters: {'n_estimators': 679, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 83 with value: 0.5122177494775698.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:08:17,503]\u001b[0m Trial 86 finished with value: 0.5034590925308673 and parameters: {'n_estimators': 665, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 5, 'bootstrap': True}. Best is trial 83 with value: 0.5122177494775698.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:14:54,111]\u001b[0m Trial 87 finished with value: 0.3726986483363199 and parameters: {'n_estimators': 833, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 10, 'bootstrap': False}. Best is trial 83 with value: 0.5122177494775698.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:19:52,922]\u001b[0m Trial 88 finished with value: 0.5045117099432184 and parameters: {'n_estimators': 701, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 83 with value: 0.5122177494775698.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:26:01,261]\u001b[0m Trial 89 finished with value: 0.5129666200333695 and parameters: {'n_estimators': 882, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 89 with value: 0.5129666200333695.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:30:27,112]\u001b[0m Trial 90 finished with value: 0.3851418957863862 and parameters: {'n_estimators': 875, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 89 with value: 0.5129666200333695.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:36:55,199]\u001b[0m Trial 91 finished with value: 0.5114523089132221 and parameters: {'n_estimators': 950, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 89 with value: 0.5129666200333695.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:43:49,759]\u001b[0m Trial 92 finished with value: 0.5120805684453805 and parameters: {'n_estimators': 962, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 89 with value: 0.5129666200333695.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:50:41,365]\u001b[0m Trial 93 finished with value: 0.511982584828264 and parameters: {'n_estimators': 960, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 89 with value: 0.5129666200333695.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:56:01,395]\u001b[0m Trial 94 finished with value: 0.510982998147646 and parameters: {'n_estimators': 768, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 89 with value: 0.5129666200333695.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-16 13:02:44,306]\u001b[0m Trial 95 finished with value: 0.5120884900099126 and parameters: {'n_estimators': 940, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 89 with value: 0.5129666200333695.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 13:07:38,473]\u001b[0m Trial 96 finished with value: 0.383090566635086 and parameters: {'n_estimators': 955, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 89 with value: 0.5129666200333695.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 13:13:29,017]\u001b[0m Trial 97 finished with value: 0.5123965146271204 and parameters: {'n_estimators': 859, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 89 with value: 0.5129666200333695.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 13:17:56,317]\u001b[0m Trial 98 finished with value: 0.3845791478673067 and parameters: {'n_estimators': 868, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 89 with value: 0.5129666200333695.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 13:24:36,242]\u001b[0m Trial 99 finished with value: 0.5113514483282413 and parameters: {'n_estimators': 949, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 89 with value: 0.5129666200333695.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.5129666200333695\n",
      "\n",
      "Optimized parameters: {'n_estimators': 882, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 10, 'bootstrap': True}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def randomforest_objective(trial):\n",
    "    \n",
    "    params = {# Number of trees in random forest\n",
    "    'n_estimators': trial.suggest_int(\"n_estimators\", 200, 2000),\n",
    "    # Maximum number of levels in tree\n",
    "    'max_depth': trial.suggest_int(\"max_depth\", 10, 110, step=10),\n",
    "    # Minimum number of samples required to split a node\n",
    "    'min_samples_split': trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    'min_samples_leaf': trial.suggest_int(\"min_samples_leaf\", 2, 10),\n",
    "    # Number of features to consider at every split\n",
    "    #'max_features': trial.suggest_int(\"max_features\", 10, 211),\n",
    "    # Method of selecting samples for training each tree\n",
    "    'bootstrap': trial.suggest_categorical(\"bootstrap\", [True, False])\n",
    "    }\n",
    "\n",
    "    clf = RandomForestClassifier( \n",
    "        **params, n_jobs=-1, random_state=42,\n",
    "    )\n",
    "\n",
    "    forest_smote = Pipeline([('smote', smote), ('model', clf)])\n",
    "    scores = cross_val_score(\n",
    "        forest_smote, X_train, y_train, cv=cv,\n",
    "        scoring=custom_score,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    \n",
    "    #send results to mlflow\n",
    "    mlflow_hyperparameter_tuning(experiment_id, params, scores)\n",
    "    \n",
    "    return scores.mean()\n",
    "\n",
    "randomforest_params = udf.tune(randomforest_objective, 100)\n",
    "#forest_optimized = RandomForestClassifier(n_jobs=-1, random_state=42, **randomforest_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8086aa1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T21:07:57.132935Z",
     "start_time": "2023-03-22T20:09:52.481380Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;smote&#x27;, SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 RandomForestClassifier(max_depth=20, min_samples_leaf=10,\n",
       "                                        min_samples_split=6, n_estimators=882,\n",
       "                                        n_jobs=-1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;smote&#x27;, SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 RandomForestClassifier(max_depth=20, min_samples_leaf=10,\n",
       "                                        min_samples_split=6, n_estimators=882,\n",
       "                                        n_jobs=-1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE(k_neighbors=17, random_state=1001)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=20, min_samples_leaf=10, min_samples_split=6,\n",
       "                       n_estimators=882, n_jobs=-1)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('smote', SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                ('model',\n",
       "                 RandomForestClassifier(max_depth=20, min_samples_leaf=10,\n",
       "                                        min_samples_split=6, n_estimators=882,\n",
       "                                        n_jobs=-1))])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#randomforest_params = {'n_estimators': 690, 'max_depth': 90, 'min_samples_split': 3, 'min_samples_leaf': 7, 'bootstrap': True}\n",
    "#randomforest_params = {'random_state': 42, 'n_estimators': 633, 'max_depth': 20, 'max_features': 13, 'min_samples_split': 3, 'min_samples_leaf':7, 'bootstrap':True}\n",
    "randomforest_params = {'n_estimators': 882, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 10, 'bootstrap': True}\n",
    "randomforest_optimized = construct_model(forest, randomforest_params)\n",
    "randomforest_optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b19d7852",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T21:15:52.127590Z",
     "start_time": "2023-03-22T21:15:33.229704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pour le seuil 0.2, le f3_score est : 0.529 et le mean score est : 0.586\n",
      "Accuracy score : 0.642494\n",
      "f3_score : 0.528968 \n",
      "\n",
      "Mean evalation score : 0.585731\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model_evaluation(randomforest_optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1c5524f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T21:18:45.034776Z",
     "start_time": "2023-03-22T21:18:41.196806Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(randomforest_optimized, open(Path(PROJECT_ROOT + '/model_and_data/model.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "be19eb1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-16T19:00:23.452913Z",
     "start_time": "2023-03-16T19:00:20.014568Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pour le seuil 0.2, le f3_score est : 0.535 et le mean score est : 0.544\n",
      "Accuracy score : 0.553070\n",
      "f3_score : 0.535242 \n",
      "\n",
      "Mean evalation score : 0.544156\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model_evaluation(randomforest_optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2808d25",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ff68fea7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T23:11:41.517177Z",
     "start_time": "2023-03-09T23:11:41.433109Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "38db9493",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T23:12:13.284949Z",
     "start_time": "2023-03-09T23:11:44.550513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-22 {color: black;background-color: white;}#sk-container-id-22 pre{padding: 0;}#sk-container-id-22 div.sk-toggleable {background-color: white;}#sk-container-id-22 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-22 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-22 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-22 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-22 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-22 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-22 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-22 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-22 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-22 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-22 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-22 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-22 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-22 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-22 div.sk-item {position: relative;z-index: 1;}#sk-container-id-22 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-22 div.sk-item::before, #sk-container-id-22 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-22 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-22 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-22 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-22 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-22 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-22 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-22 div.sk-label-container {text-align: center;}#sk-container-id-22 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-22 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-22\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;smote&#x27;, SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                (&#x27;model&#x27;, LogisticRegression(n_jobs=-1, random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-64\" type=\"checkbox\" ><label for=\"sk-estimator-id-64\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;smote&#x27;, SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                (&#x27;model&#x27;, LogisticRegression(n_jobs=-1, random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-65\" type=\"checkbox\" ><label for=\"sk-estimator-id-65\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE(k_neighbors=17, random_state=1001)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-66\" type=\"checkbox\" ><label for=\"sk-estimator-id-66\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(n_jobs=-1, random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('smote', SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                ('model', LogisticRegression(n_jobs=-1, random_state=42))])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression = LogisticRegression(random_state=42, n_jobs = -1)\n",
    "logistic_regression_smote = Pipeline([('smote', smote), ('model', logistic_regression)])\n",
    "logistic_regression_smote.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "70609e5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T23:12:22.512072Z",
     "start_time": "2023-03-09T23:12:22.218322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pour le seuil 0.35, le f3_score est : 0.421 et le mean score est : 0.578\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = logistic_regression_smote.predict_proba(X_test)[:,1]\n",
    "threshold_f3 = custom_metric(y_test, y_pred_proba, return_proba=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0e757334",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T23:12:25.530280Z",
     "start_time": "2023-03-09T23:12:25.250037Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.735172\n",
      "f3_score : 0.420976 \n",
      "\n",
      "Mean evalation score : 0.578074\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(logistic_regression, X_test, y_test, threshold_f3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87556eb8",
   "metadata": {},
   "source": [
    "### Optimisation & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "76eab59d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T08:02:00.707587Z",
     "start_time": "2023-03-10T08:01:59.957333Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/03/10 09:02:00 INFO mlflow.tracking.fluent: Experiment with name 'Logistic Regression(1) Hyperparameter Tuning' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'153487527092994202'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_id = dict(mlflow.set_experiment(\"Logistic Regression(1) Hyperparameter Tuning\"))['experiment_id']\n",
    "experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "5efbd974",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T16:24:35.069003Z",
     "start_time": "2023-03-03T16:24:34.978504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///Users/kone/Desktop/Oc_Formation/Projets/Projet7/openclassrooms_projects7/mlruns'"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracking_uri = mlflow.get_tracking_uri()\n",
    "tracking_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "6407f6d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T15:15:38.475215Z",
     "start_time": "2023-03-03T15:15:37.842586Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kone/Desktop/Oc_Formation/Projets/Projet7/openclassrooms_projects7'"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROJECT_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c25f93e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T08:26:10.320036Z",
     "start_time": "2023-03-10T08:04:02.187599Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-10 09:04:02,294]\u001b[0m A new study created in memory with name: Hyperparameters optimization\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:04:27,553]\u001b[0m Trial 0 finished with value: 0.48679030538668383 and parameters: {'tol': 0.0006053210318339322, 'C': 2.588971334664364e-05, 'penalty': 'l2'}. Best is trial 0 with value: 0.48679030538668383.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:04:35,249]\u001b[0m Trial 1 finished with value: 0.5006433490036858 and parameters: {'tol': 0.0009286932616491065, 'C': 1.5977683192025823e-10, 'penalty': 'l2'}. Best is trial 1 with value: 0.5006433490036858.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:04:43,003]\u001b[0m Trial 2 finished with value: 0.0 and parameters: {'tol': 0.0007466072735738306, 'C': 1.7919669679581004e-05, 'penalty': 'l1'}. Best is trial 1 with value: 0.5006433490036858.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:04:50,663]\u001b[0m Trial 3 finished with value: 0.0 and parameters: {'tol': 0.0006562246904114321, 'C': 1.5552480524189524e-06, 'penalty': 'l1'}. Best is trial 1 with value: 0.5006433490036858.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:04:56,474]\u001b[0m Trial 4 finished with value: 0.5006433490036858 and parameters: {'tol': 0.000885964022139065, 'C': 1.0583652448264016e-09, 'penalty': 'l2'}. Best is trial 1 with value: 0.5006433490036858.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:05:08,355]\u001b[0m Trial 5 finished with value: 0.4189170423587716 and parameters: {'tol': 0.00044249482327467194, 'C': 0.00025491110540892847, 'penalty': 'l1'}. Best is trial 1 with value: 0.5006433490036858.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:05:18,585]\u001b[0m Trial 6 finished with value: 0.0 and parameters: {'tol': 0.000493440224508456, 'C': 0.00016513805043173548, 'penalty': 'l1'}. Best is trial 1 with value: 0.5006433490036858.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:06:32,397]\u001b[0m Trial 7 finished with value: 0.49058151278520085 and parameters: {'tol': 0.0006885698990775395, 'C': 0.007510847204083808, 'penalty': 'l1'}. Best is trial 1 with value: 0.5006433490036858.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:06:37,680]\u001b[0m Trial 8 finished with value: 0.5006597897348499 and parameters: {'tol': 0.0007678741576292011, 'C': 6.281573081617586e-09, 'penalty': 'l2'}. Best is trial 8 with value: 0.5006597897348499.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:06:42,953]\u001b[0m Trial 9 finished with value: 0.0 and parameters: {'tol': 0.0006237566605915097, 'C': 7.337074733194364e-09, 'penalty': 'l1'}. Best is trial 8 with value: 0.5006597897348499.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:06:47,259]\u001b[0m Trial 10 finished with value: 0.5007787392631109 and parameters: {'tol': 0.00024318617383420885, 'C': 6.002189585973118e-08, 'penalty': 'l2'}. Best is trial 10 with value: 0.5007787392631109.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:06:51,886]\u001b[0m Trial 11 finished with value: 0.500796996639121 and parameters: {'tol': 0.00018370277141880513, 'C': 6.485802904697198e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:06:57,371]\u001b[0m Trial 12 finished with value: 0.46540548248029945 and parameters: {'tol': 0.00018394003540894125, 'C': 1.693301457800959e-07, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:07:03,397]\u001b[0m Trial 13 finished with value: 0.46641564713642925 and parameters: {'tol': 5.377338915670151e-05, 'C': 3.9234414435723914e-07, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:07:07,792]\u001b[0m Trial 14 finished with value: 0.500694487153105 and parameters: {'tol': 0.0002745170493087876, 'C': 3.069677957111432e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:07:11,878]\u001b[0m Trial 15 finished with value: 0.49965212243550744 and parameters: {'tol': 0.00033267331000394213, 'C': 9.718723928976031e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:07:22,529]\u001b[0m Trial 16 finished with value: 0.4371789637390485 and parameters: {'tol': 1.5007737855655251e-05, 'C': 0.5817612125356832, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:07:28,185]\u001b[0m Trial 17 finished with value: 0.46614041559881336 and parameters: {'tol': 0.00016910158910150806, 'C': 1.456461290126514e-06, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:07:34,951]\u001b[0m Trial 18 finished with value: 0.5006433490036858 and parameters: {'tol': 0.0003630881471270877, 'C': 2.2471489859403305e-10, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:07:40,904]\u001b[0m Trial 19 finished with value: 0.5006597897348499 and parameters: {'tol': 0.00011375735868765152, 'C': 1.5715682653847706e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:07:46,893]\u001b[0m Trial 20 finished with value: 0.5006433490036858 and parameters: {'tol': 0.00024064834519723182, 'C': 1.339128820400068e-09, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:07:52,842]\u001b[0m Trial 21 finished with value: 0.5007449180911484 and parameters: {'tol': 0.00027113214201657406, 'C': 4.9635276141354846e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:07:58,722]\u001b[0m Trial 22 finished with value: 0.5004882505122717 and parameters: {'tol': 0.00012625405883823877, 'C': 6.87196468148956e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:08:05,246]\u001b[0m Trial 23 finished with value: 0.4652928036502291 and parameters: {'tol': 0.000265904197868095, 'C': 9.528564481188916e-07, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:08:11,363]\u001b[0m Trial 24 finished with value: 0.500694487153105 and parameters: {'tol': 0.00039686908255272914, 'C': 3.5694046175651694e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:08:16,680]\u001b[0m Trial 25 finished with value: 0.5006597897348499 and parameters: {'tol': 0.0003116183858759653, 'C': 3.6694544301492454e-09, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:08:23,139]\u001b[0m Trial 26 finished with value: 0.4659346155295787 and parameters: {'tol': 0.00019727826113444708, 'C': 2.721907932161736e-07, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:08:27,772]\u001b[0m Trial 27 finished with value: 0.500694487153105 and parameters: {'tol': 0.0004011307034870023, 'C': 2.5043205508906497e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:08:32,832]\u001b[0m Trial 28 finished with value: 0.4719446190239413 and parameters: {'tol': 8.24191715285766e-05, 'C': 3.5644331418059366e-06, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:08:38,026]\u001b[0m Trial 29 finished with value: 0.4751582738280489 and parameters: {'tol': 0.0005236769614106714, 'C': 5.064452571165909e-06, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:08:42,948]\u001b[0m Trial 30 finished with value: 0.4654377678206695 and parameters: {'tol': 0.00022117424269124707, 'C': 1.7933151539557703e-07, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:08:47,182]\u001b[0m Trial 31 finished with value: 0.5007622815652489 and parameters: {'tol': 0.0002855762171392894, 'C': 5.4384392998821865e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:08:52,688]\u001b[0m Trial 32 finished with value: 0.4664347716445437 and parameters: {'tol': 0.0002840952421869202, 'C': 3.5940118256078415e-07, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:08:57,309]\u001b[0m Trial 33 finished with value: 0.5007622815652489 and parameters: {'tol': 0.00013931911089089456, 'C': 5.252460361697001e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:09:01,527]\u001b[0m Trial 34 finished with value: 0.5006597897348499 and parameters: {'tol': 0.00014190873172827926, 'C': 8.63143530421304e-09, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:09:05,787]\u001b[0m Trial 35 finished with value: 0.0 and parameters: {'tol': 1.1690137534683124e-05, 'C': 1.624897519665583e-09, 'penalty': 'l1'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-10 09:09:10,454]\u001b[0m Trial 36 finished with value: 0.4660709156227038 and parameters: {'tol': 0.00019786898777252645, 'C': 6.660612133529707e-07, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:09:15,129]\u001b[0m Trial 37 finished with value: 0.0 and parameters: {'tol': 8.484843499870035e-05, 'C': 2.439954915295275e-10, 'penalty': 'l1'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:09:19,692]\u001b[0m Trial 38 finished with value: 0.4995999556078067 and parameters: {'tol': 0.00014643278760771534, 'C': 9.066915155093566e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:09:23,914]\u001b[0m Trial 39 finished with value: 0.0 and parameters: {'tol': 0.0003401132706648693, 'C': 1.284170872212576e-05, 'penalty': 'l1'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:09:28,066]\u001b[0m Trial 40 finished with value: 0.5006597897348499 and parameters: {'tol': 0.00022469313673053584, 'C': 1.200879877986649e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:09:32,906]\u001b[0m Trial 41 finished with value: 0.5007622815652489 and parameters: {'tol': 0.00028831963390518506, 'C': 5.555875244974657e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:09:37,943]\u001b[0m Trial 42 finished with value: 0.475492765770926 and parameters: {'tol': 0.0003040116406672692, 'C': 1.05321102861237e-07, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:09:41,789]\u001b[0m Trial 43 finished with value: 0.5006597897348499 and parameters: {'tol': 0.00017696867331300328, 'C': 4.281617412744957e-09, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:09:46,832]\u001b[0m Trial 44 finished with value: 0.4656783351812253 and parameters: {'tol': 0.00022837024002214133, 'C': 1.2955352059958603e-06, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:09:51,324]\u001b[0m Trial 45 finished with value: 0.5006597897348499 and parameters: {'tol': 0.00011287729168970112, 'C': 1.4955582788599844e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:09:55,874]\u001b[0m Trial 46 finished with value: 0.4663639184614209 and parameters: {'tol': 0.0004586355700905517, 'C': 3.1507160121808246e-07, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:10:00,460]\u001b[0m Trial 47 finished with value: 0.0 and parameters: {'tol': 0.0002563852935847477, 'C': 3.915140301800355e-09, 'penalty': 'l1'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:10:05,661]\u001b[0m Trial 48 finished with value: 0.5007279257524541 and parameters: {'tol': 5.5362726857518757e-05, 'C': 4.1718226233635837e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:10:10,264]\u001b[0m Trial 49 finished with value: 0.465336045027389 and parameters: {'tol': 0.00035685593457725266, 'C': 1.3028064874001073e-07, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:10:14,795]\u001b[0m Trial 50 finished with value: 0.0 and parameters: {'tol': 0.00016269703486242152, 'C': 3.370060483864685e-06, 'penalty': 'l1'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:10:19,406]\u001b[0m Trial 51 finished with value: 0.5007787392631109 and parameters: {'tol': 0.0002816733959545495, 'C': 5.97520905464251e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:10:23,711]\u001b[0m Trial 52 finished with value: 0.500694487153105 and parameters: {'tol': 0.0003121770877572477, 'C': 2.6508872015822574e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:10:30,192]\u001b[0m Trial 53 finished with value: 0.4660704676986544 and parameters: {'tol': 0.00020314192819351234, 'C': 6.207615716618702e-07, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:10:34,859]\u001b[0m Trial 54 finished with value: 0.5007622815652489 and parameters: {'tol': 0.00025217073209825313, 'C': 5.319155659144182e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:10:39,829]\u001b[0m Trial 55 finished with value: 0.5006597897348499 and parameters: {'tol': 0.0002867529875278596, 'C': 1.3430084311324422e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:10:44,295]\u001b[0m Trial 56 finished with value: 0.49965212243550744 and parameters: {'tol': 0.0001560955648474732, 'C': 9.689293458278734e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:10:48,807]\u001b[0m Trial 57 finished with value: 0.46634678806274976 and parameters: {'tol': 0.0003744987117033874, 'C': 3.243575787531767e-07, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:10:54,333]\u001b[0m Trial 58 finished with value: 0.46547184464489205 and parameters: {'tol': 0.0002199847013155462, 'C': 1.8585721164463058e-07, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:11:00,711]\u001b[0m Trial 59 finished with value: 0.5006597897348499 and parameters: {'tol': 0.00033634043473516824, 'C': 2.3287720003857534e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:11:05,539]\u001b[0m Trial 60 finished with value: 0.5006597897348499 and parameters: {'tol': 0.0002988058020336652, 'C': 7.432610067410662e-09, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:11:10,056]\u001b[0m Trial 61 finished with value: 0.5007622815652489 and parameters: {'tol': 0.00023807215183818765, 'C': 5.322520027497768e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:11:16,574]\u001b[0m Trial 62 finished with value: 0.5007279257524541 and parameters: {'tol': 0.00025410014068519163, 'C': 4.221341613846316e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:11:20,958]\u001b[0m Trial 63 finished with value: 0.5004882505122717 and parameters: {'tol': 0.00016869296969906862, 'C': 6.94907578464385e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:11:26,085]\u001b[0m Trial 64 finished with value: 0.46608814779243357 and parameters: {'tol': 0.00025880053130250834, 'C': 6.66637559786329e-07, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:11:29,940]\u001b[0m Trial 65 finished with value: 0.5006433490036858 and parameters: {'tol': 0.00019911522691608313, 'C': 2.376044675368907e-09, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:11:34,270]\u001b[0m Trial 66 finished with value: 0.5006433490036858 and parameters: {'tol': 0.00011098085316095361, 'C': 5.88894906308989e-10, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:11:38,462]\u001b[0m Trial 67 finished with value: 0.5006597897348499 and parameters: {'tol': 0.0003242448095108231, 'C': 7.451315474870478e-09, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:11:43,319]\u001b[0m Trial 68 finished with value: 0.4654377678206695 and parameters: {'tol': 0.0002973768092713262, 'C': 1.7884350517576525e-07, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:11:47,759]\u001b[0m Trial 69 finished with value: 0.5006597897348499 and parameters: {'tol': 0.0003842391109701574, 'C': 1.6297064487630364e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:11:52,519]\u001b[0m Trial 70 finished with value: 0.0 and parameters: {'tol': 0.0002734992428384151, 'C': 3.7000510433341425e-08, 'penalty': 'l1'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:11:57,019]\u001b[0m Trial 71 finished with value: 0.500796996639121 and parameters: {'tol': 0.0002341963489728525, 'C': 6.307958190200156e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-10 09:12:01,923]\u001b[0m Trial 72 finished with value: 0.500796996639121 and parameters: {'tol': 0.00019764360020317894, 'C': 6.54654261909714e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:12:07,773]\u001b[0m Trial 73 finished with value: 0.465336045027389 and parameters: {'tol': 0.00013683675527849514, 'C': 1.365269937336901e-07, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:12:12,536]\u001b[0m Trial 74 finished with value: 0.5006597897348499 and parameters: {'tol': 0.00019645671164690313, 'C': 2.1368109180370192e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:12:17,238]\u001b[0m Trial 75 finished with value: 0.4995300777317415 and parameters: {'tol': 0.000232028109963719, 'C': 8.08391410018162e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:12:21,955]\u001b[0m Trial 76 finished with value: 0.46634678806274976 and parameters: {'tol': 0.0001761921123726373, 'C': 2.903177553794737e-07, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:12:27,518]\u001b[0m Trial 77 finished with value: 0.46749093933897684 and parameters: {'tol': 0.0004186098361564108, 'C': 1.8843530721162982e-06, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:12:32,164]\u001b[0m Trial 78 finished with value: 0.5006597897348499 and parameters: {'tol': 0.0003514340865434722, 'C': 5.6897966475835834e-09, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:12:36,430]\u001b[0m Trial 79 finished with value: 0.5006597897348499 and parameters: {'tol': 0.0002796206113933227, 'C': 1.2892401862304863e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:12:40,559]\u001b[0m Trial 80 finished with value: 0.500694487153105 and parameters: {'tol': 0.00013760027102093007, 'C': 2.739404528619425e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:12:44,702]\u001b[0m Trial 81 finished with value: 0.4998566201010576 and parameters: {'tol': 0.0002480379155775501, 'C': 7.404122859859216e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:12:48,837]\u001b[0m Trial 82 finished with value: 0.5007279257524541 and parameters: {'tol': 0.00021147363490393192, 'C': 4.615563081235119e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:12:53,189]\u001b[0m Trial 83 finished with value: 0.4654225113914374 and parameters: {'tol': 0.00018961004741884757, 'C': 1.9616244886700415e-07, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:12:57,632]\u001b[0m Trial 84 finished with value: 0.4665022686499206 and parameters: {'tol': 0.0003309239040322185, 'C': 4.792040782745802e-07, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:13:02,076]\u001b[0m Trial 85 finished with value: 0.0 and parameters: {'tol': 0.00024453253615577586, 'C': 1.1521239275860056e-07, 'penalty': 'l1'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:13:05,882]\u001b[0m Trial 86 finished with value: 0.5007622815652489 and parameters: {'tol': 0.00017228173306923567, 'C': 5.397842821288249e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:13:09,733]\u001b[0m Trial 87 finished with value: 0.5006597897348499 and parameters: {'tol': 0.00021737755988692316, 'C': 1.1182919322629328e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:13:14,007]\u001b[0m Trial 88 finished with value: 0.4658846127846667 and parameters: {'tol': 0.0003060243287653089, 'C': 2.3930926880004224e-07, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:13:17,887]\u001b[0m Trial 89 finished with value: 0.5006597897348499 and parameters: {'tol': 0.0002677219608728993, 'C': 2.121698967829797e-08, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:13:22,412]\u001b[0m Trial 90 finished with value: 0.4665022686499206 and parameters: {'tol': 0.00010166836981499386, 'C': 4.799980961719868e-07, 'penalty': 'l2'}. Best is trial 11 with value: 0.500796996639121.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:13:26,429]\u001b[0m Trial 91 finished with value: 0.500813994759489 and parameters: {'tol': 0.0002329433780056682, 'C': 6.681553108313681e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:13:30,753]\u001b[0m Trial 92 finished with value: 0.500694487153105 and parameters: {'tol': 0.00015181895107666595, 'C': 3.492966667477813e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:13:35,666]\u001b[0m Trial 93 finished with value: 0.46535307393852704 and parameters: {'tol': 0.0002285725791110633, 'C': 1.1625352651623948e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:13:40,216]\u001b[0m Trial 94 finished with value: 0.500813994759489 and parameters: {'tol': 0.00027386139668465455, 'C': 6.713823784452255e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:13:44,594]\u001b[0m Trial 95 finished with value: 0.4995300777317415 and parameters: {'tol': 0.00028805242958808235, 'C': 8.149920972582424e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:13:49,077]\u001b[0m Trial 96 finished with value: 0.465425124003451 and parameters: {'tol': 0.0001936920459823967, 'C': 1.630677890244782e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:13:53,545]\u001b[0m Trial 97 finished with value: 0.5006597897348499 and parameters: {'tol': 0.00012654544506927374, 'C': 2.254051008058768e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:13:57,581]\u001b[0m Trial 98 finished with value: 0.0 and parameters: {'tol': 0.0003148148324862396, 'C': 9.88746843935329e-07, 'penalty': 'l1'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:14:01,487]\u001b[0m Trial 99 finished with value: 0.5006597897348499 and parameters: {'tol': 0.0002754763365606271, 'C': 8.383597220071326e-09, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:14:06,218]\u001b[0m Trial 100 finished with value: 0.466382058858672 and parameters: {'tol': 0.00021598260154429014, 'C': 3.026544605266236e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:14:10,030]\u001b[0m Trial 101 finished with value: 0.5007449180911484 and parameters: {'tol': 0.00024158574454568538, 'C': 4.856656415190259e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:14:15,264]\u001b[0m Trial 102 finished with value: 0.500796996639121 and parameters: {'tol': 0.00018049787280130622, 'C': 6.485790136796005e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:14:20,205]\u001b[0m Trial 103 finished with value: 0.4998566201010576 and parameters: {'tol': 0.00015299844672857538, 'C': 7.659692309717928e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:14:24,390]\u001b[0m Trial 104 finished with value: 0.500694487153105 and parameters: {'tol': 0.00017933712502952445, 'C': 3.745331797926056e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:14:28,602]\u001b[0m Trial 105 finished with value: 0.4653541651824278 and parameters: {'tol': 0.0002074523858704788, 'C': 1.3840771120701672e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:14:33,386]\u001b[0m Trial 106 finished with value: 0.5006597897348499 and parameters: {'tol': 0.00026009143116359, 'C': 1.544922887621718e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:14:37,443]\u001b[0m Trial 107 finished with value: 0.500694487153105 and parameters: {'tol': 0.00018422597680835755, 'C': 2.718967677599137e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-10 09:14:41,522]\u001b[0m Trial 108 finished with value: 0.5006597897348499 and parameters: {'tol': 0.0003447314581295542, 'C': 4.513871907567841e-09, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:14:45,958]\u001b[0m Trial 109 finished with value: 0.4654380584676817 and parameters: {'tol': 0.0002934880502003474, 'C': 2.0247499910545657e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:14:50,130]\u001b[0m Trial 110 finished with value: 0.48605106975661555 and parameters: {'tol': 0.0002335659628789107, 'C': 1.0427490286120208e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:14:54,557]\u001b[0m Trial 111 finished with value: 0.5007787392631109 and parameters: {'tol': 0.0002556809674473114, 'C': 6.090881359970626e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:14:59,998]\u001b[0m Trial 112 finished with value: 0.5007449180911484 and parameters: {'tol': 0.00032002852451696033, 'C': 4.7745911347639286e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:15:05,230]\u001b[0m Trial 113 finished with value: 0.500694487153105 and parameters: {'tol': 0.00026213993603233556, 'C': 2.8466985838357802e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:15:10,555]\u001b[0m Trial 114 finished with value: 0.5007787392631109 and parameters: {'tol': 0.00016397156564180537, 'C': 6.141597820728147e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:15:15,417]\u001b[0m Trial 115 finished with value: 0.4998566201010576 and parameters: {'tol': 0.00016247989875275656, 'C': 7.585600723662118e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:15:19,850]\u001b[0m Trial 116 finished with value: 0.5006597897348499 and parameters: {'tol': 0.00013986014488243985, 'C': 1.1727549140470532e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:15:24,523]\u001b[0m Trial 117 finished with value: 0.4664347716445437 and parameters: {'tol': 9.301582003184563e-05, 'C': 3.70520803382602e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:15:29,501]\u001b[0m Trial 118 finished with value: 0.0 and parameters: {'tol': 7.698077558082423e-05, 'C': 1.3571433055345363e-07, 'penalty': 'l1'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:15:33,283]\u001b[0m Trial 119 finished with value: 0.500813994759489 and parameters: {'tol': 0.00011851460926462227, 'C': 6.595502309861624e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:15:37,344]\u001b[0m Trial 120 finished with value: 0.4659346155295787 and parameters: {'tol': 0.00021758073704899024, 'C': 2.6891459304721216e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:15:41,541]\u001b[0m Trial 121 finished with value: 0.5004882505122717 and parameters: {'tol': 0.0001956034778120283, 'C': 6.837396332808754e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:15:45,262]\u001b[0m Trial 122 finished with value: 0.5006597897348499 and parameters: {'tol': 0.00012061570614310476, 'C': 2.2052762376928817e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:15:48,836]\u001b[0m Trial 123 finished with value: 0.500694487153105 and parameters: {'tol': 0.00015179302833437258, 'C': 3.577568553985425e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:15:53,269]\u001b[0m Trial 124 finished with value: 0.46535307393852704 and parameters: {'tol': 0.00017670850013827913, 'C': 1.2228554328244038e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:15:57,233]\u001b[0m Trial 125 finished with value: 0.5006597897348499 and parameters: {'tol': 0.00011789115388499996, 'C': 1.7620587322107022e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:16:01,554]\u001b[0m Trial 126 finished with value: 0.4654564843971416 and parameters: {'tol': 0.0002449069687623556, 'C': 2.072457301826553e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:16:06,468]\u001b[0m Trial 127 finished with value: 0.500796996639121 and parameters: {'tol': 0.00021504504931538668, 'C': 6.3343724873957e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:16:10,578]\u001b[0m Trial 128 finished with value: 0.500796996639121 and parameters: {'tol': 0.00020504092392739824, 'C': 6.217921595701972e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:16:15,621]\u001b[0m Trial 129 finished with value: 0.4665022686499206 and parameters: {'tol': 0.00020748510025893278, 'C': 4.807731017001969e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:16:20,321]\u001b[0m Trial 130 finished with value: 0.5001843935430816 and parameters: {'tol': 0.0002287893877453438, 'C': 7.198733058940588e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:16:24,400]\u001b[0m Trial 131 finished with value: 0.5007622815652489 and parameters: {'tol': 0.0002652022866640695, 'C': 5.019390272410814e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:16:28,588]\u001b[0m Trial 132 finished with value: 0.500694487153105 and parameters: {'tol': 0.00018372121757517204, 'C': 3.2560672958199474e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:16:33,004]\u001b[0m Trial 133 finished with value: 0.49963383966014224 and parameters: {'tol': 0.00016379738365016394, 'C': 9.498373873749789e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:16:37,298]\u001b[0m Trial 134 finished with value: 0.5006597897348499 and parameters: {'tol': 0.00020763446616234863, 'C': 9.232231096866207e-09, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:16:44,677]\u001b[0m Trial 135 finished with value: 0.4654888925650457 and parameters: {'tol': 0.00024299849391161023, 'C': 1.8355242126519757e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:16:48,365]\u001b[0m Trial 136 finished with value: 0.5007622815652489 and parameters: {'tol': 0.00027897145855383524, 'C': 5.3982716772135266e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:16:52,264]\u001b[0m Trial 137 finished with value: 0.5006597897348499 and parameters: {'tol': 0.00022655502124694913, 'C': 1.7598925416813492e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:16:55,983]\u001b[0m Trial 138 finished with value: 0.4995999556078067 and parameters: {'tol': 0.00030247958904537544, 'C': 9.04071142434486e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:16:59,545]\u001b[0m Trial 139 finished with value: 0.0 and parameters: {'tol': 0.00018691267719486804, 'C': 5.962690643558896e-09, 'penalty': 'l1'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:17:03,134]\u001b[0m Trial 140 finished with value: 0.500694487153105 and parameters: {'tol': 0.0002526094360382422, 'C': 3.285006433014442e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:17:06,769]\u001b[0m Trial 141 finished with value: 0.46537085996748606 and parameters: {'tol': 0.00013884478557258162, 'C': 1.4110764222841577e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:17:10,011]\u001b[0m Trial 142 finished with value: 0.500796996639121 and parameters: {'tol': 0.0001660782655360975, 'C': 6.457505407306033e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:17:13,266]\u001b[0m Trial 143 finished with value: 0.5007622815652489 and parameters: {'tol': 0.0001679044796727126, 'C': 5.659358621374561e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-10 09:17:16,737]\u001b[0m Trial 144 finished with value: 0.46634578481534106 and parameters: {'tol': 0.00020211011833594508, 'C': 2.830502186287915e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:17:20,001]\u001b[0m Trial 145 finished with value: 0.4995999556078067 and parameters: {'tol': 0.00022692619453656084, 'C': 9.201667411353887e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:17:23,215]\u001b[0m Trial 146 finished with value: 0.500694487153105 and parameters: {'tol': 0.0001557951516030696, 'C': 2.5467093422299445e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:17:26,974]\u001b[0m Trial 147 finished with value: 0.5006597897348499 and parameters: {'tol': 0.00010206085688698569, 'C': 1.2571036558279394e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:17:30,417]\u001b[0m Trial 148 finished with value: 0.5007279257524541 and parameters: {'tol': 0.00012794647597520303, 'C': 4.3156390726409584e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:17:34,135]\u001b[0m Trial 149 finished with value: 0.4653707852914367 and parameters: {'tol': 0.0002003120556305491, 'C': 1.4754072813457205e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:17:37,414]\u001b[0m Trial 150 finished with value: 0.500796996639121 and parameters: {'tol': 0.00028396076527185244, 'C': 6.358366624784261e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:17:40,425]\u001b[0m Trial 151 finished with value: 0.5004882505122717 and parameters: {'tol': 0.000278995245071479, 'C': 6.853028504657339e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:17:43,430]\u001b[0m Trial 152 finished with value: 0.500694487153105 and parameters: {'tol': 0.0003275624643496863, 'C': 3.1848312779657977e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:17:46,964]\u001b[0m Trial 153 finished with value: 0.46535307393852704 and parameters: {'tol': 0.00023685916150557195, 'C': 1.233196100168754e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:17:50,273]\u001b[0m Trial 154 finished with value: 0.5006597897348499 and parameters: {'tol': 0.0002644975410009386, 'C': 1.901256955598787e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:17:53,598]\u001b[0m Trial 155 finished with value: 0.5001843935430816 and parameters: {'tol': 0.0003588156434948656, 'C': 7.282297475299134e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:17:57,075]\u001b[0m Trial 156 finished with value: 0.46545618536635835 and parameters: {'tol': 0.0002949816944725223, 'C': 1.9992996521510245e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:18:00,565]\u001b[0m Trial 157 finished with value: 0.5007279257524541 and parameters: {'tol': 0.00021624197163692664, 'C': 4.2514844815728135e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:18:04,463]\u001b[0m Trial 158 finished with value: 0.4932356649615107 and parameters: {'tol': 0.0001866172379919523, 'C': 1.0214279582511563e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:18:08,157]\u001b[0m Trial 159 finished with value: 0.4664347716445437 and parameters: {'tol': 0.0002508939003377127, 'C': 3.725584124590497e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:18:11,551]\u001b[0m Trial 160 finished with value: 0.4660723078812546 and parameters: {'tol': 7.2170468435904e-05, 'C': 7.364047363720981e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:18:14,815]\u001b[0m Trial 161 finished with value: 0.5007622815652489 and parameters: {'tol': 0.00014332761028916922, 'C': 5.341587115716844e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:18:18,114]\u001b[0m Trial 162 finished with value: 0.500694487153105 and parameters: {'tol': 0.00017162453760960383, 'C': 3.005831043668879e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:18:21,804]\u001b[0m Trial 163 finished with value: 0.500796996639121 and parameters: {'tol': 0.00011593879418686192, 'C': 6.469955683250205e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:18:25,084]\u001b[0m Trial 164 finished with value: 0.5007787392631109 and parameters: {'tol': 5.1110889550352694e-05, 'C': 6.148226575794643e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:18:28,420]\u001b[0m Trial 165 finished with value: 0.4998566201010576 and parameters: {'tol': 3.463052291838471e-05, 'C': 7.918415129592133e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:18:32,140]\u001b[0m Trial 166 finished with value: 0.4654564843971416 and parameters: {'tol': 5.8309126773589124e-05, 'C': 2.1235057491137242e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:18:35,447]\u001b[0m Trial 167 finished with value: 0.5006597897348499 and parameters: {'tol': 0.00010629259019906733, 'C': 2.0897645942773438e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:18:38,934]\u001b[0m Trial 168 finished with value: 0.0 and parameters: {'tol': 8.79818471492977e-05, 'C': 1.1121673499094412e-07, 'penalty': 'l1'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:18:42,371]\u001b[0m Trial 169 finished with value: 0.500694487153105 and parameters: {'tol': 2.4173053734370788e-05, 'C': 3.93966962129494e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:18:45,724]\u001b[0m Trial 170 finished with value: 0.5007622815652489 and parameters: {'tol': 0.000121317531159901, 'C': 5.474453486636248e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:18:48,994]\u001b[0m Trial 171 finished with value: 0.500813994759489 and parameters: {'tol': 0.0002078370318642264, 'C': 6.599626309622777e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:18:52,420]\u001b[0m Trial 172 finished with value: 0.4653874116042938 and parameters: {'tol': 0.00015729138235703774, 'C': 1.5810240450442274e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:18:55,826]\u001b[0m Trial 173 finished with value: 0.4998566201010576 and parameters: {'tol': 4.266028203158415e-05, 'C': 7.426999128920324e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:18:59,322]\u001b[0m Trial 174 finished with value: 0.500694487153105 and parameters: {'tol': 0.00021238118393707375, 'C': 3.215651388546483e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:19:02,729]\u001b[0m Trial 175 finished with value: 0.5006597897348499 and parameters: {'tol': 0.00018270109744958704, 'C': 1.3636318367326832e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:19:06,070]\u001b[0m Trial 176 finished with value: 0.475492765770926 and parameters: {'tol': 0.00022961541252461908, 'C': 1.084911821710365e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:19:09,502]\u001b[0m Trial 177 finished with value: 0.5007622815652489 and parameters: {'tol': 0.00020465872523926706, 'C': 5.660361208119816e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:19:12,925]\u001b[0m Trial 178 finished with value: 0.46589936460396186 and parameters: {'tol': 7.168832426091877e-05, 'C': 2.6124627814621783e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:19:16,274]\u001b[0m Trial 179 finished with value: 0.5006597897348499 and parameters: {'tol': 8.734542064515244e-06, 'C': 2.0451735521035756e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-10 09:19:19,287]\u001b[0m Trial 180 finished with value: 0.5007109391924841 and parameters: {'tol': 0.00016750398559057476, 'C': 4.001003497175076e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:19:22,314]\u001b[0m Trial 181 finished with value: 0.500813994759489 and parameters: {'tol': 0.00028790137406179133, 'C': 6.762945184295951e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:19:25,678]\u001b[0m Trial 182 finished with value: 0.4998566201010576 and parameters: {'tol': 0.0002558341206180413, 'C': 7.783083327070533e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:19:29,441]\u001b[0m Trial 183 finished with value: 0.465336045027389 and parameters: {'tol': 0.0002684028676048452, 'C': 1.3633979484091216e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:19:32,719]\u001b[0m Trial 184 finished with value: 0.5007787392631109 and parameters: {'tol': 0.00023904566005000024, 'C': 5.91472082488227e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:19:35,909]\u001b[0m Trial 185 finished with value: 0.500694487153105 and parameters: {'tol': 0.00018891770299574105, 'C': 2.838318429504652e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:19:39,504]\u001b[0m Trial 186 finished with value: 0.4943004834455563 and parameters: {'tol': 0.00031260163098300795, 'C': 4.596756862106381e-05, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:19:42,984]\u001b[0m Trial 187 finished with value: 0.49965212243550744 and parameters: {'tol': 0.0001336307764083615, 'C': 9.842074997551258e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:19:46,529]\u001b[0m Trial 188 finished with value: 0.5006433490036858 and parameters: {'tol': 0.0002865382565315422, 'C': 1.1885547519038828e-10, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:19:50,372]\u001b[0m Trial 189 finished with value: 0.46545480306461184 and parameters: {'tol': 9.814109544227105e-05, 'C': 1.8801566616067462e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:19:53,661]\u001b[0m Trial 190 finished with value: 0.5007279257524541 and parameters: {'tol': 0.00022166814437489217, 'C': 4.204632076820922e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:19:56,840]\u001b[0m Trial 191 finished with value: 0.5007787392631109 and parameters: {'tol': 0.0002392332163939262, 'C': 5.921684791922576e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:20:00,256]\u001b[0m Trial 192 finished with value: 0.5004882505122717 and parameters: {'tol': 0.0002474844847553838, 'C': 7.00202972712211e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:20:04,022]\u001b[0m Trial 193 finished with value: 0.4653697687235853 and parameters: {'tol': 0.00019539309979504287, 'C': 1.1382235804843315e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:20:07,179]\u001b[0m Trial 194 finished with value: 0.5007449180911484 and parameters: {'tol': 0.0002220233038893069, 'C': 4.939510520866739e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:20:10,279]\u001b[0m Trial 195 finished with value: 0.500694487153105 and parameters: {'tol': 0.00028057428575900225, 'C': 2.5759651307152806e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:20:13,585]\u001b[0m Trial 196 finished with value: 0.49951361437247677 and parameters: {'tol': 0.00015228292859566158, 'C': 8.056926039257033e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:20:16,798]\u001b[0m Trial 197 finished with value: 0.500694487153105 and parameters: {'tol': 0.0004901089451103546, 'C': 3.634178425890093e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:20:20,411]\u001b[0m Trial 198 finished with value: 0.0 and parameters: {'tol': 0.00024191747730073563, 'C': 1.474163469646956e-07, 'penalty': 'l1'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:20:23,551]\u001b[0m Trial 199 finished with value: 0.5006597897348499 and parameters: {'tol': 0.0002042060206059389, 'C': 1.6469264509137848e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:20:26,762]\u001b[0m Trial 200 finished with value: 0.5004882505122717 and parameters: {'tol': 0.0002573394894811717, 'C': 6.871743476807678e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:20:29,988]\u001b[0m Trial 201 finished with value: 0.5007622815652489 and parameters: {'tol': 0.0002421733568179527, 'C': 5.5000397969622464e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:20:33,352]\u001b[0m Trial 202 finished with value: 0.5007279257524541 and parameters: {'tol': 4.6583684201449726e-07, 'C': 4.51312302070217e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:20:37,145]\u001b[0m Trial 203 finished with value: 0.46535307393852704 and parameters: {'tol': 0.00022656005795922113, 'C': 1.2067118239582827e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:20:40,472]\u001b[0m Trial 204 finished with value: 0.4998566201010576 and parameters: {'tol': 0.0001792678473613144, 'C': 7.606514947667024e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:20:43,900]\u001b[0m Trial 205 finished with value: 0.500694487153105 and parameters: {'tol': 0.00026871818079454956, 'C': 2.46675773906326e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:20:47,556]\u001b[0m Trial 206 finished with value: 0.4654564843971416 and parameters: {'tol': 0.0003072799888562258, 'C': 2.1392965342112244e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:20:51,052]\u001b[0m Trial 207 finished with value: 0.5006433490036858 and parameters: {'tol': 5.1999068432669275e-05, 'C': 5.419610964941338e-10, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:20:54,407]\u001b[0m Trial 208 finished with value: 0.5007622815652489 and parameters: {'tol': 0.00020804328620915277, 'C': 5.475834166049911e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:20:57,752]\u001b[0m Trial 209 finished with value: 0.49963383966014224 and parameters: {'tol': 0.0001139518287203264, 'C': 9.548621611343283e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:21:01,098]\u001b[0m Trial 210 finished with value: 0.5006597897348499 and parameters: {'tol': 0.00023606828975541685, 'C': 1.0125137436317989e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:21:04,460]\u001b[0m Trial 211 finished with value: 0.5007279257524541 and parameters: {'tol': 0.0002919834537501013, 'C': 4.055704457132229e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:21:07,763]\u001b[0m Trial 212 finished with value: 0.500796996639121 and parameters: {'tol': 0.0003322412369080052, 'C': 6.2932441082377e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:21:11,057]\u001b[0m Trial 213 finished with value: 0.5007787392631109 and parameters: {'tol': 0.0003328336493451074, 'C': 5.766933659378765e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:21:14,492]\u001b[0m Trial 214 finished with value: 0.500694487153105 and parameters: {'tol': 0.0002698243980381397, 'C': 2.9775794125612874e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:21:18,052]\u001b[0m Trial 215 finished with value: 0.4932356649615107 and parameters: {'tol': 0.00017575545661092763, 'C': 1.0234478139642617e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-10 09:21:22,121]\u001b[0m Trial 216 finished with value: 0.46542253231881203 and parameters: {'tol': 0.0002487099264169961, 'C': 1.5624723736955534e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:21:25,292]\u001b[0m Trial 217 finished with value: 0.500796996639121 and parameters: {'tol': 0.0001961306364304123, 'C': 6.523365036949941e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:21:28,520]\u001b[0m Trial 218 finished with value: 0.500694487153105 and parameters: {'tol': 0.00014678203227715938, 'C': 3.227152203393341e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:21:32,197]\u001b[0m Trial 219 finished with value: 0.48605106975661555 and parameters: {'tol': 0.00019827860913179955, 'C': 1.0422433806524744e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:21:35,740]\u001b[0m Trial 220 finished with value: 0.4659535431002789 and parameters: {'tol': 0.00036949889324471485, 'C': 2.78925208604311e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:21:39,188]\u001b[0m Trial 221 finished with value: 0.500813994759489 and parameters: {'tol': 0.0005575305409400919, 'C': 6.605221026512271e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:21:42,436]\u001b[0m Trial 222 finished with value: 0.5001843935430816 and parameters: {'tol': 0.0005390305578269984, 'C': 7.205417965139676e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:21:46,345]\u001b[0m Trial 223 finished with value: 0.47608586231918587 and parameters: {'tol': 0.0001647212464975601, 'C': 7.616754530422475e-06, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:21:49,698]\u001b[0m Trial 224 finished with value: 0.5007279257524541 and parameters: {'tol': 0.00022046280939127768, 'C': 4.3926028827424334e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:21:53,193]\u001b[0m Trial 225 finished with value: 0.4998566201010576 and parameters: {'tol': 0.0003922495014030067, 'C': 7.404387134233758e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:21:56,765]\u001b[0m Trial 226 finished with value: 0.465336045027389 and parameters: {'tol': 0.0005710028820400037, 'C': 1.3244609992076903e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:21:59,962]\u001b[0m Trial 227 finished with value: 0.5006597897348499 and parameters: {'tol': 0.000191559826644338, 'C': 2.3167683885145907e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:22:02,997]\u001b[0m Trial 228 finished with value: 0.5007279257524541 and parameters: {'tol': 0.00045457135840895765, 'C': 4.617510897922039e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:22:06,140]\u001b[0m Trial 229 finished with value: 0.4998566201010576 and parameters: {'tol': 0.00012959685448831056, 'C': 7.709538488539461e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:22:09,568]\u001b[0m Trial 230 finished with value: 0.0 and parameters: {'tol': 0.000736415578324611, 'C': 1.7120672271646436e-07, 'penalty': 'l1'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:22:12,699]\u001b[0m Trial 231 finished with value: 0.5007787392631109 and parameters: {'tol': 0.00021563611965077776, 'C': 5.8663889580631996e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:22:15,765]\u001b[0m Trial 232 finished with value: 0.500694487153105 and parameters: {'tol': 0.00042150103335302923, 'C': 3.603051027165173e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:22:19,424]\u001b[0m Trial 233 finished with value: 0.46747244393675497 and parameters: {'tol': 0.00023950160309642402, 'C': 1.8823870257945273e-06, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:22:22,622]\u001b[0m Trial 234 finished with value: 0.5007787392631109 and parameters: {'tol': 0.00028017054349215893, 'C': 5.9187565736893065e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:22:26,100]\u001b[0m Trial 235 finished with value: 0.475492765770926 and parameters: {'tol': 0.0002586468605950516, 'C': 1.0558783432681751e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:22:29,139]\u001b[0m Trial 236 finished with value: 0.5006597897348499 and parameters: {'tol': 8.619923393577116e-05, 'C': 1.888045648981011e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:22:32,328]\u001b[0m Trial 237 finished with value: 0.5007787392631109 and parameters: {'tol': 0.00029887212465670417, 'C': 5.767348343698935e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:22:37,814]\u001b[0m Trial 238 finished with value: 0.49138541709416766 and parameters: {'tol': 0.00018460510118290248, 'C': 0.0008666652167602463, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:22:41,182]\u001b[0m Trial 239 finished with value: 0.500694487153105 and parameters: {'tol': 0.0002293718823862375, 'C': 3.375447315475122e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:22:44,408]\u001b[0m Trial 240 finished with value: 0.4996169131343028 and parameters: {'tol': 0.00020803429691436314, 'C': 9.353929947202474e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:22:47,494]\u001b[0m Trial 241 finished with value: 0.5007787392631109 and parameters: {'tol': 0.0006111814829163741, 'C': 6.068541156536455e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:22:50,715]\u001b[0m Trial 242 finished with value: 0.5007449180911484 and parameters: {'tol': 0.00033567974981113914, 'C': 4.671037700008288e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:22:53,825]\u001b[0m Trial 243 finished with value: 0.4995999556078067 and parameters: {'tol': 0.00031813943909221544, 'C': 9.053610379716861e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:22:57,145]\u001b[0m Trial 244 finished with value: 0.5007787392631109 and parameters: {'tol': 0.0003469550715435452, 'C': 6.13223989625207e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:23:00,654]\u001b[0m Trial 245 finished with value: 0.46538748007649505 and parameters: {'tol': 0.000275808816830386, 'C': 1.5052102106678958e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:23:03,929]\u001b[0m Trial 246 finished with value: 0.500694487153105 and parameters: {'tol': 0.0006383258800864621, 'C': 3.2023231809661906e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:23:07,236]\u001b[0m Trial 247 finished with value: 0.5007449180911484 and parameters: {'tol': 0.00016496131787915657, 'C': 4.8294756040793304e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:23:10,457]\u001b[0m Trial 248 finished with value: 0.4995999556078067 and parameters: {'tol': 0.0009640954566947903, 'C': 9.038426229648903e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:23:13,824]\u001b[0m Trial 249 finished with value: 0.5006597897348499 and parameters: {'tol': 0.0003267990801003795, 'C': 2.015034459993341e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:23:17,643]\u001b[0m Trial 250 finished with value: 0.46535307393852704 and parameters: {'tol': 0.00025428352722368247, 'C': 1.2880582754832527e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:23:20,833]\u001b[0m Trial 251 finished with value: 0.5006433490036858 and parameters: {'tol': 0.00029371132593257, 'C': 2.521125581181476e-09, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-10 09:23:24,065]\u001b[0m Trial 252 finished with value: 0.500796996639121 and parameters: {'tol': 0.00036711242462890404, 'C': 6.574779812746902e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:23:27,143]\u001b[0m Trial 253 finished with value: 0.500694487153105 and parameters: {'tol': 0.00037253776391211514, 'C': 3.389096126829028e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:23:30,418]\u001b[0m Trial 254 finished with value: 0.4998566201010576 and parameters: {'tol': 0.0001982176952961814, 'C': 7.954408352057616e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:23:34,035]\u001b[0m Trial 255 finished with value: 0.4664310649835725 and parameters: {'tol': 0.00023830220508251027, 'C': 4.539847633499402e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:23:37,737]\u001b[0m Trial 256 finished with value: 0.46545480306461184 and parameters: {'tol': 0.0002186046702671021, 'C': 1.8755102016757663e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:23:41,040]\u001b[0m Trial 257 finished with value: 0.500694487153105 and parameters: {'tol': 0.00014921509312565564, 'C': 3.832747942029226e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:23:44,670]\u001b[0m Trial 258 finished with value: 0.4653697687235853 and parameters: {'tol': 6.47768716290419e-05, 'C': 1.152265355667342e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:23:47,838]\u001b[0m Trial 259 finished with value: 0.500796996639121 and parameters: {'tol': 0.0002648849697637852, 'C': 6.309146935947266e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:23:51,159]\u001b[0m Trial 260 finished with value: 0.0 and parameters: {'tol': 0.0003084029585367215, 'C': 2.5358649278781293e-08, 'penalty': 'l1'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:23:54,636]\u001b[0m Trial 261 finished with value: 0.5006433490036858 and parameters: {'tol': 0.0002674342422901363, 'C': 1.8828412372084187e-10, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:23:58,096]\u001b[0m Trial 262 finished with value: 0.46634578481534106 and parameters: {'tol': 2.6929550726405976e-05, 'C': 2.8082249372899386e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:24:01,477]\u001b[0m Trial 263 finished with value: 0.4998566201010576 and parameters: {'tol': 0.00017682075789739315, 'C': 7.555678710225727e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:24:04,732]\u001b[0m Trial 264 finished with value: 0.5006597897348499 and parameters: {'tol': 0.0005673753700203488, 'C': 1.4123188463431671e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:24:07,848]\u001b[0m Trial 265 finished with value: 0.5007279257524541 and parameters: {'tol': 0.00011142434358342592, 'C': 4.536883172562711e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:24:11,481]\u001b[0m Trial 266 finished with value: 0.465336045027389 and parameters: {'tol': 0.00028860602330995787, 'C': 1.327694865821218e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:24:14,851]\u001b[0m Trial 267 finished with value: 0.4998566201010576 and parameters: {'tol': 0.00025756041867859016, 'C': 7.810841748284153e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:24:18,606]\u001b[0m Trial 268 finished with value: 0.4654564843971416 and parameters: {'tol': 4.3394288488467705e-05, 'C': 2.0998063970923884e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:24:22,292]\u001b[0m Trial 269 finished with value: 0.4803665696129191 and parameters: {'tol': 0.0001951676989162876, 'C': 1.5818272414102747e-05, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:24:25,671]\u001b[0m Trial 270 finished with value: 0.500694487153105 and parameters: {'tol': 0.00021819205007613484, 'C': 2.856398374236129e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:24:29,108]\u001b[0m Trial 271 finished with value: 0.5007449180911484 and parameters: {'tol': 0.0003584790911601044, 'C': 4.6730079274568255e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:24:32,649]\u001b[0m Trial 272 finished with value: 0.4932356649615107 and parameters: {'tol': 0.0001331086819369127, 'C': 1.0084794328750716e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:24:36,366]\u001b[0m Trial 273 finished with value: 0.4660179397140266 and parameters: {'tol': 0.00016432350545234477, 'C': 8.752011295842319e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:24:39,655]\u001b[0m Trial 274 finished with value: 0.5007787392631109 and parameters: {'tol': 0.000873730972571786, 'C': 6.112670907779187e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:24:43,161]\u001b[0m Trial 275 finished with value: 0.5006597897348499 and parameters: {'tol': 0.00040583865228016245, 'C': 1.9355963592151313e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:24:46,797]\u001b[0m Trial 276 finished with value: 0.4653707230614434 and parameters: {'tol': 0.00027224650180413733, 'C': 1.614501803949855e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:24:49,882]\u001b[0m Trial 277 finished with value: 0.500694487153105 and parameters: {'tol': 0.0004854680966380097, 'C': 3.927228087792614e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:24:53,129]\u001b[0m Trial 278 finished with value: 0.0 and parameters: {'tol': 7.525843631762206e-05, 'C': 9.073969963436011e-08, 'penalty': 'l1'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:24:56,345]\u001b[0m Trial 279 finished with value: 0.500796996639121 and parameters: {'tol': 0.00024228966170256142, 'C': 6.518015783307769e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:24:59,663]\u001b[0m Trial 280 finished with value: 0.5006597897348499 and parameters: {'tol': 0.0003118776204808617, 'C': 8.965237639706598e-09, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:25:02,934]\u001b[0m Trial 281 finished with value: 0.500694487153105 and parameters: {'tol': 0.00020912844631086201, 'C': 2.499465024872097e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:25:06,633]\u001b[0m Trial 282 finished with value: 0.465336045027389 and parameters: {'tol': 0.000184011605515741, 'C': 1.348446483163796e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:25:10,230]\u001b[0m Trial 283 finished with value: 0.4718898947715545 and parameters: {'tol': 0.00028661179525941635, 'C': 3.4493813040850733e-06, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:25:13,602]\u001b[0m Trial 284 finished with value: 0.5006597897348499 and parameters: {'tol': 0.0002482577212612016, 'C': 5.246195265516017e-09, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:25:17,201]\u001b[0m Trial 285 finished with value: 0.46560511905265456 and parameters: {'tol': 0.0005105341642294244, 'C': 1.2356219411885546e-06, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:25:20,795]\u001b[0m Trial 286 finished with value: 0.46641564713642925 and parameters: {'tol': 0.0004360923969154838, 'C': 4.023235847516416e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:25:24,101]\u001b[0m Trial 287 finished with value: 0.500796996639121 and parameters: {'tol': 0.0002280562693323789, 'C': 6.42312504034821e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-10 09:25:27,474]\u001b[0m Trial 288 finished with value: 0.4995999556078067 and parameters: {'tol': 0.0002281583531584909, 'C': 9.012833754147787e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:25:30,735]\u001b[0m Trial 289 finished with value: 0.500694487153105 and parameters: {'tol': 0.0002660738167869816, 'C': 3.721676034924772e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:25:38,389]\u001b[0m Trial 290 finished with value: 0.4507858514119737 and parameters: {'tol': 0.0002091544491825439, 'C': 0.015856667657610343, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:25:42,103]\u001b[0m Trial 291 finished with value: 0.4662767149482027 and parameters: {'tol': 0.00023833116832060988, 'C': 2.456393267286955e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:25:45,463]\u001b[0m Trial 292 finished with value: 0.5007622815652489 and parameters: {'tol': 0.0003051916807093552, 'C': 5.336198547270304e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:25:48,749]\u001b[0m Trial 293 finished with value: 0.5006433490036858 and parameters: {'tol': 0.00034353746154002103, 'C': 9.436670314296445e-10, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:25:52,661]\u001b[0m Trial 294 finished with value: 0.46535307393852704 and parameters: {'tol': 0.0001869653976502601, 'C': 1.273688887801324e-07, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:25:56,184]\u001b[0m Trial 295 finished with value: 0.5006597897348499 and parameters: {'tol': 0.00022461015200110206, 'C': 1.3737672507187361e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:25:59,617]\u001b[0m Trial 296 finished with value: 0.500813994759489 and parameters: {'tol': 0.00025571375826138464, 'C': 6.826342658388929e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:26:03,442]\u001b[0m Trial 297 finished with value: 0.4686132229444386 and parameters: {'tol': 0.0002652036076784016, 'C': 2.2574034637666852e-06, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:26:06,658]\u001b[0m Trial 298 finished with value: 0.4994966936463722 and parameters: {'tol': 0.0002826837078284892, 'C': 8.009215096104659e-08, 'penalty': 'l2'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:26:10,182]\u001b[0m Trial 299 finished with value: 0.0 and parameters: {'tol': 0.00025774141863454546, 'C': 3.371587816826108e-08, 'penalty': 'l1'}. Best is trial 91 with value: 0.500813994759489.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.500813994759489\n",
      "\n",
      "Optimized parameters: {'tol': 0.0002329433780056682, 'C': 6.681553108313681e-08, 'penalty': 'l2'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#with mlflow.start_run(experiment_id='844779971019835314'):\n",
    "def logistic_regression_objective(trial):\n",
    "    #_l1_ratio = trial.suggest_float(\"l1_ratio\", 0., 1)\n",
    "    #_C = trial.suggest_float(\"C\", 0.00001, 0.9901)\n",
    "    #_max_iter = trial.suggest_int(\"max_iter\", 50, 500)\n",
    "    #_penalty = trial.suggest_categorical(\"penalty\", ['l1', 'l2'])\n",
    "\n",
    "\n",
    "    params = {\n",
    "        'tol' : trial.suggest_uniform('tol' , 1e-10 , 1e-3),\n",
    "        'C' : trial.suggest_loguniform(\"C\", 1e-10, 1),\n",
    "        'penalty': trial.suggest_categorical('penalty', ['l2', 'l1'])\n",
    "    }\n",
    "    if params['penalty'] == 'l1':\n",
    "        params['solver'] = 'saga'\n",
    "    else:\n",
    "        params['solver'] = 'lbfgs'\n",
    "\n",
    "    logistic_regression = LogisticRegression(\n",
    "        **params, random_state=42, n_jobs=-1\n",
    "    )\n",
    "    logistic_regression_smote = Pipeline([('smote', smote), ('model', logistic_regression)])\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        logistic_regression_smote, X_train, y_train, cv=cv,\n",
    "        scoring=custom_score,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    \n",
    "    mlflow_hyperparameter_tuning(experiment_id, params, scores)\n",
    "        \n",
    "    return scores.mean()\n",
    "\n",
    "logistic_regression_params = udf.tune(logistic_regression_objective, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "118fb077",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T08:27:46.017089Z",
     "start_time": "2023-03-10T08:27:45.144362Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tol': 0.0002329433780056682, 'C': 6.681553108313681e-08, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c01a3ce",
   "metadata": {},
   "source": [
    "Best score: 0.4995235299332249\n",
    "\n",
    "Optimized parameters: {'tol': 0.00019002996404617352, 'C': 0.00010206877916671905, 'solver': 'lbfgs'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2630b15c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T08:27:55.806120Z",
     "start_time": "2023-03-10T08:27:52.279384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-25 {color: black;background-color: white;}#sk-container-id-25 pre{padding: 0;}#sk-container-id-25 div.sk-toggleable {background-color: white;}#sk-container-id-25 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-25 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-25 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-25 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-25 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-25 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-25 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-25 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-25 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-25 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-25 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-25 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-25 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-25 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-25 div.sk-item {position: relative;z-index: 1;}#sk-container-id-25 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-25 div.sk-item::before, #sk-container-id-25 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-25 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-25 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-25 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-25 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-25 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-25 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-25 div.sk-label-container {text-align: center;}#sk-container-id-25 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-25 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-25\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;smote&#x27;, SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LogisticRegression(C=6.681553108313681e-08, n_jobs=-1,\n",
       "                                    random_state=42,\n",
       "                                    tol=0.0002329433780056682))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-73\" type=\"checkbox\" ><label for=\"sk-estimator-id-73\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;smote&#x27;, SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LogisticRegression(C=6.681553108313681e-08, n_jobs=-1,\n",
       "                                    random_state=42,\n",
       "                                    tol=0.0002329433780056682))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-74\" type=\"checkbox\" ><label for=\"sk-estimator-id-74\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE(k_neighbors=17, random_state=1001)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-75\" type=\"checkbox\" ><label for=\"sk-estimator-id-75\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=6.681553108313681e-08, n_jobs=-1, random_state=42,\n",
       "                   tol=0.0002329433780056682)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('smote', SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=6.681553108313681e-08, n_jobs=-1,\n",
       "                                    random_state=42,\n",
       "                                    tol=0.0002329433780056682))])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logistic_regression_params = {'tol': 0.00019002996404617352, 'C': 0.00010206877916671905, 'solver': 'lbfgs'}\n",
    "logistic_regression_optimized = construct_model(logistic_regression, logistic_regression_params)\n",
    "logistic_regression_optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "728bee1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T08:28:05.577709Z",
     "start_time": "2023-03-10T08:28:05.020216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pour le seuil 0.5, le f3_score est : 0.48 et le mean score est : 0.529\n",
      "Accuracy score : 0.578044\n",
      "f3_score : 0.479694 \n",
      "\n",
      "Mean evalation score : 0.528869\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUkAAAEbCAYAAABXzHZUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAApuklEQVR4nO3de5xVVf3/8dc5w0Uuiqh4AUQo9WNqigiaGaV5qfBSpmbeL6Wmohma9hNUNPVrXtEgKy/hN8NKi29e0ExBRVCQCryAnxQBG0QUAREEZC6/P9Y+w+Y4s88eZc+cmXk/fezHzN5r7b3XYZzPrLXX2mvlamtrERGR+uWbuwAiIuVMQVJEJIGCpIhIAgVJEZEECpIiIgkUJEUaYGb6/RDaNXcB2hozOxE4G9gT6AD8B7gXuN3dqzK6Z2fgLuBwwh/GP7j72Rvx+k8DXwOucveRG+u6zcXMNgeuAaYBvy+R9zTgd8ACd++bddmk6ekvZRMys98B9wGDgY5ALbAHcDPwVzPLZXTrE4HjgU2BKmDtRr7+e8BCYMVGvm5zeRY4D6hIkXcV4bMvyrRE0mxUk2wiZnYmcBqwDhhKqH3UAMOAG4AjgO8D92dw++2irzPcfdDGvri7H7uxr9nMNkub0d0fAB7IsCzSzHJ646ZpmNlrgAG3uPtFRWm/J9Tw7nP3p6Jj3YCrgO8C2wBvAr8mNMtrozxjgVOB/0cIvhcCWwJPAWe7+9uxpnDcgcABwJXAM+5+QHS9vsC8KE8/d59vZtsD10fX2IpQY3oQGOHua6PzCveoa26bWQfgMuAkYHtCbev3wLXu/nGUZ2RUht8AU4ArorzTgHPcfXYD/5YHAJOAV6PPfAuwE/ACcDLwJeA6oHd03dPdvTL273oTMAToASwFHgUudvdlZjYf2CF2uwXu3jf2GS8Dvg18IbrHYmLNbTO7GLiR8AfwS+7+YvQH8reEn/Egd59Z3+eS8qSaZBMws+0IARLg4eJ0dz+5KH8nYDLwxejQh8AuwKjoOucWXeJswi/2KqAT4dnjbcCxhKbwh4Sm9sfRfmOa2w8B/aNzPwD6AhcDXYFz6jshemzwMHBorPz9CEFwbzM70t1rYqd8I/oMKwiPIb4KjAX2KVG23oQAtwbYhBD4JwGfA1YS/i0OJgSoIdE5Y4HvEB51LCX8ATqDENTOJPwR6E1oai/jk83okUB1lD6DENTjbgWOAfYFxpjZkcAvorT/UYBsefRMsmnEf5EWpsh/PiFALgP2cvfNCDVGgHPMrDh4bEv4pewG3BkdOxTqmsK3RMeed/fe7v58mkKb2RaEAFkFbO/uWwNHAs+Q/Pzx2Oj+64BDovIfHO0fRggicX2BI929G3B5dGyQmXUvUcRuwDXReVdGx3YEris69pXo83SIPsscYEd334r1f3D2BXD3/YDK6NiwaD/uA6AP4RHG08UFcvdq4HTCH6JBhJpsd+AVQmeQtDAKkk0j3gGQpnPmiOjrnYWah7v/LzC9KL3gGXd/Maqd/S06tumnLGsdd18KzCW0OJ4zs1sI5T/M3S9NUf7x7v5kdK2ngPENlN/dvVDDHh87nuYz/Dr6+kLs2Jjo67T4ddz94+iPxu7ApmZ2DiGgQ6gZp/F3d1/i7kujgPgJ7j6H8KgEQq22mtDk/zjlPaSMKEg2jbdj3/cuTjSzfcysZ+zQ1tHXeUVZC/vbFB1fEvv+o+jrp+kpr+/xy2HARODzwE8IQXhx9OytIRuj/JDu/8+l0dd4AHov+vqJxwpm9gNCbX4moabZsRH3gvS92L8jBEeABcCslOdJmVGQbALuvoDwiwIh6NSJBizfC/zXzC6LDi+OvvYtulS/6Os7Rcfj4yvT9sQVngl2jB3rVpzJ3Z3wDG9b4HuE53tdgBvNbJcGrt0U5S+U7xO1uYZqeGa2O+FxRHdgP3fflvU1vrikMqxOWbSbWd+C+ByQVPOWMqYg2XRujr4ONbPTzaydmXUkPOjfhfCzeCrK8/fo65lmtgfUDUIvPIt8aCOUZ1n01aJnj7D+uWch4ctm9h6h9rR1NNxlJOtre1s1cO1C+b9rZgdG1zoQOCo6/rd6z8reroQadg1QGf37nxalxX8XCkF7MzMrrl2XDOJmNgQ4IbrPfdHhEQl/VKSMKUg2ndGEMZAdgHsIHR8fABdE6b9w98IztNsBB7YAZpnZCtb/so129xkboTyTCL/w3YE3zWwu4flcvBY2HZhPqDm+bGbvAv8FOhM6Pxoqx58IvfPtgYlm9gGhyd6eEOD/uhHK/2n8k9B51InwrHUpYZA9bDg2cn709SbC503NzDZl/XPS3xA6cV4l1Njv0quOLY9+YE0kGtt4IvBDQvCpJdTIpgInuPvPYnk/BPYjBMv/En7BnBBQL2AjcPdXCENf5hMC9+uEITRVsTxVwDeBXwJvEQLJQsLztkPcfU0D164i9G7/nBCMNonucxVwTGGcZ1Nz97mEn8HrhD8G8wj/BsuAbma2d5R1JOGPQA2wpJ7aZJLrCaMZ3gUui/4tCj3o+xPe5JEWRIPJRUQSqCYpIpJAQVJEJIGCpIhIAgVJEZEELXKCi2h82yDC+L16Bw6LyGdWQXhH/cXCjE+NFY3BTTv13IroVdiy0iKDJCFATm7uQoi0EYOB5xp7kpltUU279ys2eKEq0TIz27HcAmVLDZKLADocNIxc51ITxUi5+OmQnZu7CNIIy99/l9EjzodPP+v6ZhVUsXiTfajKbZKYsV3tGrZZM707odapILkRVAPkOncn33XL5i6LpLTF1tuVziTl6DM90qqq6Ex1vnNyppry7R5pqUFSRFqKXC5spfKUKQVJEclWLh+2UnnKlIKkiGQsRU3yU01/2jQUJEUkW7lcipqkgqSItFV6JikikiBfEbYktSXSm5GCpIhkSx03IiIJ1NwWEUmgjhsRkSQpmttlPCGZgqSIZKuiImxJ1HEjIm1WBs8kzewEYARhBc5R7j6mKN0Iq1V2J6zz/n13X2ZmpxIWayusDf+ouw9Pulf51nFFpHUoPJNM3NIHSTPrBVwLfAXoD5xlZrvG0nOEpYuvd/c9gX8DhdVIBwLD3L1/tCUGSFBNUkSytvFrkgcDEwvzTprZg8AxwNVR+gBglbs/Hu1fB2wefT8I2MnMLgNmAee7+7KkmylIiki2GjdOsndoKW9gubsvj+33ZMM5LhcB+8T2dwTeMbO7gb0Ia6ifH8t7E2G9++uA0YS12Buk5raIZCy3vjbZ0LZ+govJwLyi7cKiC+aB2g1vQE1svx1wAHCHuw8A3gRuAXD3o9x9irvXAjcA3ypVetUkRSRb+Xzp1xLzdfW1wUBlUeryov3KKF/BtsDbsf13gNfdfUa0fz/woJl1A85w91uj4zkovbaEgqSIZKtxze1Kd59f4opPAiPNrAewCjgaOCuWPhXoYWZ7uvss4Ajgn8BK4BIzm+ru04ChwPhSxVdzW0SyVaqpnaZjJ8bdFwLDgUnATGCcu083swlmNtDdVwNHAXea2avA14GL3L0a+B5wh5nNAfYGLil1P9UkRSRbGUxw4e7jgHFFx4bEvp/Ghp05heOTCb3fqSlIiki2NAuQiEiCXIqOGwVJEWmzNFWaiEgCNbdFRBKoJiki0rBcLkeuRBAsld6cFCRFJFOhIlkqSDZRYT4FBUkRyVQunyOXLxEkS6Q3JwVJEclUjhTNbRQkRaSN0jNJEZEECpIiIkk2mC4yIU+ZUpAUkWylqEmWc/e2gqSIZCqfz8cn1W04T5lSkBSRTGmcpIhIKWUcBEtRkBSRTKl3W0QkgYKkiEgCvZYoIpJANUkRkSQaJyki0rBcikl3G1uTNLMTgBFAe2CUu48pSjfgN0B34B3g++6+zMz6APcBWwMOnOjuK5PuVb4jOEWkVSjMApS4NWKMkJn1Aq4FvgL0B84ys11j6TngIeB6d98T+Dfwsyj5V8Cv3H0XYAZwean7KUiKSLZyKbf0DgYmuvtSd18FPAgcE0sfAKxy98ej/euAMWbWHvhqlB9gLHBsqZupuS0imcrnc9SWeO0w1rvdO7SUN7Dc3ZfH9nsCi2L7i4B9Yvs7Au+Y2d3AXsAc4HxgK2CFu1fFzutdsvylMoiIfBYlm9obduxMBuYVbRcWXTIP1MZvAdTE9tsBBwB3uPsA4E3glnrOo+i8eqkmKSLZatxUaYOByqLU5UX7lVG+gm2Bt2P77wCvu/uMaP9+QhP7XaCbmVW4ezWwXdF59VKQbEI54KffMnbaZlPWVddw3SNzqFy2ui79+H2354j+PVn+0ToArn/0Nb7YuxuH7bkdAB0q8uy0bVcOu/U5Vq6tqu8WspHV1NRy570TWPDWYtq1a8c5Pzyc7bbZ4hP5fn33I3Tt2omTjjuI6poafn33I7y96H3y+TznnXkE29ZzTlvRyN7tSnefX+KSTwIjzawHsAo4Gjgrlj4V6GFme7r7LOAI4J/uvs7MJgPHAeOAU4DHSpU/0yCZopu+P3AXsBnwLPCj2POCVudr1oOO7fKcOXYGu/XajAsO3olLHnipLt223ZSr/jYbf+fDumNvLf2IR18Kj18u/qbx8Ky3FSCb0PR/vsa6j6u47soz+M8bldw77h/87CfHbZDniYn/5K3Kd9l1lx0A+Oe//gPAtVeczitz5jO2nnPako09BMjdF5rZcGAS0AG4y92nm9kE4Ap3n2FmRwF3mlkXQs3z5Oj0c4F7zWwE8BZwfKn7ZRYkY930ewNrgalmNsndZ8ey3Qf80N1fiB6yngnckVWZmtue22/O83OXAvDqwhXsst2mG6Tvst1mnLp/X7bs2oEpry/hf6cuiKVtyud6dOGmx71Jy9zWvfaf/9J/j88DsPOOvXlz3qIN0v31Sl5/YyGHHLg3CxctAWCfgbuw9147A7BkyQdsvlmXpi102UkxmLyR3dvuPo5QG4wfGxL7fhobduYUji8gPK9MLcuaZF03PYCZFbrpr472dwA6ufsLUf6xwFUUBUkz2xzYvOjaJXukylGXjhWsitUCa2qhIpejujY8S/7Hq4t5cEYlq9ZW8Ytj92D/HVcy5Y33ATht/77c9ey8Zil3W7Z69Vo6d96kbj+fz1FdXUNFRZ5lyz/kz+Of4ZIff4+p02ZvcF5FRZ5f/uZvTJ/xGhddcEzxZduUXD4Hpd7NLuN3t7Ps3a6vm753I9ILLuSTvV2TN2ZBm8qqtdV07lBRt5/PURcgAf44/S0+WL2Oqppapr6xhJ23DTXNrh3bscOWXfjXgmVNXua2rlOnjqxZs7Zuv6amloqK8GszddocPvzwI6696X7GPzKF555/hUnPzqrLe/7Z3+b2G8/j13c/ypo1Hzd52ctFI3u3y06WQbJUN32p9IJRQL+ibXA9+creS5XL+fKOWwKwW6/NmPvu+rehunSsYNzZX6JT+xBE9+67Ba8tCs8m9+qzOS/OW9r0BRZ22Xl7/jXzDQD+80Ylfbbfui7tsG/sww0/P5Orh5/CUYfvz1f2250Dv7onzzz3En996DkAOnZsTz6XK+vlCbJWmJk8eWvuUjYsy+Z2qW76SkIXfEPpAESDSJfHj9Uz2LRFePq19xjUbwt+e+re5HI5rnl4Nofutg2dOlTwt3+/zR2T5jLm5AGsq67hxXlLeX5uaGr32bIzC5evLnF1ycI+e+/CrFfe5LKrfgfUct6ZRzJ56susWbOOQ74+oN5z9h24C2PufIjLr7mX6upqTjvpUDp0aLsDSXJaLbFBid307r7AzNaY2f7uPoXQ+1SyO74lqwVueGzDjpcF739U9/3jL7/D4y+/84nz/vDCW1kXTRqQz+c4+/TDNjjWq+dWn8h34Ff3rPt+k006cNH5bfs5ZFya3u1yrkpm1gZw94VAoZt+JjCu0E1vZgOjbCcCt5rZa0BX4PasyiMizSM8biixlXGQzLQNkKKbfhb1dNOLSCuSoiJZW74xUm/ciEi28imWb6jN50q/RN1MFCRFJFNpHkm21Y4bEZF04yDb6jNJERHVJEVEEuRy+ZKD6Wty5TvYXkFSRDLVwodJKkiKSLa07raISALVJEVEEhQmuCiVp1wpSIpIplSTFBFJUHg/OzlT+UZJBUkRydjGX76hKSlIikim1NwWEUmgIUAiIglUkxQRSZCm46a2kR03ZnYCMAJoD4xy9zFF6VcCZwCF1fPudPcxZnYqcD2wODr+qLsPT7qXgqSIZGpjN7fNrBdwLbA3sBaYamaT3D2+ru9A4Pvu/nzR6QOBYe5+f9r7KUiKSKYaGSR717PQ3/JoQcCCg4GJ7r4UwMweBI4Bro7lGQhcZmY7AM8CF7v7GmAQsJOZXQbMAs5398S1mst36g0RaTUKzyUb2mImA/OKtguLLtcTWBTbXwT0LuyYWVfg38BPgQHA5sDlsbw/B/YA/guMLlV21SRFJFONrEkOJiw3Hbe8aD9PWHy07nRYv/qDu68E6tbSMrObgXuA4e5+VOz4DcDcUuVXkBSRTDWyd7vS3eeXuGQlIZgWbAu8Xdgxsz7Awe5+T+HywDoz6wac4e63xo5XlSq/mtsikql8ntJLyjYuEj0JHGRmPcysM3A08HgsfTVwg5n1M7MccB4wHlgJXGJm+0b5hkbHk8vfqKKJiDRSPpdLtaXl7guB4cAkYCYwzt2nm9kEMxvo7u8BZwMPA06oMd7s7tXA94A7zGwOoXf8klL3a7C5bWZblCjo0nQfSUTasiwGk7v7OGBc0bEhse//AvylnvMmEzpzUkt6JrmE8HC0vuLXAhWNuZGItFGtdbVEd1dTXEQ+szylZ0Ir52BTsnfbzPLAMGB34HzCw84bova9iEiiNK8llpxvshmlGQJ0I9CDMFI9D3wT2A64IMNyiUgrkYv+K5WnXKWp5R4EnAascfcPgEOBQ7IslIi0Hvlcuq1cpQmS69w9Ppp9LSkGYIqIAHUdN0lbi+y4iXnFzM4DKiy8eT6MMDZJRKSklj6fZJqa5I8J44q2AaYAXfnkC+ciIvXa2IPJm1rJmqS7rwB+0ARlEZFWKJ9L0bvdkoOkmW0N3EborFkHTAAuKprfTUSkXm2huX0n8CawD/BVwnTov8myUCLSeuRypZvc5Rwk03Tc9HX3b8f2Lzazl7MqkIi0LjlKr6pdxjEyVU3ybTPrV9gxs95sOCuwiEiDSg3/STMpb3NKmgXoYcJEFj2AmWb2JFANHAi81DTFE5GWLs1g8XIeTJ7U3H6wgeOPZlEQEWmdWu272+5+b33Ho5l+d8ysRCLSqmzsJWWbWpohQGcTJrnoEjv8HmFdCRGRRDlKN6fLN0Sm67j5GWGM5KPAXsAVpFgXQkQEWn7HTZogudTdpxHe197G3a8FvpZpqUSk1cil3MpVqlmAzKw78DphQDlo6QYRSakin0u1las0g8l/CzwCHEEYCnQU8FqmpRKRVqPVd9y4+z1m9id3X2Vm+wEDgb9nXzQRaRXSTBfZyBhpZicAI4D2wCh3H1OUfiVwBuE1aoA73X2MmfUB7gO2Jiw3e6K7r0y6V9Jg8mFF+/Hdc4FbUn0aEWnT0kyF1phZgMysF3AtYd3stcBUM5vk7rNj2QYC33f354tO/xXwK3f/o5ldDlwOXJp0v6Sa5BcT0mqTLioiUpDBLEAHAxPdfSmAmT0IHANcHcszELjMzHYAngUuJrwx+FXgO1GescAzfNog6e6nN6rYzWD8+V+mV6/ezV0MSan7oKHNXQRphIqa1fTaCNfJUfqZYyy1d1GrFWB50dSMPdlw/ohFrO9Uxsy6Av8Gfgq8QQiGlwOjgRXuXhU7r2QASdNxIyLyqVXkclSUCJKx9Mn1JF8FjIzt59mwNZsD4utwrQSGFPbN7GbgHkJTu7gVXEMJ5bwmuIi0ArkUKyXGYuhgoF/RNqrokpWEZa0LtgXeLuyYWR8zOyNeBMKE4e8C3cysMIRxu/h5DVFNUkQy1chZgCrdfX6JSz4JjDSzHsAq4GjgrFj6auAGM5sEzAfOA8a7+zozmwwcB4wDTgEeK1X+NO9u54GLgN2BodF2g7tXlzpXRGRjj5N094VmNhyYBHQA7nL36WY2AbjC3WdEc048HKU/B9wcnX4ucK+ZjQDeAo4vdb80NckbCXNKDiJUW79JqKZekPpTiUiblcV8ku4+jlAbjB8bEvv+L8Bf6jlvAXBAY+6V5pnkQcBpwJpo5cRDCRNeiIiUVBgCVGorV6ne3Xb3eM/RWqAqIb+ISJ2KXI52JbZSvd/NKU1z+xUzOw+osDCAaRhhRiARkZLCOMnSecpVmprkj4EBwDbAFKArcGGGZRKRVqTUcrJpXltsTmkmuFgB/KAJyiIirVAGryU2qTRDgG6v77i7q3dbRErKpejdbtFBEng/9n0H4HDg6UxKIyKtTppJdVv0pLvuflV838yuBx7KrEQi0qq09HW3G/3utrt/CBtlchARaQNyKf8rV2meSf6S9TNn5AgTXc7JslAi0nq0hWeSS2Lf1wK/B/6QTXFEpLXJk6K53SQl+XTSBMnPu/spmZdERFqllr4QWJoAvqeZle8nEJGyVpFPt5WrNDXJRcCrZvYCULeqmMZJikga4ZlkqZpkExXmU0haLbFjNJnF89EmItJoLX0IUFJN8nlgQPE4SRGRxmjNryWWcbFFpKXIkyNfIpyUSm9OSUFyEzPbiwaCpbv/K5siiUhr0pprkp8jTH9eX/Fro3QRkUQVuRztSr27XcZRMilIznb3vZqsJCLSKrXmmqSIyGeWZlLdljrp7rNNVgoRabWyqEma2QnACKA9MMrdxzSQ7zBgtLv3i/ZPBa4HFkdZHnX34Un3ajBIuvuPG1dsEZFPylH61b7GxEgz6wVcS5hsZy0w1cwmufvsonzbADcVXX4gMMzd7097vzJ+GUhEWoMM1rg5GJjo7kvdfRXwIHBMPfnuAorHeQ8CTjWzl83sPjPrXupmeiYpIplq5DPJ3mFR1g0sd/flsf2ehNelCxYB+8RPMLMLgH8BLxRdaxGhdjkVuA4YDZyYVDYFSRHJVI7SzelY+uR6kq8CRsb286yf47Zwek1hx8x2B44GDgJ6xy/k7kfF8t0AzC1RNAVJEclWIztuBgOVRcnLi/Yro3wF2wJvx/aPBbYDZhDW5eppZpMJ63Od4e63Fm4LVJUqv4KkiGSs9HySsbpkpbvPL5H5SWCkmfUAVhFqjWcVEt39SuBKADPrCzzt7oPNrAK4xMymuvs0YCgwvlTp1XEjIpnKp9zScveFwHBgEjATGOfu081sgpkNTDivGvgecIeZzSH0jl9S6n6qSYpIprIYTO7u44BxRceG1JNvPtA3tj8ZGNCYeylIikimwjPJVjjprojIxpCmOV3Oz/0UJEUkWykWAivnqqSCpIhkqpHjJMuOgqSIZEpTpYmIJKjI5UpOqttSJ90VEfnMctF/pfKUKwVJEcmUmtsiIglyKVZLVE1SRNos1SRFRBLkSfFaomqSItJW5XNhK5WnXClIikim1LstIpIkxTPJMo6RCpIiki3VJBOY2WaEBXcOL55t2Mz6E1Yz24ywxveP3L3kVOotWU1NDRf94k+8+vpCOrRvx+0jTuRz2/eoS39o4r8ZNfYf5HI5Tj1qf075zpdZV1XN0Kvv461FS/n44youOuMbDPnaHs34KdqWXC7HzZcex2479eLjdVVccM0fmFe5pC59r137cO2F3yWXy7H4/RWcfcW9VFfXcMfIU+jTcwuqq2v48bX38/qCxQl3ad1a+jPJzGYoMrN9geeAnRvIch8w1N13JlS2z8yqLOXi0adfYu3aKp6452KuHPptRoz6a11adXUNV41+iPG/Op8n7rmIX/7+Sd5fvpI/T5jOFt268NidP+GB287hkhsfaMZP0PYcdsAedOzYjm/84GauGv03rrnwuxuk3zb8BM67+j6+deatPPX8bLbfbgsO2X83KiryfOMHt3DDXY8z4twjmqn05SEEyVJLyjZ3KRuWZU3yTOA84PfFCWa2A9DJ3QvLPY4lrIh2R4blaXYvzJrLQV/+AgCDvtiPmXPeqkurqMgz7c8jaNeugveWfkgttXTp1JFvHzyAIw/aqy5fu4pynnmv9fnSnp/nqalzAJjxynz6f6FPXdqOO2zN0g9Wcc7xB7Lrjj154rlXeWPBu+RzOdq1y5PL5di0yyZUVVU3V/HLgmYBaoC7/xCgnjV0of51c3vXl9HMNgc2Lzpcb95y9+GqNWzWpVPdfj6fp6qqmnbtKgBo166ChyfO5Kc3/JlDv7Ib7dtVsEnH9nXnnvqzuxl+zuHNUva2atMum7Bi1eq6/ZqaGioq8lRX17Blt67s88V+XHrjA8x9613+eOs5zHztLea+9S59ttuS6Q9czpabd+H7w37djJ+g+eVSLN9QeqGw5tNc1ZLEdXOLXAjMK9rqW5u37G3aZRNWfrS2br+2trYuQBYc8fX+zJ5wDR+vq+aPj04DoPKdZRx5zm0cN2Qfjv3moCYtc1v34ao1dO3csW4/l8tRXR3+V136wSrmVS7B571DVXUNTz0/m/679OGc47/OxBfmMOiYqxl84v/wqytPpmOHtttHmku5lavmCpKVhHVxC4rXzY0bBfQr2gY3kLes7bvn5/jHlFcBePHleXzh8z3r0lasXM1hZ41i7cfryOfzdO7UgXw+x7vvr+Do80czcuh3OOnI/Zqr6G3WtFlvcsj+uwEwcPe+zJm7/n/T+QuX0KVTB/r13gqA/fb6PK+9uYjlH37EipWh9rnsg49o366CinwbfkzSwqNks/x5c/cFZrbGzPZ39ynAycBjDeRdTtHi5A004cve4QfsyaRpr3HoGTcDtYy+4iQeePxFVn20ltO++xWO/eZADjtrFO3aVbDbjr343rf2Yfitf2X5io+48e7HuPHu8E/0wG3n0mmTDs37YdqIR56exYH77sLf7x4G5Bh69X0c842BdOnckXvHT+H8a8Zx5zWnkcvlmP7Smzwx5VWm/Ot1fnn5SUz47YW0b9+On//qYT5a83Fzf5Rmk8VqiWZ2AjACaA+McvcxDeQ7DBjt7v2i/T6ETuOtAQdOdPeVSffK1dbWJqV/ZmY2HzjA3eeb2QTgCnefYWZ7AncShgD9Czjd3dcmXCp+zb7AvAlPPEWvXi3y8WSb1H3Q0OYugjRCRc1qeq15DqBf8RC+NAq/p7eO/T96bNMzMe97i9/mJ6d9J9W9zKwXYeTM3sBawjDD4919dlG+bYCnCZ3EfaNjjwD3ufsfzexyoKu7X5p0v8xrkoXCRd8PiX0/C9gn6/uLSBnYuM3pg4GJ7r4UwMweBI4Bri7Kdxdh1Mz1Ub72wFeB70TpY4FngOYNkiLStjXyjZve9TxOWx49diuob3TMBhUuM7uA0EJ9IXZ4K2BF7KWVBkfVxClIikimGjmfZH0jV64CRsb2E0fHmNnuwNHAQWwYBIvPg4ZH1dRRkBSRTDVyMPlgwuiXuOVF+5VsOMKleHTMsYTRMzOADkBPM5sMfB3oZmYV7l4d5WloVE0dBUkRyVYuV3qw+Pr0yhSdRE8CI82sB7CKUGs8q5Do7lcCV0Jd59HT7j442p8MHAeMA06hgVE1cW148JaINIVCc7vUlpa7LwSGA5OAmcA4d59uZhPMbGCJ088FzjKz2YTa6IhS91NNUkQylcW72+4+jlAbjB8bUk+++UDf2P4C4IDG3EtBUkSy1cJnuFCQFJFMadJdEZEEWlJWRCSBgqSISAI1t0VEEqgmKSJSQhnHwJIUJEUkey04SipIikimsph0tykpSIpIplr4WHIFSRHJWAuPkgqSIpKpECNLDQEqXwqSIpIpDQESEUnQwlvbCpIikq1cikl3S07K24wUJEUkW2km1S3fGKkgKSLZUnNbRCRJC4+SCpIikinNAiQikkBDgEREEuSBfIkgWM7LtipIikjGWvZDSQVJEclUFs1tMzuBsGZ2e2CUu48pSj8KuAqoAF4EznL3j83sVOB6YHGU9VF3H550LwVJEcnUxq5Hmlkv4Fpgb2AtMNXMJrn77Ci9CzAaGODui83sj8BpwG+BgcAwd78/7f0UJEUkW40bTN7bzIpTl7v78tj+wcBEd18KYGYPAscAVwO4+yoz6+vu68ysM7A1sCw6dxCwk5ldBswCznf3ZSQo5+elItIKFF5LLLVFJgPzirYLiy7ZE1gU218E9I5niALkt4D/AlsBT8Ty/hzYI0obXar8qkmKSKYa2dweDFQWJS8v2s8DtUWn1xRf090fA7Y0s+uAO4AT3P2oQrqZ3QDMLVE0BUkRyVYjO24q3X1+iUtWEoJpwbbA24UdM9sCGOjuhdrjH4A/mVk34Ax3v7VwW6CqVPnV3BaRTOVS/tcITwIHmVmP6Jnj0cDjG9wS7jOzPtH+scBzwErgEjPbNzo+FBhf6mYKkiKSrVzKLSV3XwgMByYBM4Fx7j7dzCaY2UB3fx84C3jEzGYBBlzq7tXA94A7zGwOoXf8klL3U3NbRDKVxVBydx8HjCs6NiT2/f8B/1fPeZOBAY25l4KkiGRKS8qKiCRp4ZPu6pmkiEgC1SRFJFM5UgwBapKSfDoKkiKSKU26KyKSQJPuiogkUJAUEUkQxkmWam6XLwVJEcmUapIiIgla9uINCpIikrUWHiVbapCsAFj8zjvNXQ5phIqa1c1dBGmEipo1dd9+luu8u3hxfFLdBvOUq5YaJLcDOP2UE5u7HNIIvZq7APJpbUeKyWnrsQJYdvopJ3ZPmX9ZdE5ZaalB8kXCpJuLgOpmLsvG1JswfX19szNLeWrNP7MKQoB88dOc7O5LzWxHYLOUp6worFtTTnK1tbWlc0mTMLO+hDU9+qWYnVnKgH5mrZ8muBARSaAgKSKSQEFSRCSBgmR5WQ5cxSeX0JTytRz9zFo1ddyIiCRQTVJEJIGCpIhIgpY6mLzFM7MTgBFAe2CUu48pSu8P3EUYiPss8CN3r2rqcsqGzGwzYCpwePG4SP3MWifVJJuBmfUCrgW+AvQHzjKzXYuy3QcMdfedCa//n9mkhZRPMLN9geeAnRvIop9ZK6Qg2TwOBia6+1J3XwU8CBxTSDSzHYBO7v5CdGgscGyTl1KKnQmcB7xdnKCfWeul5nbz6El477xgEbBPifTeTVAuSeDuPwQws/qS9TNrpVSTbB55ID72KgfUNCJdyo9+Zq2UgmTzqCSa7i2yLRs24UqlS/nRz6yVUpBsHk8CB5lZDzPrDBwNPF5IdPcFwBoz2z86dDLwWNMXU9LSz6z1UpBsBu6+EBgOTAJmAuPcfbqZTTCzgVG2E4Fbzew1oCtwe7MUVhLpZ9b66bVEEZEEqkmKiCRQkBQRSaAgKSKSQEFSRCSBgqSISAK9ltiKRCv3zQVejh3OAbe5+z2f8dqPAA+6+1gzmwkc4O7LG8jbDRjv7l9v5D2OIUwQcUDR8QOA0e6+e4nza4Ee7r6kEfccC7zi7jc1pqzSdihItj6r3b1/YSeacegVM5vh7i9tjBvEr9+A7mz4LrpIi6Ug2cq5+0Izex3Y2cwGAD8AugAfuPuBZvYD4FzCo5f3CTW518ysJ3AvYeKGBcDWhWvGa2xm9v+AU4Eq4HXgNOB3QKeoxrk3YWqx24AtCQve316o2ZrZ1YRB2O9H5ycys52BMcCmhNcAZwLHufuaKMu1ZjYo+jwj3P2R6Lx6P2cj/imljdIzyVbOzPYDdgSmRYd2IzSVDzSzrxEC3GB33wu4ARgf5RsDvODuuwEXALvUc+0jCUFxv6gpPA8YCpzO+hptjjAV3M/cfW/ga8DFZvYlM/s24ZXM/sCXgW4pPtKZwL3u/qXoc/UDDoulv+nuA4CTgHujVz+TPqdIItUkW59CDQ7Cz3cJcKK7/zea4usld18RpR9GCDRTY9N/dTezLQhzXl4M4O5vmNnEeu51MPCAuy+L8g2DumejBTsDnwfuid2jE7AXsCvwV3f/MDrvHkJATnIpcIiZXRJduyfhFcCCX0dlecXMZgP7ESY3buhziiRSkGx9Vpd4Zrgy9n0F8Ht3vxTAzPKEoLOMMO1XLpa3vmUIqohND2ZmmwObF+WpIDTt+8fybQN8ANyY4h7F7if8f/tn4FGgT9E1qmPf54F1JH9OkURqbrdtfweON7PCFF8/Ap6Kvn8cOAvAzPoAB9Zz/pPAd6N1XwBGAsMIwa7CzHKAA6vN7KToWtsDrxCeVT4GHGtmm0eB6+QUZf4GcLW7/yna35cQBAtOi+4zgPWPGZI+p0gi1STbMHd/wsx+AfzDzGqAFcB33b3WzM4DfmdmcwhzJc6s5/wJ0do8U6Jm7KuEZ4YfAdOj/cHAt4HboiZye+Byd58CYGZfBGYQanWzgB4lin0ZMN7MVhFqo88QgmHB58zs34Qa7vfdfSmQ9Dkb8S8mbZFmARIRSaDmtohIAgVJEZEECpIiIgkUJEVEEihIiogkUJAUEUmgICkikkBBUkQkwf8Hv0Q5g6HzU9oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model_evaluation(logistic_regression_optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90ea97d",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6c093a2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-12T23:20:11.755911Z",
     "start_time": "2023-03-12T23:20:05.859246Z"
    }
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4efdb25e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-12T23:20:17.800483Z",
     "start_time": "2023-03-12T23:20:11.788030Z"
    }
   },
   "outputs": [],
   "source": [
    "#LightGBM classifier\n",
    "X_train = X_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "X_test = X_test.rename(columns=lambda x:re.sub('[^A-Za-z0-9_]+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "49c1d8f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-12T23:23:14.353502Z",
     "start_time": "2023-03-12T23:22:08.693784Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /tmp/pip-req-build-tbfphzo4/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /tmp/pip-req-build-tbfphzo4/compile/src/boosting/rf.hpp, line 35 .\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rm/h7csftjd5bs95gx889r84c2r0000gn/T/ipykernel_4554/2134419350.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlgbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLGBMClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboosting_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlgbm_smote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'smote'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmote\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlgbm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlgbm_smote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/imblearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    888\u001b[0m                     \u001b[0mvalid_sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m         super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n\u001b[0m\u001b[1;32m    891\u001b[0m                     \u001b[0meval_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_sample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m                     \u001b[0meval_class_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_class_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_init_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_init_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0minit_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbooster_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m         self._Booster = train(params, train_set,\n\u001b[0m\u001b[1;32m    684\u001b[0m                               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_sets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;31m# construct booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0mbooster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[1;32m   2232\u001b[0m             \u001b[0mparams_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_dict_to_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2233\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2234\u001b[0;31m             _safe_call(_LIB.LGBM_BoosterCreate(\n\u001b[0m\u001b[1;32m   2235\u001b[0m                 \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2236\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \"\"\"\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLightGBMError\u001b[0m: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /tmp/pip-req-build-tbfphzo4/compile/src/boosting/rf.hpp, line 35 .\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(random_state=42, n_jobs=-1, boosting_type='rf')\n",
    "lgbm_smote = Pipeline([('smote', smote), ('model', lgbm)])\n",
    "lgbm_smote.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "14d73e8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T08:34:25.356472Z",
     "start_time": "2023-03-10T08:34:25.047655Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pour le seuil 0.2, le f3_score est : 0.33 et le mean score est : 0.601\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = lgbm_smote.predict_proba(X_test)[:,1]\n",
    "threshold_f3 = custom_metric(y_test, y_pred_proba, return_proba=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a4d6895f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T08:34:26.610616Z",
     "start_time": "2023-03-10T08:34:26.235934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.872268\n",
      "f3_score : 0.330425 \n",
      "\n",
      "Mean evalation score : 0.601347\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(lgbm_smote, X_test, y_test, threshold_f3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adb59b5",
   "metadata": {},
   "source": [
    "### Optimisation & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5b498dba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T08:34:39.606734Z",
     "start_time": "2023-03-10T08:34:39.504765Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'500409515578582350'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_id = dict(mlflow.set_experiment(\"LightGBM Hyperparameter(1) Tuning\"))['experiment_id']\n",
    "experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "903d4564",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:00:45.193753Z",
     "start_time": "2023-03-10T08:35:23.968035Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-10 09:35:24,580]\u001b[0m A new study created in memory with name: Hyperparameters optimization\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:36:56,470]\u001b[0m Trial 0 finished with value: 0.4261745197517476 and parameters: {'n_estimators': 897, 'learning_rate': 0.08178609709380619, 'num_leaves': 2120, 'max_depth': 10, 'min_data_in_leaf': 300, 'max_bin': 227, 'lambda_l1': 50, 'lambda_l2': 25, 'min_gain_to_split': 14.480398448018658, 'bagging_fraction': 0.6000000000000001, 'bagging_freq': 1, 'feature_fraction': 0.6000000000000001}. Best is trial 0 with value: 0.4261745197517476.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:37:44,225]\u001b[0m Trial 1 finished with value: 0.45981360658307285 and parameters: {'n_estimators': 1593, 'learning_rate': 0.12645911392074313, 'num_leaves': 1720, 'max_depth': 4, 'min_data_in_leaf': 6700, 'max_bin': 232, 'lambda_l1': 40, 'lambda_l2': 20, 'min_gain_to_split': 4.843563335373039, 'bagging_fraction': 0.5, 'bagging_freq': 1, 'feature_fraction': 0.9}. Best is trial 1 with value: 0.45981360658307285.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:38:30,725]\u001b[0m Trial 2 finished with value: 0.4767253936454748 and parameters: {'n_estimators': 649, 'learning_rate': 0.19665206234607682, 'num_leaves': 360, 'max_depth': 8, 'min_data_in_leaf': 4500, 'max_bin': 278, 'lambda_l1': 75, 'lambda_l2': 30, 'min_gain_to_split': 5.714406546622209, 'bagging_fraction': 0.4, 'bagging_freq': 1, 'feature_fraction': 0.5}. Best is trial 2 with value: 0.4767253936454748.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:39:15,970]\u001b[0m Trial 3 finished with value: 0.40644363790474375 and parameters: {'n_estimators': 1405, 'learning_rate': 0.22900838533860177, 'num_leaves': 240, 'max_depth': 9, 'min_data_in_leaf': 2000, 'max_bin': 272, 'lambda_l1': 60, 'lambda_l2': 10, 'min_gain_to_split': 4.354187021237242, 'bagging_fraction': 0.5, 'bagging_freq': 1, 'feature_fraction': 0.7}. Best is trial 2 with value: 0.4767253936454748.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:40:24,934]\u001b[0m Trial 4 finished with value: 0.38501381111532484 and parameters: {'n_estimators': 1004, 'learning_rate': 0.08187366666716915, 'num_leaves': 1460, 'max_depth': 8, 'min_data_in_leaf': 2900, 'max_bin': 295, 'lambda_l1': 55, 'lambda_l2': 5, 'min_gain_to_split': 0.3775217283797039, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'feature_fraction': 0.4}. Best is trial 2 with value: 0.4767253936454748.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:40:48,800]\u001b[0m Trial 5 finished with value: 0.45393815007429544 and parameters: {'n_estimators': 672, 'learning_rate': 0.05876682548700404, 'num_leaves': 2260, 'max_depth': 3, 'min_data_in_leaf': 4500, 'max_bin': 268, 'lambda_l1': 60, 'lambda_l2': 40, 'min_gain_to_split': 2.6500568825569992, 'bagging_fraction': 0.4, 'bagging_freq': 1, 'feature_fraction': 0.6000000000000001}. Best is trial 2 with value: 0.4767253936454748.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:41:34,708]\u001b[0m Trial 6 finished with value: 0.4316901507542477 and parameters: {'n_estimators': 711, 'learning_rate': 0.21758462219043836, 'num_leaves': 2540, 'max_depth': 8, 'min_data_in_leaf': 1400, 'max_bin': 245, 'lambda_l1': 80, 'lambda_l2': 15, 'min_gain_to_split': 8.251601414088265, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'feature_fraction': 0.4}. Best is trial 2 with value: 0.4767253936454748.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:42:48,805]\u001b[0m Trial 7 finished with value: 0.5024782736034382 and parameters: {'n_estimators': 1622, 'learning_rate': 0.053341953116330915, 'num_leaves': 1840, 'max_depth': 9, 'min_data_in_leaf': 2500, 'max_bin': 220, 'lambda_l1': 100, 'lambda_l2': 95, 'min_gain_to_split': 3.1257611882956606, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.2}. Best is trial 7 with value: 0.5024782736034382.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:43:08,347]\u001b[0m Trial 8 finished with value: 0.0 and parameters: {'n_estimators': 818, 'learning_rate': 0.04760320595277423, 'num_leaves': 1260, 'max_depth': 11, 'min_data_in_leaf': 7400, 'max_bin': 290, 'lambda_l1': 65, 'lambda_l2': 25, 'min_gain_to_split': 10.030627361449417, 'bagging_fraction': 0.4, 'bagging_freq': 1, 'feature_fraction': 0.4}. Best is trial 7 with value: 0.5024782736034382.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:43:24,743]\u001b[0m Trial 9 finished with value: 0.4345030738369401 and parameters: {'n_estimators': 311, 'learning_rate': 0.28758135523205863, 'num_leaves': 500, 'max_depth': 6, 'min_data_in_leaf': 4400, 'max_bin': 257, 'lambda_l1': 80, 'lambda_l2': 15, 'min_gain_to_split': 6.130039755434627, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'feature_fraction': 0.8}. Best is trial 7 with value: 0.5024782736034382.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:43:50,863]\u001b[0m Trial 10 finished with value: 0.0 and parameters: {'n_estimators': 1899, 'learning_rate': 0.01441051017198755, 'num_leaves': 2840, 'max_depth': 12, 'min_data_in_leaf': 9100, 'max_bin': 200, 'lambda_l1': 0, 'lambda_l2': 100, 'min_gain_to_split': 0.1315660006026702, 'bagging_fraction': 0.2, 'bagging_freq': 1, 'feature_fraction': 0.2}. Best is trial 7 with value: 0.5024782736034382.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:44:52,449]\u001b[0m Trial 11 finished with value: 0.38518811056680724 and parameters: {'n_estimators': 1272, 'learning_rate': 0.14857493097321423, 'num_leaves': 940, 'max_depth': 6, 'min_data_in_leaf': 3500, 'max_bin': 201, 'lambda_l1': 100, 'lambda_l2': 75, 'min_gain_to_split': 3.0860040088262277, 'bagging_fraction': 0.2, 'bagging_freq': 1, 'feature_fraction': 0.2}. Best is trial 7 with value: 0.5024782736034382.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:45:55,437]\u001b[0m Trial 12 finished with value: 0.0 and parameters: {'n_estimators': 1881, 'learning_rate': 0.17391687779467285, 'num_leaves': 860, 'max_depth': 6, 'min_data_in_leaf': 5700, 'max_bin': 223, 'lambda_l1': 100, 'lambda_l2': 60, 'min_gain_to_split': 7.140262345543245, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.30000000000000004}. Best is trial 7 with value: 0.5024782736034382.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:46:32,765]\u001b[0m Trial 13 finished with value: 0.4088322620253856 and parameters: {'n_estimators': 474, 'learning_rate': 0.11136576726144451, 'num_leaves': 40, 'max_depth': 10, 'min_data_in_leaf': 2800, 'max_bin': 279, 'lambda_l1': 85, 'lambda_l2': 100, 'min_gain_to_split': 2.519424121252995, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.5}. Best is trial 7 with value: 0.5024782736034382.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:47:34,095]\u001b[0m Trial 14 finished with value: 0.0 and parameters: {'n_estimators': 1579, 'learning_rate': 0.16596257352519828, 'num_leaves': 1760, 'max_depth': 7, 'min_data_in_leaf': 5600, 'max_bin': 246, 'lambda_l1': 30, 'lambda_l2': 45, 'min_gain_to_split': 5.523362177509995, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.30000000000000004}. Best is trial 7 with value: 0.5024782736034382.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:48:50,020]\u001b[0m Trial 15 finished with value: 0.5151607824711615 and parameters: {'n_estimators': 1137, 'learning_rate': 0.010943115173500245, 'num_leaves': 1060, 'max_depth': 9, 'min_data_in_leaf': 200, 'max_bin': 215, 'lambda_l1': 90, 'lambda_l2': 80, 'min_gain_to_split': 9.519601277844671, 'bagging_fraction': 0.4, 'bagging_freq': 1, 'feature_fraction': 0.5}. Best is trial 15 with value: 0.5151607824711615.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:49:16,278]\u001b[0m Trial 16 finished with value: 0.532015131356277 and parameters: {'n_estimators': 1142, 'learning_rate': 0.01879731476546734, 'num_leaves': 1060, 'max_depth': 10, 'min_data_in_leaf': 300, 'max_bin': 216, 'lambda_l1': 95, 'lambda_l2': 80, 'min_gain_to_split': 9.89401805518984, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.7}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:49:42,012]\u001b[0m Trial 17 finished with value: 0.4771607082221518 and parameters: {'n_estimators': 1143, 'learning_rate': 0.01074175952818923, 'num_leaves': 960, 'max_depth': 12, 'min_data_in_leaf': 600, 'max_bin': 212, 'lambda_l1': 15, 'lambda_l2': 80, 'min_gain_to_split': 10.31982759083144, 'bagging_fraction': 0.2, 'bagging_freq': 1, 'feature_fraction': 0.7}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:50:20,063]\u001b[0m Trial 18 finished with value: 0.4761897787431472 and parameters: {'n_estimators': 1096, 'learning_rate': 0.012568917571361332, 'num_leaves': 680, 'max_depth': 10, 'min_data_in_leaf': 1200, 'max_bin': 237, 'lambda_l1': 90, 'lambda_l2': 65, 'min_gain_to_split': 11.574101161043638, 'bagging_fraction': 0.6000000000000001, 'bagging_freq': 1, 'feature_fraction': 0.7}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-10 09:50:57,662]\u001b[0m Trial 19 finished with value: 0.46009810207795027 and parameters: {'n_estimators': 1296, 'learning_rate': 0.03551267846053546, 'num_leaves': 1260, 'max_depth': 11, 'min_data_in_leaf': 9800, 'max_bin': 215, 'lambda_l1': 90, 'lambda_l2': 85, 'min_gain_to_split': 8.435551667038133, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.9}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:51:24,791]\u001b[0m Trial 20 finished with value: 0.4788380897254839 and parameters: {'n_estimators': 1393, 'learning_rate': 0.09623583930134352, 'num_leaves': 1160, 'max_depth': 9, 'min_data_in_leaf': 300, 'max_bin': 209, 'lambda_l1': 70, 'lambda_l2': 60, 'min_gain_to_split': 12.555691659648055, 'bagging_fraction': 0.4, 'bagging_freq': 1, 'feature_fraction': 0.8}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:52:18,186]\u001b[0m Trial 21 finished with value: 0.46916726878025783 and parameters: {'n_estimators': 1579, 'learning_rate': 0.05317466691510842, 'num_leaves': 1780, 'max_depth': 9, 'min_data_in_leaf': 1900, 'max_bin': 218, 'lambda_l1': 100, 'lambda_l2': 90, 'min_gain_to_split': 9.499072963183066, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.6000000000000001}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:53:52,684]\u001b[0m Trial 22 finished with value: 0.48780873333191366 and parameters: {'n_estimators': 1745, 'learning_rate': 0.037070302579506005, 'num_leaves': 2040, 'max_depth': 11, 'min_data_in_leaf': 1300, 'max_bin': 233, 'lambda_l1': 90, 'lambda_l2': 70, 'min_gain_to_split': 8.249040317824887, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.5}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:54:50,353]\u001b[0m Trial 23 finished with value: 0.42562445175736857 and parameters: {'n_estimators': 983, 'learning_rate': 0.06621840363802617, 'num_leaves': 1500, 'max_depth': 7, 'min_data_in_leaf': 2600, 'max_bin': 208, 'lambda_l1': 100, 'lambda_l2': 90, 'min_gain_to_split': 7.004440933131735, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.30000000000000004}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:55:35,336]\u001b[0m Trial 24 finished with value: 0.49734640959757054 and parameters: {'n_estimators': 1293, 'learning_rate': 0.03046722180926953, 'num_leaves': 640, 'max_depth': 9, 'min_data_in_leaf': 3600, 'max_bin': 221, 'lambda_l1': 90, 'lambda_l2': 90, 'min_gain_to_split': 9.10679887947279, 'bagging_fraction': 0.5, 'bagging_freq': 1, 'feature_fraction': 0.8}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:57:06,067]\u001b[0m Trial 25 finished with value: 0.4896152510669737 and parameters: {'n_estimators': 1483, 'learning_rate': 0.06645758250813977, 'num_leaves': 1100, 'max_depth': 10, 'min_data_in_leaf': 900, 'max_bin': 240, 'lambda_l1': 75, 'lambda_l2': 55, 'min_gain_to_split': 11.39207509534875, 'bagging_fraction': 0.4, 'bagging_freq': 1, 'feature_fraction': 0.2}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:57:47,996]\u001b[0m Trial 26 finished with value: 0.44533147495791187 and parameters: {'n_estimators': 1709, 'learning_rate': 0.03630246199297216, 'num_leaves': 1580, 'max_depth': 11, 'min_data_in_leaf': 2100, 'max_bin': 258, 'lambda_l1': 95, 'lambda_l2': 75, 'min_gain_to_split': 7.0959875833786965, 'bagging_fraction': 0.2, 'bagging_freq': 1, 'feature_fraction': 0.7}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:58:31,178]\u001b[0m Trial 27 finished with value: 0.5163642521765919 and parameters: {'n_estimators': 1184, 'learning_rate': 0.07991007162368169, 'num_leaves': 1960, 'max_depth': 9, 'min_data_in_leaf': 1500, 'max_bin': 227, 'lambda_l1': 80, 'lambda_l2': 100, 'min_gain_to_split': 10.408877168713527, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.6000000000000001}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 09:59:30,085]\u001b[0m Trial 28 finished with value: 0.46847774326905095 and parameters: {'n_estimators': 1072, 'learning_rate': 0.08726564056959642, 'num_leaves': 2420, 'max_depth': 7, 'min_data_in_leaf': 300, 'max_bin': 229, 'lambda_l1': 80, 'lambda_l2': 80, 'min_gain_to_split': 10.921113447728718, 'bagging_fraction': 0.5, 'bagging_freq': 1, 'feature_fraction': 0.6000000000000001}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:00:47,126]\u001b[0m Trial 29 finished with value: 0.42541153981485225 and parameters: {'n_estimators': 872, 'learning_rate': 0.07623926736895735, 'num_leaves': 2040, 'max_depth': 10, 'min_data_in_leaf': 200, 'max_bin': 228, 'lambda_l1': 45, 'lambda_l2': 100, 'min_gain_to_split': 13.124149292158403, 'bagging_fraction': 0.6000000000000001, 'bagging_freq': 1, 'feature_fraction': 0.5}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:01:37,720]\u001b[0m Trial 30 finished with value: 0.48855356785837306 and parameters: {'n_estimators': 1225, 'learning_rate': 0.09847394078826233, 'num_leaves': 1380, 'max_depth': 5, 'min_data_in_leaf': 1600, 'max_bin': 206, 'lambda_l1': 70, 'lambda_l2': 70, 'min_gain_to_split': 14.177447476422731, 'bagging_fraction': 0.4, 'bagging_freq': 1, 'feature_fraction': 0.6000000000000001}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:02:01,840]\u001b[0m Trial 31 finished with value: 0.5155231257430939 and parameters: {'n_estimators': 927, 'learning_rate': 0.047063127016862, 'num_leaves': 1840, 'max_depth': 9, 'min_data_in_leaf': 1000, 'max_bin': 223, 'lambda_l1': 85, 'lambda_l2': 95, 'min_gain_to_split': 9.160904726733504, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.7}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:02:30,201]\u001b[0m Trial 32 finished with value: 0.5239502035034846 and parameters: {'n_estimators': 956, 'learning_rate': 0.025926382073491933, 'num_leaves': 1940, 'max_depth': 8, 'min_data_in_leaf': 1100, 'max_bin': 224, 'lambda_l1': 85, 'lambda_l2': 85, 'min_gain_to_split': 9.372157091577716, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.7}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:02:51,224]\u001b[0m Trial 33 finished with value: 0.41045027090174385 and parameters: {'n_estimators': 951, 'learning_rate': 0.0312997510206107, 'num_leaves': 2180, 'max_depth': 8, 'min_data_in_leaf': 1000, 'max_bin': 225, 'lambda_l1': 75, 'lambda_l2': 95, 'min_gain_to_split': 10.57573061634618, 'bagging_fraction': 0.2, 'bagging_freq': 1, 'feature_fraction': 0.7}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:03:12,295]\u001b[0m Trial 34 finished with value: 0.5155198646265183 and parameters: {'n_estimators': 803, 'learning_rate': 0.07127079487832078, 'num_leaves': 1980, 'max_depth': 8, 'min_data_in_leaf': 900, 'max_bin': 235, 'lambda_l1': 85, 'lambda_l2': 85, 'min_gain_to_split': 8.775260188999882, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.8}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:03:25,814]\u001b[0m Trial 35 finished with value: 0.4461971693372007 and parameters: {'n_estimators': 1039, 'learning_rate': 0.11314855318483977, 'num_leaves': 1640, 'max_depth': 8, 'min_data_in_leaf': 3500, 'max_bin': 242, 'lambda_l1': 35, 'lambda_l2': 95, 'min_gain_to_split': 9.841125421099212, 'bagging_fraction': 0.2, 'bagging_freq': 1, 'feature_fraction': 0.7}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:03:52,530]\u001b[0m Trial 36 finished with value: 0.4639844299420447 and parameters: {'n_estimators': 546, 'learning_rate': 0.05609072764456957, 'num_leaves': 2520, 'max_depth': 10, 'min_data_in_leaf': 2000, 'max_bin': 254, 'lambda_l1': 55, 'lambda_l2': 85, 'min_gain_to_split': 11.956003801619053, 'bagging_fraction': 0.5, 'bagging_freq': 1, 'feature_fraction': 0.9}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:04:10,993]\u001b[0m Trial 37 finished with value: 0.0 and parameters: {'n_estimators': 747, 'learning_rate': 0.08630465523205968, 'num_leaves': 2300, 'max_depth': 9, 'min_data_in_leaf': 7100, 'max_bin': 230, 'lambda_l1': 70, 'lambda_l2': 100, 'min_gain_to_split': 10.641140702742213, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.6000000000000001}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-10 10:04:33,531]\u001b[0m Trial 38 finished with value: 0.49720550476453085 and parameters: {'n_estimators': 912, 'learning_rate': 0.029624531074585483, 'num_leaves': 1840, 'max_depth': 7, 'min_data_in_leaf': 1500, 'max_bin': 223, 'lambda_l1': 85, 'lambda_l2': 90, 'min_gain_to_split': 7.709304447477036, 'bagging_fraction': 0.4, 'bagging_freq': 1, 'feature_fraction': 0.7}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.480398448018658, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.480398448018658\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l1 is set=50, reg_alpha=0.0 will be ignored. Current value: lambda_l1=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.843563335373039, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.843563335373039\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6700\n",
      "[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.714406546622209, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.714406546622209\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4500\n",
      "[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.354187021237242, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.354187021237242\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2000\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.3775217283797039, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.3775217283797039\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=2.6500568825569992, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.6500568825569992\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4500\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.251601414088265, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.251601414088265\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1400\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=3.1257611882956606, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.1257611882956606\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2500\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.130039755434627, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.130039755434627\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4400\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=3.0860040088262277, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.0860040088262277\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3500\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.523362177509995, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.523362177509995\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5600\n",
      "[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.519601277844671, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.519601277844671\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.89401805518984, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.89401805518984\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.435551667038133, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.435551667038133\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9800\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.555691659648055, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.555691659648055\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.499072963183066, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.499072963183066\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1900\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.249040317824887, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.249040317824887\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.004440933131735, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.004440933131735\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2600\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.39207509534875, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.39207509534875\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-10 10:04:52,570]\u001b[0m Trial 39 finished with value: 0.489312539051863 and parameters: {'n_estimators': 600, 'learning_rate': 0.04666887712265774, 'num_leaves': 2800, 'max_depth': 10, 'min_data_in_leaf': 2300, 'max_bin': 217, 'lambda_l1': 60, 'lambda_l2': 75, 'min_gain_to_split': 9.366316484154778, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.8}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.480398448018658, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.480398448018658\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l1 is set=50, reg_alpha=0.0 will be ignored. Current value: lambda_l1=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.843563335373039, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.843563335373039\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6700\n",
      "[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.3775217283797039, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.3775217283797039\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=2.6500568825569992, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.6500568825569992\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4500\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.030627361449417, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.030627361449417\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7400\n",
      "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=3.0860040088262277, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.0860040088262277\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3500\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=2.519424121252995, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.519424121252995\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2800\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.519601277844671, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.519601277844671\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.89401805518984, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.89401805518984\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.31982759083144, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.31982759083144\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=600\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.574101161043638, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.574101161043638\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.435551667038133, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.435551667038133\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9800\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.555691659648055, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.555691659648055\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.499072963183066, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.499072963183066\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1900\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.249040317824887, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.249040317824887\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.004440933131735, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.004440933131735\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2600\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.10679887947279, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.10679887947279\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3600\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.39207509534875, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.39207509534875\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.0959875833786965, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.0959875833786965\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2100\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-10 10:05:28,193]\u001b[0m Trial 40 finished with value: 0.4347161140404999 and parameters: {'n_estimators': 1177, 'learning_rate': 0.07666201609688766, 'num_leaves': 1920, 'max_depth': 3, 'min_data_in_leaf': 3300, 'max_bin': 211, 'lambda_l1': 75, 'lambda_l2': 95, 'min_gain_to_split': 8.901017463427527, 'bagging_fraction': 0.2, 'bagging_freq': 1, 'feature_fraction': 0.6000000000000001}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:05:45,292]\u001b[0m Trial 41 finished with value: 0.5156048484075533 and parameters: {'n_estimators': 804, 'learning_rate': 0.06939222240027774, 'num_leaves': 2000, 'max_depth': 8, 'min_data_in_leaf': 900, 'max_bin': 235, 'lambda_l1': 85, 'lambda_l2': 85, 'min_gain_to_split': 8.806760018674924, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.8}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.714406546622209, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.714406546622209\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4500\n",
      "[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.3775217283797039, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.3775217283797039\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.251601414088265, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.251601414088265\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1400\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=3.1257611882956606, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.1257611882956606\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2500\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.130039755434627, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.130039755434627\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4400\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.1315660006026702, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.1315660006026702\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9100\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=3.0860040088262277, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.0860040088262277\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3500\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=2.519424121252995, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.519424121252995\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2800\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.519601277844671, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.519601277844671\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.89401805518984, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.89401805518984\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.31982759083144, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.31982759083144\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=600\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.574101161043638, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.574101161043638\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.435551667038133, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.435551667038133\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9800\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.555691659648055, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.555691659648055\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.499072963183066, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.499072963183066\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1900\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.004440933131735, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.004440933131735\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2600\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.39207509534875, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.39207509534875\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.0959875833786965, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.0959875833786965\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2100\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.408877168713527, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.408877168713527\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1500\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.177447476422731, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.177447476422731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-10 10:06:04,802]\u001b[0m Trial 42 finished with value: 0.523130045631371 and parameters: {'n_estimators': 862, 'learning_rate': 0.049182708520117885, 'num_leaves': 2120, 'max_depth': 8, 'min_data_in_leaf': 800, 'max_bin': 250, 'lambda_l1': 95, 'lambda_l2': 85, 'min_gain_to_split': 10.00593329832756, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.7}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:06:25,372]\u001b[0m Trial 43 finished with value: 0.5076877206127782 and parameters: {'n_estimators': 774, 'learning_rate': 0.06494028931835684, 'num_leaves': 2180, 'max_depth': 8, 'min_data_in_leaf': 700, 'max_bin': 263, 'lambda_l1': 95, 'lambda_l2': 85, 'min_gain_to_split': 10.045969480496892, 'bagging_fraction': 0.4, 'bagging_freq': 1, 'feature_fraction': 0.8}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:06:43,583]\u001b[0m Trial 44 finished with value: 0.4752177046717022 and parameters: {'n_estimators': 855, 'learning_rate': 0.060366955043864204, 'num_leaves': 2680, 'max_depth': 8, 'min_data_in_leaf': 1600, 'max_bin': 249, 'lambda_l1': 95, 'lambda_l2': 70, 'min_gain_to_split': 11.234890700581659, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.9}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:07:15,383]\u001b[0m Trial 45 finished with value: 0.43635779206360414 and parameters: {'n_estimators': 649, 'learning_rate': 0.021189665450450784, 'num_leaves': 2420, 'max_depth': 7, 'min_data_in_leaf': 700, 'max_bin': 240, 'lambda_l1': 80, 'lambda_l2': 30, 'min_gain_to_split': 10.218159220934682, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'feature_fraction': 0.8}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.843563335373039, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.843563335373039\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6700\n",
      "[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.714406546622209, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.714406546622209\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4500\n",
      "[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.354187021237242, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.354187021237242\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2000\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=2.6500568825569992, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.6500568825569992\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4500\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.251601414088265, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.251601414088265\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1400\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.030627361449417, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.030627361449417\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7400\n",
      "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.130039755434627, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.130039755434627\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4400\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.1315660006026702, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.1315660006026702\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9100\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=3.0860040088262277, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.0860040088262277\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3500\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.140262345543245, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.140262345543245\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5700\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=2.519424121252995, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.519424121252995\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2800\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.31982759083144, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.31982759083144\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=600\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.574101161043638, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.574101161043638\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.555691659648055, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.555691659648055\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.499072963183066, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.499072963183066\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1900\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.10679887947279, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.10679887947279\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3600\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.0959875833786965, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.0959875833786965\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2100\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.408877168713527, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.408877168713527\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1500\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.921113447728718, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.921113447728718\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.160904726733504, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.160904726733504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.480398448018658, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.480398448018658\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l1 is set=50, reg_alpha=0.0 will be ignored. Current value: lambda_l1=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.843563335373039, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.843563335373039\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6700\n",
      "[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.714406546622209, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.714406546622209\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4500\n",
      "[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.354187021237242, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.354187021237242\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2000\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=2.6500568825569992, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.6500568825569992\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4500\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=3.1257611882956606, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.1257611882956606\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2500\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.030627361449417, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.030627361449417\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7400\n",
      "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.1315660006026702, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.1315660006026702\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9100\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.140262345543245, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.140262345543245\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5700\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.523362177509995, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.523362177509995\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5600\n",
      "[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.89401805518984, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.89401805518984\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.574101161043638, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.574101161043638\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.435551667038133, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.435551667038133\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9800\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.499072963183066, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.499072963183066\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1900\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.249040317824887, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.249040317824887\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.004440933131735, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.004440933131735\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2600\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.10679887947279, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.10679887947279\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3600\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.408877168713527, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.408877168713527\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1500\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.921113447728718, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.921113447728718\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-10 10:07:37,746]\u001b[0m Trial 46 finished with value: 0.48769818483702226 and parameters: {'n_estimators': 994, 'learning_rate': 0.044229891499706284, 'num_leaves': 2300, 'max_depth': 6, 'min_data_in_leaf': 3000, 'max_bin': 250, 'lambda_l1': 65, 'lambda_l2': 80, 'min_gain_to_split': 7.6486501190342, 'bagging_fraction': 0.4, 'bagging_freq': 1, 'feature_fraction': 0.7}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.480398448018658, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.480398448018658\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l1 is set=50, reg_alpha=0.0 will be ignored. Current value: lambda_l1=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.843563335373039, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.843563335373039\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6700\n",
      "[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.354187021237242, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.354187021237242\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2000\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.3775217283797039, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.3775217283797039\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=2.6500568825569992, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.6500568825569992\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4500\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.251601414088265, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.251601414088265\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1400\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=3.1257611882956606, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.1257611882956606\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2500\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.030627361449417, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.030627361449417\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7400\n",
      "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.130039755434627, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.130039755434627\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4400\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.1315660006026702, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.1315660006026702\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9100\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.140262345543245, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.140262345543245\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5700\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=2.519424121252995, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.519424121252995\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2800\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.523362177509995, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.523362177509995\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5600\n",
      "[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.519601277844671, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.519601277844671\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.435551667038133, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.435551667038133\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9800\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.555691659648055, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.555691659648055\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.10679887947279, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.10679887947279\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3600\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.0959875833786965, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.0959875833786965\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2100\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.921113447728718, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.921113447728718\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-10 10:08:09,976]\u001b[0m Trial 47 finished with value: 0.0 and parameters: {'n_estimators': 1364, 'learning_rate': 0.02620231582813567, 'num_leaves': 2140, 'max_depth': 8, 'min_data_in_leaf': 3900, 'max_bin': 234, 'lambda_l1': 95, 'lambda_l2': 65, 'min_gain_to_split': 8.266198692510097, 'bagging_fraction': 0.2, 'bagging_freq': 1, 'feature_fraction': 0.6000000000000001}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:08:22,908]\u001b[0m Trial 48 finished with value: 0.460839699329396 and parameters: {'n_estimators': 432, 'learning_rate': 0.023143105262958357, 'num_leaves': 1680, 'max_depth': 9, 'min_data_in_leaf': 7900, 'max_bin': 271, 'lambda_l1': 80, 'lambda_l2': 45, 'min_gain_to_split': 10.793089987573836, 'bagging_fraction': 0.5, 'bagging_freq': 1, 'feature_fraction': 0.7}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:08:39,322]\u001b[0m Trial 49 finished with value: 0.42363403366204616 and parameters: {'n_estimators': 1174, 'learning_rate': 0.053897278960025205, 'num_leaves': 1400, 'max_depth': 5, 'min_data_in_leaf': 1800, 'max_bin': 244, 'lambda_l1': 85, 'lambda_l2': 0, 'min_gain_to_split': 9.669932744512415, 'bagging_fraction': 0.2, 'bagging_freq': 1, 'feature_fraction': 0.8}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:08:55,565]\u001b[0m Trial 50 finished with value: 0.43765083127778037 and parameters: {'n_estimators': 712, 'learning_rate': 0.12482223653234134, 'num_leaves': 2020, 'max_depth': 8, 'min_data_in_leaf': 4800, 'max_bin': 203, 'lambda_l1': 95, 'lambda_l2': 75, 'min_gain_to_split': 10.105879457451168, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.9}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.480398448018658, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.480398448018658\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l1 is set=50, reg_alpha=0.0 will be ignored. Current value: lambda_l1=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.714406546622209, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.714406546622209\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4500\n",
      "[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.3775217283797039, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.3775217283797039\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.251601414088265, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.251601414088265\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1400\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.130039755434627, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.130039755434627\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4400\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=3.0860040088262277, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.0860040088262277\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3500\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.140262345543245, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.140262345543245\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5700\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=2.519424121252995, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.519424121252995\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2800\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.523362177509995, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.523362177509995\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5600\n",
      "[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.31982759083144, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.31982759083144\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=600\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.249040317824887, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.249040317824887\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.004440933131735, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.004440933131735\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2600\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.39207509534875, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.39207509534875\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.0959875833786965, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.0959875833786965\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2100\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.921113447728718, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.921113447728718\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=13.124149292158403, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.124149292158403\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.177447476422731, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.177447476422731\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n",
      "[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.372157091577716, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.372157091577716\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1100\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.57573061634618, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.57573061634618\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1000\n",
      "[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-10 10:09:15,450]\u001b[0m Trial 51 finished with value: 0.5187721869075177 and parameters: {'n_estimators': 922, 'learning_rate': 0.04369197284387442, 'num_leaves': 1900, 'max_depth': 9, 'min_data_in_leaf': 600, 'max_bin': 225, 'lambda_l1': 85, 'lambda_l2': 95, 'min_gain_to_split': 9.163659499009299, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.7}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.354187021237242, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.354187021237242\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2000\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=3.1257611882956606, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.1257611882956606\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2500\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.030627361449417, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.030627361449417\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7400\n",
      "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.1315660006026702, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.1315660006026702\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9100\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.140262345543245, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.140262345543245\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5700\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.523362177509995, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.523362177509995\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5600\n",
      "[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.519601277844671, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.519601277844671\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.89401805518984, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.89401805518984\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.31982759083144, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.31982759083144\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=600\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.574101161043638, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.574101161043638\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.249040317824887, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.249040317824887\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.10679887947279, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.10679887947279\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3600\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.39207509534875, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.39207509534875\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.921113447728718, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.921113447728718\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=13.124149292158403, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.124149292158403\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.160904726733504, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.160904726733504\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1000\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.57573061634618, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.57573061634618\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1000\n",
      "[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.775260188999882, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.775260188999882\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.956003801619053, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.956003801619053\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2000\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-10 10:09:52,498]\u001b[0m Trial 52 finished with value: 0.5165636332633374 and parameters: {'n_estimators': 1068, 'learning_rate': 0.04252122111641898, 'num_leaves': 1920, 'max_depth': 9, 'min_data_in_leaf': 1300, 'max_bin': 227, 'lambda_l1': 80, 'lambda_l2': 90, 'min_gain_to_split': 8.81851972700013, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.6000000000000001}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:10:35,559]\u001b[0m Trial 53 finished with value: 0.47669239044878875 and parameters: {'n_estimators': 1072, 'learning_rate': 0.04171057564709913, 'num_leaves': 1580, 'max_depth': 9, 'min_data_in_leaf': 500, 'max_bin': 285, 'lambda_l1': 65, 'lambda_l2': 100, 'min_gain_to_split': 9.661731587227322, 'bagging_fraction': 0.4, 'bagging_freq': 1, 'feature_fraction': 0.6000000000000001}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:11:46,529]\u001b[0m Trial 54 finished with value: 0.521235809705676 and parameters: {'n_estimators': 1225, 'learning_rate': 0.04220791589866031, 'num_leaves': 1860, 'max_depth': 9, 'min_data_in_leaf': 1300, 'max_bin': 226, 'lambda_l1': 90, 'lambda_l2': 90, 'min_gain_to_split': 8.098839122229055, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.5}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:12:39,844]\u001b[0m Trial 55 finished with value: 0.46358314456266314 and parameters: {'n_estimators': 1024, 'learning_rate': 0.019151433889944305, 'num_leaves': 1300, 'max_depth': 10, 'min_data_in_leaf': 2400, 'max_bin': 214, 'lambda_l1': 90, 'lambda_l2': 90, 'min_gain_to_split': 8.330810815889112, 'bagging_fraction': 0.2, 'bagging_freq': 1, 'feature_fraction': 0.5}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:13:41,310]\u001b[0m Trial 56 finished with value: 0.5232447153276216 and parameters: {'n_estimators': 1256, 'learning_rate': 0.012521250456532611, 'num_leaves': 1740, 'max_depth': 11, 'min_data_in_leaf': 1200, 'max_bin': 221, 'lambda_l1': 100, 'lambda_l2': 80, 'min_gain_to_split': 6.551981422498399, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.4}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:14:59,516]\u001b[0m Trial 57 finished with value: 0.5182995179278345 and parameters: {'n_estimators': 1343, 'learning_rate': 0.010581950912708707, 'num_leaves': 1740, 'max_depth': 11, 'min_data_in_leaf': 500, 'max_bin': 218, 'lambda_l1': 100, 'lambda_l2': 80, 'min_gain_to_split': 6.637692531668317, 'bagging_fraction': 0.4, 'bagging_freq': 1, 'feature_fraction': 0.4}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:15:43,318]\u001b[0m Trial 58 finished with value: 0.0 and parameters: {'n_estimators': 1471, 'learning_rate': 0.024351293176992337, 'num_leaves': 1520, 'max_depth': 12, 'min_data_in_leaf': 5900, 'max_bin': 220, 'lambda_l1': 20, 'lambda_l2': 65, 'min_gain_to_split': 7.727578365007922, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.4}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:16:47,917]\u001b[0m Trial 59 finished with value: 0.5019190203628919 and parameters: {'n_estimators': 1226, 'learning_rate': 0.03355594484865481, 'num_leaves': 340, 'max_depth': 11, 'min_data_in_leaf': 1200, 'max_bin': 206, 'lambda_l1': 100, 'lambda_l2': 80, 'min_gain_to_split': 6.348969891702792, 'bagging_fraction': 0.4, 'bagging_freq': 1, 'feature_fraction': 0.5}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:18:04,431]\u001b[0m Trial 60 finished with value: 0.4144943027011959 and parameters: {'n_estimators': 1480, 'learning_rate': 0.017610959100011758, 'num_leaves': 1800, 'max_depth': 10, 'min_data_in_leaf': 200, 'max_bin': 263, 'lambda_l1': 95, 'lambda_l2': 75, 'min_gain_to_split': 5.288286603429221, 'bagging_fraction': 0.2, 'bagging_freq': 1, 'feature_fraction': 0.4}. Best is trial 16 with value: 0.532015131356277.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:19:12,864]\u001b[0m Trial 61 finished with value: 0.5321268955655543 and parameters: {'n_estimators': 1327, 'learning_rate': 0.010754152104918344, 'num_leaves': 1660, 'max_depth': 11, 'min_data_in_leaf': 400, 'max_bin': 300, 'lambda_l1': 100, 'lambda_l2': 85, 'min_gain_to_split': 6.234667778269985, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.30000000000000004}. Best is trial 61 with value: 0.5321268955655543.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:20:31,916]\u001b[0m Trial 62 finished with value: 0.5309466388489822 and parameters: {'n_estimators': 1273, 'learning_rate': 0.010113934027878352, 'num_leaves': 2100, 'max_depth': 11, 'min_data_in_leaf': 700, 'max_bin': 297, 'lambda_l1': 100, 'lambda_l2': 85, 'min_gain_to_split': 5.957338925504859, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.30000000000000004}. Best is trial 61 with value: 0.5321268955655543.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:21:33,955]\u001b[0m Trial 63 finished with value: 0.4072530564555127 and parameters: {'n_estimators': 1248, 'learning_rate': 0.013900182216291076, 'num_leaves': 800, 'max_depth': 12, 'min_data_in_leaf': 1800, 'max_bin': 298, 'lambda_l1': 100, 'lambda_l2': 85, 'min_gain_to_split': 5.902837147857241, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.30000000000000004}. Best is trial 61 with value: 0.5321268955655543.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:22:49,637]\u001b[0m Trial 64 finished with value: 0.5210977086003845 and parameters: {'n_estimators': 1436, 'learning_rate': 0.01015065682625807, 'num_leaves': 1680, 'max_depth': 11, 'min_data_in_leaf': 1200, 'max_bin': 292, 'lambda_l1': 90, 'lambda_l2': 70, 'min_gain_to_split': 4.451474694549608, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.30000000000000004}. Best is trial 61 with value: 0.5321268955655543.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:23:54,962]\u001b[0m Trial 65 finished with value: 0.5087989629108384 and parameters: {'n_estimators': 1331, 'learning_rate': 0.026344770561276258, 'num_leaves': 2220, 'max_depth': 11, 'min_data_in_leaf': 600, 'max_bin': 277, 'lambda_l1': 95, 'lambda_l2': 80, 'min_gain_to_split': 6.298370467092901, 'bagging_fraction': 0.4, 'bagging_freq': 1, 'feature_fraction': 0.30000000000000004}. Best is trial 61 with value: 0.5321268955655543.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:24:52,175]\u001b[0m Trial 66 finished with value: 0.4648043130969297 and parameters: {'n_estimators': 1128, 'learning_rate': 0.03337743809219379, 'num_leaves': 2080, 'max_depth': 12, 'min_data_in_leaf': 2200, 'max_bin': 300, 'lambda_l1': 100, 'lambda_l2': 90, 'min_gain_to_split': 6.908855597102384, 'bagging_fraction': 0.2, 'bagging_freq': 1, 'feature_fraction': 0.4}. Best is trial 61 with value: 0.5321268955655543.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:25:51,233]\u001b[0m Trial 67 finished with value: 0.4379738037333524 and parameters: {'n_estimators': 1539, 'learning_rate': 0.020502872684739295, 'num_leaves': 1400, 'max_depth': 11, 'min_data_in_leaf': 2700, 'max_bin': 286, 'lambda_l1': 90, 'lambda_l2': 55, 'min_gain_to_split': 5.346955204031535, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.2}. Best is trial 61 with value: 0.5321268955655543.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:26:57,848]\u001b[0m Trial 68 finished with value: 0.4545821579107838 and parameters: {'n_estimators': 1289, 'learning_rate': 0.05397981112730967, 'num_leaves': 1200, 'max_depth': 10, 'min_data_in_leaf': 1000, 'max_bin': 294, 'lambda_l1': 100, 'lambda_l2': 75, 'min_gain_to_split': 7.340711260613811, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'feature_fraction': 0.30000000000000004}. Best is trial 61 with value: 0.5321268955655543.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:28:17,920]\u001b[0m Trial 69 finished with value: 0.4192482729122724 and parameters: {'n_estimators': 1408, 'learning_rate': 0.038876437954192385, 'num_leaves': 2380, 'max_depth': 11, 'min_data_in_leaf': 200, 'max_bin': 287, 'lambda_l1': 95, 'lambda_l2': 85, 'min_gain_to_split': 5.872096772917196, 'bagging_fraction': 0.2, 'bagging_freq': 1, 'feature_fraction': 0.4}. Best is trial 61 with value: 0.5321268955655543.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:29:11,176]\u001b[0m Trial 70 finished with value: 0.5059506645389525 and parameters: {'n_estimators': 1104, 'learning_rate': 0.028444272448899976, 'num_leaves': 1600, 'max_depth': 12, 'min_data_in_leaf': 1700, 'max_bin': 282, 'lambda_l1': 90, 'lambda_l2': 85, 'min_gain_to_split': 7.885473421572215, 'bagging_fraction': 0.4, 'bagging_freq': 1, 'feature_fraction': 0.30000000000000004}. Best is trial 61 with value: 0.5321268955655543.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n",
      "[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.160904726733504, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.160904726733504\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1000\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.57573061634618, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.57573061634618\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1000\n",
      "[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.775260188999882, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.775260188999882\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.956003801619053, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.956003801619053\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2000\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.641140702742213, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.641140702742213\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7100\n",
      "[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.366316484154778, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.366316484154778\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2300\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.901017463427527, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.901017463427527\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3300\n",
      "[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.806760018674924, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.806760018674924\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.00593329832756, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.00593329832756\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.045969480496892, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.045969480496892\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.234890700581659, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.234890700581659\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.218159220934682, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.218159220934682\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.266198692510097, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.266198692510097\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3900\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.793089987573836, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.793089987573836\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7900\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.163659499009299, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.163659499009299\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=600\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.661731587227322, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.661731587227322\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=500\n",
      "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.330810815889112, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.330810815889112\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2400\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.348969891702792, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.348969891702792\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.288286603429221, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.288286603429221\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1000\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.57573061634618, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.57573061634618\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1000\n",
      "[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.841125421099212, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.841125421099212\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3500\n",
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.956003801619053, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.956003801619053\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2000\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.641140702742213, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.641140702742213\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7100\n",
      "[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.709304447477036, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.709304447477036\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1500\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.901017463427527, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.901017463427527\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3300\n",
      "[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.00593329832756, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.00593329832756\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.234890700581659, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.234890700581659\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.6486501190342, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.6486501190342\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3000\n",
      "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.266198692510097, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.266198692510097\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3900\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.793089987573836, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.793089987573836\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7900\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.669932744512415, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.669932744512415\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1800\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.105879457451168, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.105879457451168\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4800\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.163659499009299, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.163659499009299\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=600\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.81851972700013, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.81851972700013\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.661731587227322, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.661731587227322\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=500\n",
      "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.098839122229055, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.098839122229055\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.330810815889112, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.330810815889112\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2400\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.637692531668317, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.637692531668317\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-10 10:30:24,229]\u001b[0m Trial 71 finished with value: 0.5207704021864202 and parameters: {'n_estimators': 1407, 'learning_rate': 0.01094997462433497, 'num_leaves': 1680, 'max_depth': 11, 'min_data_in_leaf': 1200, 'max_bin': 295, 'lambda_l1': 90, 'lambda_l2': 80, 'min_gain_to_split': 4.295837456332624, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.30000000000000004}. Best is trial 61 with value: 0.5321268955655543.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_gain_to_split is set=10.408877168713527, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.408877168713527\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1500\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=13.124149292158403, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.124149292158403\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.160904726733504, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.160904726733504\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1000\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.372157091577716, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.372157091577716\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1100\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.775260188999882, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.775260188999882\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.841125421099212, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.841125421099212\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3500\n",
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.641140702742213, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.641140702742213\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7100\n",
      "[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.709304447477036, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.709304447477036\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1500\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.366316484154778, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.366316484154778\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2300\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.901017463427527, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.901017463427527\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3300\n",
      "[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.806760018674924, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.806760018674924\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.00593329832756, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.00593329832756\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.045969480496892, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.045969480496892\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.234890700581659, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.234890700581659\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.6486501190342, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.6486501190342\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3000\n",
      "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.266198692510097, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.266198692510097\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3900\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.105879457451168, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.105879457451168\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4800\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.163659499009299, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.163659499009299\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=600\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.661731587227322, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.661731587227322\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=500\n",
      "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-10 10:31:39,268]\u001b[0m Trial 72 finished with value: 0.4646447218844222 and parameters: {'n_estimators': 1643, 'learning_rate': 0.011644473381617577, 'num_leaves': 1740, 'max_depth': 11, 'min_data_in_leaf': 1300, 'max_bin': 292, 'lambda_l1': 100, 'lambda_l2': 70, 'min_gain_to_split': 4.721832441671047, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.2}. Best is trial 61 with value: 0.5321268955655543.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:32:51,805]\u001b[0m Trial 73 finished with value: 0.5277899338777665 and parameters: {'n_estimators': 1221, 'learning_rate': 0.018136351280355803, 'num_leaves': 1480, 'max_depth': 12, 'min_data_in_leaf': 800, 'max_bin': 289, 'lambda_l1': 95, 'lambda_l2': 75, 'min_gain_to_split': 6.560367156525831, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.30000000000000004}. Best is trial 61 with value: 0.5321268955655543.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:33:59,276]\u001b[0m Trial 74 finished with value: 0.5241056326888902 and parameters: {'n_estimators': 1221, 'learning_rate': 0.035919173034303475, 'num_leaves': 1480, 'max_depth': 12, 'min_data_in_leaf': 800, 'max_bin': 299, 'lambda_l1': 95, 'lambda_l2': 90, 'min_gain_to_split': 6.806841060106483, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.4}. Best is trial 61 with value: 0.5321268955655543.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_gain_to_split is set=10.408877168713527, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.408877168713527\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1500\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=13.124149292158403, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.124149292158403\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.177447476422731, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.177447476422731\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n",
      "[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.372157091577716, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.372157091577716\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1100\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.57573061634618, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.57573061634618\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1000\n",
      "[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.775260188999882, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.775260188999882\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.841125421099212, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.841125421099212\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3500\n",
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.956003801619053, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.956003801619053\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2000\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.641140702742213, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.641140702742213\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7100\n",
      "[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.366316484154778, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.366316484154778\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2300\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.045969480496892, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.045969480496892\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.234890700581659, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.234890700581659\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.218159220934682, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.218159220934682\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.669932744512415, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.669932744512415\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1800\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.105879457451168, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.105879457451168\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4800\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.81851972700013, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.81851972700013\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.330810815889112, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.330810815889112\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2400\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.551981422498399, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.551981422498399\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.727578365007922, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.727578365007922\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5900\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-10 10:35:03,890]\u001b[0m Trial 75 finished with value: 0.5249260989595693 and parameters: {'n_estimators': 1198, 'learning_rate': 0.022853881269465293, 'num_leaves': 1000, 'max_depth': 12, 'min_data_in_leaf': 700, 'max_bin': 297, 'lambda_l1': 95, 'lambda_l2': 75, 'min_gain_to_split': 7.311783634613598, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.4}. Best is trial 61 with value: 0.5321268955655543.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=13.124149292158403, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.124149292158403\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.177447476422731, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.177447476422731\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n",
      "[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.372157091577716, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.372157091577716\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1100\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.775260188999882, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.775260188999882\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.956003801619053, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.956003801619053\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2000\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.709304447477036, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.709304447477036\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1500\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.366316484154778, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.366316484154778\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2300\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.901017463427527, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.901017463427527\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3300\n",
      "[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.806760018674924, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.806760018674924\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.6486501190342, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.6486501190342\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3000\n",
      "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.266198692510097, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.266198692510097\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3900\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.669932744512415, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.669932744512415\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1800\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.105879457451168, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.105879457451168\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4800\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.163659499009299, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.163659499009299\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=600\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.81851972700013, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.81851972700013\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.551981422498399, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.551981422498399\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.637692531668317, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.637692531668317\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=500\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.727578365007922, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.727578365007922\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5900\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.288286603429221, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.288286603429221\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-10 10:36:26,728]\u001b[0m Trial 76 finished with value: 0.5099860387550963 and parameters: {'n_estimators': 1310, 'learning_rate': 0.020030773670411374, 'num_leaves': 980, 'max_depth': 12, 'min_data_in_leaf': 500, 'max_bin': 299, 'lambda_l1': 100, 'lambda_l2': 75, 'min_gain_to_split': 6.660797217998123, 'bagging_fraction': 0.4, 'bagging_freq': 1, 'feature_fraction': 0.4}. Best is trial 61 with value: 0.5321268955655543.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:37:31,978]\u001b[0m Trial 77 finished with value: 0.3838953421582518 and parameters: {'n_estimators': 1176, 'learning_rate': 0.031950162631667944, 'num_leaves': 820, 'max_depth': 12, 'min_data_in_leaf': 400, 'max_bin': 296, 'lambda_l1': 0, 'lambda_l2': 60, 'min_gain_to_split': 7.275152644360245, 'bagging_fraction': 0.2, 'bagging_freq': 1, 'feature_fraction': 0.4}. Best is trial 61 with value: 0.5321268955655543.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_gain_to_split is set=14.177447476422731, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.177447476422731\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n",
      "[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.160904726733504, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.160904726733504\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1000\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.372157091577716, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.372157091577716\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1100\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.841125421099212, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.841125421099212\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3500\n",
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.641140702742213, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.641140702742213\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7100\n",
      "[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.709304447477036, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.709304447477036\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1500\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.901017463427527, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.901017463427527\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3300\n",
      "[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.00593329832756, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.00593329832756\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.218159220934682, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.218159220934682\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.266198692510097, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.266198692510097\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3900\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.793089987573836, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.793089987573836\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7900\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.81851972700013, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.81851972700013\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.661731587227322, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.661731587227322\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=500\n",
      "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.098839122229055, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.098839122229055\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.330810815889112, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.330810815889112\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2400\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.551981422498399, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.551981422498399\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.348969891702792, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.348969891702792\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.288286603429221, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.288286603429221\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.957338925504859, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.957338925504859\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-10 10:38:36,296]\u001b[0m Trial 78 finished with value: 0.5273827972779422 and parameters: {'n_estimators': 1249, 'learning_rate': 0.020727980940503363, 'num_leaves': 1160, 'max_depth': 12, 'min_data_in_leaf': 900, 'max_bin': 290, 'lambda_l1': 95, 'lambda_l2': 75, 'min_gain_to_split': 6.7417858711701815, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.30000000000000004}. Best is trial 61 with value: 0.5321268955655543.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:39:40,688]\u001b[0m Trial 79 finished with value: 0.5269508344877444 and parameters: {'n_estimators': 1124, 'learning_rate': 0.03664723675716608, 'num_leaves': 1060, 'max_depth': 12, 'min_data_in_leaf': 800, 'max_bin': 291, 'lambda_l1': 95, 'lambda_l2': 65, 'min_gain_to_split': 7.338476327744897, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.30000000000000004}. Best is trial 61 with value: 0.5321268955655543.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.366316484154778, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.366316484154778\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2300\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.806760018674924, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.806760018674924\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.00593329832756, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.00593329832756\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.045969480496892, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.045969480496892\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.218159220934682, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.218159220934682\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.6486501190342, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.6486501190342\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3000\n",
      "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.793089987573836, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.793089987573836\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7900\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.669932744512415, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.669932744512415\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1800\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.105879457451168, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.105879457451168\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4800\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.81851972700013, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.81851972700013\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.661731587227322, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.661731587227322\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=500\n",
      "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.098839122229055, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.098839122229055\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.551981422498399, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.551981422498399\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.637692531668317, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.637692531668317\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=500\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.727578365007922, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.727578365007922\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5900\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.348969891702792, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.348969891702792\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.288286603429221, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.288286603429221\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.234667778269985, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.234667778269985\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.957338925504859, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.957338925504859\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-10 10:40:36,787]\u001b[0m Trial 80 finished with value: 0.4428115062713392 and parameters: {'n_estimators': 1139, 'learning_rate': 0.035977222166728995, 'num_leaves': 1060, 'max_depth': 12, 'min_data_in_leaf': 2000, 'max_bin': 289, 'lambda_l1': 95, 'lambda_l2': 65, 'min_gain_to_split': 6.105502567908601, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.30000000000000004}. Best is trial 61 with value: 0.5321268955655543.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:41:32,986]\u001b[0m Trial 81 finished with value: 0.5265807335957475 and parameters: {'n_estimators': 1206, 'learning_rate': 0.024098816701524205, 'num_leaves': 1140, 'max_depth': 12, 'min_data_in_leaf': 900, 'max_bin': 297, 'lambda_l1': 95, 'lambda_l2': 70, 'min_gain_to_split': 6.960297161379451, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.2}. Best is trial 61 with value: 0.5321268955655543.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:42:35,747]\u001b[0m Trial 82 finished with value: 0.5295272084153119 and parameters: {'n_estimators': 1214, 'learning_rate': 0.021162045829138037, 'num_leaves': 1140, 'max_depth': 12, 'min_data_in_leaf': 900, 'max_bin': 297, 'lambda_l1': 95, 'lambda_l2': 70, 'min_gain_to_split': 7.052608592508279, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.2}. Best is trial 61 with value: 0.5321268955655543.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:43:34,324]\u001b[0m Trial 83 finished with value: 0.4444892659685726 and parameters: {'n_estimators': 1367, 'learning_rate': 0.01934469274973294, 'num_leaves': 1180, 'max_depth': 12, 'min_data_in_leaf': 1500, 'max_bin': 290, 'lambda_l1': 95, 'lambda_l2': 70, 'min_gain_to_split': 7.321428537692736, 'bagging_fraction': 0.2, 'bagging_freq': 1, 'feature_fraction': 0.2}. Best is trial 61 with value: 0.5321268955655543.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_gain_to_split is set=9.841125421099212, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.841125421099212\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3500\n",
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.709304447477036, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.709304447477036\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1500\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.806760018674924, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.806760018674924\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.045969480496892, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.045969480496892\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.234890700581659, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.234890700581659\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.218159220934682, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.218159220934682\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.6486501190342, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.6486501190342\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3000\n",
      "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.793089987573836, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.793089987573836\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7900\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.669932744512415, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.669932744512415\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1800\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.163659499009299, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.163659499009299\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=600\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.098839122229055, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.098839122229055\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.330810815889112, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.330810815889112\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2400\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.551981422498399, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.551981422498399\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.637692531668317, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.637692531668317\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=500\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.727578365007922, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.727578365007922\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5900\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.348969891702792, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.348969891702792\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.234667778269985, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.234667778269985\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.298370467092901, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.298370467092901\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=600\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.908855597102384, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.908855597102384\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.346955204031535, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.346955204031535\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-10 10:44:31,619]\u001b[0m Trial 84 finished with value: 0.5027320884329293 and parameters: {'n_estimators': 1201, 'learning_rate': 0.025244791469534407, 'num_leaves': 920, 'max_depth': 12, 'min_data_in_leaf': 800, 'max_bin': 296, 'lambda_l1': 90, 'lambda_l2': 60, 'min_gain_to_split': 6.992143785271957, 'bagging_fraction': 0.4, 'bagging_freq': 1, 'feature_fraction': 0.2}. Best is trial 61 with value: 0.5321268955655543.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:45:44,216]\u001b[0m Trial 85 finished with value: 0.38149433645345815 and parameters: {'n_estimators': 1282, 'learning_rate': 0.017740753529492066, 'num_leaves': 700, 'max_depth': 12, 'min_data_in_leaf': 300, 'max_bin': 280, 'lambda_l1': 5, 'lambda_l2': 55, 'min_gain_to_split': 5.738701025247641, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.2}. Best is trial 61 with value: 0.5321268955655543.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:45:59,655]\u001b[0m Trial 86 finished with value: 0.0 and parameters: {'n_estimators': 1156, 'learning_rate': 0.049731924453414685, 'num_leaves': 1060, 'max_depth': 12, 'min_data_in_leaf': 8400, 'max_bin': 292, 'lambda_l1': 45, 'lambda_l2': 65, 'min_gain_to_split': 7.615897172082374, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.30000000000000004}. Best is trial 61 with value: 0.5321268955655543.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:46:56,839]\u001b[0m Trial 87 finished with value: 0.49432147397124726 and parameters: {'n_estimators': 1094, 'learning_rate': 0.06218811796682916, 'num_leaves': 1320, 'max_depth': 12, 'min_data_in_leaf': 900, 'max_bin': 284, 'lambda_l1': 85, 'lambda_l2': 70, 'min_gain_to_split': 7.081595487330265, 'bagging_fraction': 0.4, 'bagging_freq': 1, 'feature_fraction': 0.2}. Best is trial 61 with value: 0.5321268955655543.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:48:09,094]\u001b[0m Trial 88 finished with value: 0.5290541618860302 and parameters: {'n_estimators': 1267, 'learning_rate': 0.028872522530990458, 'num_leaves': 1120, 'max_depth': 11, 'min_data_in_leaf': 400, 'max_bin': 297, 'lambda_l1': 100, 'lambda_l2': 75, 'min_gain_to_split': 6.127189684972572, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.30000000000000004}. Best is trial 61 with value: 0.5321268955655543.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:49:15,389]\u001b[0m Trial 89 finished with value: 0.5307122726537734 and parameters: {'n_estimators': 1320, 'learning_rate': 0.031319978088500705, 'num_leaves': 1240, 'max_depth': 11, 'min_data_in_leaf': 400, 'max_bin': 288, 'lambda_l1': 100, 'lambda_l2': 65, 'min_gain_to_split': 6.477231751622182, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.30000000000000004}. Best is trial 61 with value: 0.5321268955655543.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:50:18,527]\u001b[0m Trial 90 finished with value: 0.3757743145406541 and parameters: {'n_estimators': 1331, 'learning_rate': 0.057540710540028614, 'num_leaves': 1220, 'max_depth': 11, 'min_data_in_leaf': 400, 'max_bin': 276, 'lambda_l1': 100, 'lambda_l2': 65, 'min_gain_to_split': 6.249472743664129, 'bagging_fraction': 0.2, 'bagging_freq': 1, 'feature_fraction': 0.30000000000000004}. Best is trial 61 with value: 0.5321268955655543.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:51:27,396]\u001b[0m Trial 91 finished with value: 0.5315681361893289 and parameters: {'n_estimators': 1293, 'learning_rate': 0.028810040078651893, 'num_leaves': 1140, 'max_depth': 11, 'min_data_in_leaf': 200, 'max_bin': 290, 'lambda_l1': 100, 'lambda_l2': 70, 'min_gain_to_split': 6.745495001097481, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.30000000000000004}. Best is trial 61 with value: 0.5321268955655543.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:52:37,694]\u001b[0m Trial 92 finished with value: 0.5302940289732749 and parameters: {'n_estimators': 1293, 'learning_rate': 0.03208286751309312, 'num_leaves': 1260, 'max_depth': 11, 'min_data_in_leaf': 200, 'max_bin': 289, 'lambda_l1': 100, 'lambda_l2': 75, 'min_gain_to_split': 6.379080395682327, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.30000000000000004}. Best is trial 61 with value: 0.5321268955655543.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:53:39,761]\u001b[0m Trial 93 finished with value: 0.5300321390077295 and parameters: {'n_estimators': 1274, 'learning_rate': 0.030143279434433665, 'num_leaves': 1320, 'max_depth': 11, 'min_data_in_leaf': 300, 'max_bin': 287, 'lambda_l1': 100, 'lambda_l2': 75, 'min_gain_to_split': 5.534321803709195, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.30000000000000004}. Best is trial 61 with value: 0.5321268955655543.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:54:52,407]\u001b[0m Trial 94 finished with value: 0.5326298400437173 and parameters: {'n_estimators': 1379, 'learning_rate': 0.0305180705872894, 'num_leaves': 1340, 'max_depth': 11, 'min_data_in_leaf': 200, 'max_bin': 274, 'lambda_l1': 100, 'lambda_l2': 80, 'min_gain_to_split': 5.6169036486489725, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.30000000000000004}. Best is trial 94 with value: 0.5326298400437173.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:56:02,048]\u001b[0m Trial 95 finished with value: 0.5026701742532289 and parameters: {'n_estimators': 1449, 'learning_rate': 0.04946900078143942, 'num_leaves': 1300, 'max_depth': 10, 'min_data_in_leaf': 200, 'max_bin': 294, 'lambda_l1': 100, 'lambda_l2': 70, 'min_gain_to_split': 5.611717749888534, 'bagging_fraction': 0.4, 'bagging_freq': 1, 'feature_fraction': 0.30000000000000004}. Best is trial 94 with value: 0.5326298400437173.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:57:15,413]\u001b[0m Trial 96 finished with value: 0.5256770503489779 and parameters: {'n_estimators': 1546, 'learning_rate': 0.030403828615009128, 'num_leaves': 1360, 'max_depth': 11, 'min_data_in_leaf': 400, 'max_bin': 274, 'lambda_l1': 100, 'lambda_l2': 80, 'min_gain_to_split': 5.039137235947756, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.30000000000000004}. Best is trial 94 with value: 0.5326298400437173.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 10:58:27,138]\u001b[0m Trial 97 finished with value: 0.38823009470676906 and parameters: {'n_estimators': 1377, 'learning_rate': 0.041590337610998555, 'num_leaves': 1240, 'max_depth': 10, 'min_data_in_leaf': 200, 'max_bin': 282, 'lambda_l1': 100, 'lambda_l2': 80, 'min_gain_to_split': 5.8790139718153425, 'bagging_fraction': 0.2, 'bagging_freq': 1, 'feature_fraction': 0.30000000000000004}. Best is trial 94 with value: 0.5326298400437173.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=500\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.727578365007922, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.727578365007922\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5900\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.234667778269985, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.234667778269985\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.957338925504859, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.957338925504859\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.451474694549608, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.451474694549608\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.298370467092901, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.298370467092901\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=600\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.908855597102384, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.908855597102384\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.340711260613811, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.340711260613811\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1000\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.885473421572215, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.885473421572215\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1700\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.295837456332624, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.295837456332624\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.721832441671047, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.721832441671047\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.560367156525831, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.560367156525831\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.660797217998123, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.660797217998123\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=500\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.275152644360245, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.275152644360245\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.7417858711701815, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.7417858711701815\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.338476327744897, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.338476327744897\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.105502567908601, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.105502567908601\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2000\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.960297161379451, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.960297161379451\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.052608592508279, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.052608592508279\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-10 10:59:44,096]\u001b[0m Trial 98 finished with value: 0.4553710088759867 and parameters: {'n_estimators': 1520, 'learning_rate': 0.048820302033762836, 'num_leaves': 880, 'max_depth': 11, 'min_data_in_leaf': 500, 'max_bin': 288, 'lambda_l1': 100, 'lambda_l2': 60, 'min_gain_to_split': 5.482264770351104, 'bagging_fraction': 0.6000000000000001, 'bagging_freq': 1, 'feature_fraction': 0.2}. Best is trial 94 with value: 0.5326298400437173.\u001b[0m\n",
      "\u001b[32m[I 2023-03-10 11:00:45,072]\u001b[0m Trial 99 finished with value: 0.5265335468582938 and parameters: {'n_estimators': 1305, 'learning_rate': 0.03042597557604193, 'num_leaves': 1100, 'max_depth': 11, 'min_data_in_leaf': 600, 'max_bin': 293, 'lambda_l1': 100, 'lambda_l2': 75, 'min_gain_to_split': 6.278510578880634, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.30000000000000004}. Best is trial 94 with value: 0.5326298400437173.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.5326298400437173\n",
      "\n",
      "Optimized parameters: {'n_estimators': 1379, 'learning_rate': 0.0305180705872894, 'num_leaves': 1340, 'max_depth': 11, 'min_data_in_leaf': 200, 'max_bin': 274, 'lambda_l1': 100, 'lambda_l2': 80, 'min_gain_to_split': 5.6169036486489725, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.30000000000000004}\n",
      "\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.234667778269985, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.234667778269985\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.957338925504859, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.957338925504859\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.451474694549608, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.451474694549608\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.346955204031535, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.346955204031535\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2700\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.340711260613811, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.340711260613811\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1000\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.295837456332624, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.295837456332624\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.721832441671047, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.721832441671047\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.560367156525831, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.560367156525831\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.311783634613598, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.311783634613598\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.660797217998123, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.660797217998123\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=500\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.275152644360245, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.275152644360245\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.960297161379451, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.960297161379451\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.052608592508279, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.052608592508279\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.992143785271957, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.992143785271957\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.738701025247641, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.738701025247641\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.081595487330265, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.081595487330265\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.127189684972572, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.127189684972572\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.477231751622182, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.477231751622182\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.249472743664129, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.249472743664129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.745495001097481, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.745495001097481\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.534321803709195, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.534321803709195\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.039137235947756, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.039137235947756\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_gain_to_split is set=5.288286603429221, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.288286603429221\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.902837147857241, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.902837147857241\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1800\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.451474694549608, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.451474694549608\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.908855597102384, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.908855597102384\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.346955204031535, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.346955204031535\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2700\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.340711260613811, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.340711260613811\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1000\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.872096772917196, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.872096772917196\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.295837456332624, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.295837456332624\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.806841060106483, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.806841060106483\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.311783634613598, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.311783634613598\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.660797217998123, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.660797217998123\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=500\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.7417858711701815, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.7417858711701815\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.338476327744897, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.338476327744897\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.052608592508279, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.052608592508279\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.321428537692736, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.321428537692736\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1500\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.738701025247641, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.738701025247641\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.477231751622182, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.477231751622182\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.249472743664129, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.249472743664129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.379080395682327, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.379080395682327\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.6169036486489725, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.6169036486489725\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.611717749888534, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.611717749888534\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.039137235947756, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.039137235947756\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.8790139718153425, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.8790139718153425\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.482264770351104, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.482264770351104\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=500\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.957338925504859, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.957338925504859\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.902837147857241, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.902837147857241\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1800\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.451474694549608, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.451474694549608\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.298370467092901, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.298370467092901\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=600\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.908855597102384, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.908855597102384\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.346955204031535, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.346955204031535\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2700\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.872096772917196, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.872096772917196\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.885473421572215, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.885473421572215\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1700\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.295837456332624, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.295837456332624\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.721832441671047, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.721832441671047\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.560367156525831, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.560367156525831\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.806841060106483, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.806841060106483\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.311783634613598, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.311783634613598\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.275152644360245, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.275152644360245\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.338476327744897, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.338476327744897\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.105502567908601, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.105502567908601\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2000\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.960297161379451, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.960297161379451\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.738701025247641, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.738701025247641\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.615897172082374, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.615897172082374\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8400\n",
      "[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.081595487330265, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.081595487330265\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.477231751622182, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.477231751622182\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.249472743664129, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.249472743664129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.379080395682327, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.379080395682327\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.6169036486489725, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.6169036486489725\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.611717749888534, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.611717749888534\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.482264770351104, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.482264770351104\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=500\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2700\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.340711260613811, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.340711260613811\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1000\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.885473421572215, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.885473421572215\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1700\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.560367156525831, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.560367156525831\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.311783634613598, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.311783634613598\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.7417858711701815, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.7417858711701815\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.338476327744897, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.338476327744897\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.105502567908601, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.105502567908601\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2000\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.052608592508279, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.052608592508279\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.992143785271957, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.992143785271957\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.738701025247641, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.738701025247641\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.615897172082374, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.615897172082374\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8400\n",
      "[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.127189684972572, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.127189684972572\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.477231751622182, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.477231751622182\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.249472743664129, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.249472743664129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.745495001097481, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.745495001097481\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.379080395682327, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.379080395682327\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.534321803709195, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.534321803709195\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.6169036486489725, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.6169036486489725\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.8790139718153425, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.8790139718153425\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.278510578880634, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.278510578880634\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=600\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_gain_to_split is set=5.902837147857241, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.902837147857241\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1800\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.908855597102384, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.908855597102384\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.872096772917196, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.872096772917196\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.885473421572215, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.885473421572215\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1700\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.295837456332624, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.295837456332624\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.560367156525831, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.560367156525831\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.806841060106483, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.806841060106483\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.660797217998123, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.660797217998123\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=500\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.275152644360245, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.275152644360245\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.7417858711701815, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.7417858711701815\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.338476327744897, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.338476327744897\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.105502567908601, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.105502567908601\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2000\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.321428537692736, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.321428537692736\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1500\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.992143785271957, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.992143785271957\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.615897172082374, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.615897172082374\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8400\n",
      "[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.127189684972572, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.127189684972572\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.379080395682327, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.379080395682327\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.534321803709195, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.534321803709195\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.6169036486489725, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.6169036486489725\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.039137235947756, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.039137235947756\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.8790139718153425, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.8790139718153425\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.482264770351104, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.482264770351104\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=500\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.278510578880634, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.278510578880634\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=600\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.321428537692736, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.321428537692736\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1500\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.992143785271957, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.992143785271957\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.081595487330265, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.081595487330265\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.127189684972572, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.127189684972572\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.249472743664129, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.249472743664129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.745495001097481, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.745495001097481\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.534321803709195, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.534321803709195\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.611717749888534, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.611717749888534\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.039137235947756, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.039137235947756\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.482264770351104, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.482264770351104\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=500\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.278510578880634, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.278510578880634\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=600\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_gain_to_split is set=8.098839122229055, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.098839122229055\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.637692531668317, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.637692531668317\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=500\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.348969891702792, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.348969891702792\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.234667778269985, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.234667778269985\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.902837147857241, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.902837147857241\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1800\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.451474694549608, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.451474694549608\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.298370467092901, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.298370467092901\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=600\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.346955204031535, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.346955204031535\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2700\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.872096772917196, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.872096772917196\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.721832441671047, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.721832441671047\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.806841060106483, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.806841060106483\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.660797217998123, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.660797217998123\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=500\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.7417858711701815, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.7417858711701815\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.960297161379451, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.960297161379451\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.321428537692736, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.321428537692736\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1500\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.992143785271957, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.992143785271957\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.615897172082374, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.615897172082374\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8400\n",
      "[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.081595487330265, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.081595487330265\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.127189684972572, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.127189684972572\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.745495001097481, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.745495001097481\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.379080395682327, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.379080395682327\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.534321803709195, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.534321803709195\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.6169036486489725, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.6169036486489725\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.611717749888534, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.611717749888534\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.8790139718153425, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.8790139718153425\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.482264770351104, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.482264770351104\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=500\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.278510578880634, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.278510578880634\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=600\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_gain_to_split is set=5.902837147857241, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.902837147857241\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1800\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.298370467092901, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.298370467092901\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=600\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.340711260613811, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.340711260613811\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1000\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.872096772917196, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.872096772917196\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.885473421572215, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.885473421572215\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1700\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.721832441671047, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.721832441671047\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.806841060106483, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.806841060106483\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.311783634613598, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.311783634613598\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.275152644360245, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.275152644360245\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.105502567908601, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.105502567908601\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2000\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.960297161379451, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.960297161379451\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.052608592508279, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.052608592508279\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.321428537692736, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.321428537692736\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1500\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.738701025247641, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.738701025247641\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.615897172082374, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.615897172082374\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8400\n",
      "[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.081595487330265, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.081595487330265\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.477231751622182, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.477231751622182\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.745495001097481, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.745495001097481\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.611717749888534, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.611717749888534\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.039137235947756, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.039137235947756\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.8790139718153425, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.8790139718153425\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.278510578880634, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.278510578880634\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=600\n",
      "[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100\n"
     ]
    }
   ],
   "source": [
    "def lgbm_objective(trial):\n",
    "    \n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 300 ,2000),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 3000, step=20),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 200, 10000, step=100),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 200, 300),\n",
    "        \"lambda_l1\": trial.suggest_int(\"lambda_l1\", 0, 100, step=5),\n",
    "        \"lambda_l2\": trial.suggest_int(\"lambda_l2\", 0, 100, step=5),\n",
    "        \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0, 15),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.2, 0.9, step=0.1),\n",
    "        \"bagging_freq\": trial.suggest_categorical(\"bagging_freq\", [1]),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.2, 0.9, step=0.1),\n",
    "    }\n",
    "    \n",
    "    lgbm = LGBMClassifier(**params, random_state=42, n_jobs=-1)\n",
    "    logistic_regression = Pipeline([('smote', smote), ('model', lgbm)])\n",
    "    \n",
    "    scores = cross_val_score(\n",
    "        logistic_regression, X_train, y_train, cv=cv, scoring=custom_score, n_jobs=-1\n",
    "                             \n",
    "    )\n",
    "    \n",
    "    mlflow_hyperparameter_tuning(experiment_id, params, scores)\n",
    "    \n",
    "    return scores.mean()\n",
    "\n",
    "lgbm_params = udf.tune(lgbm_objective, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "523cefb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-12T23:24:56.296627Z",
     "start_time": "2023-03-12T23:24:51.684669Z"
    }
   },
   "outputs": [],
   "source": [
    "lgbm_params = {'n_estimators': 1379,\n",
    " 'learning_rate': 0.0305180705872894,\n",
    " 'num_leaves': 1340,\n",
    " 'max_depth': 11,\n",
    " 'min_data_in_leaf': 200,\n",
    " 'max_bin': 274,\n",
    " 'lambda_l1': 100,\n",
    " 'lambda_l2': 80,\n",
    " 'min_gain_to_split': 5.6169036486489725,\n",
    " 'bagging_fraction': 0.30000000000000004,\n",
    " 'bagging_freq': 1,\n",
    " 'feature_fraction': 0.30000000000000004}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e97d7121",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-12T23:43:28.618698Z",
     "start_time": "2023-03-12T23:25:03.868201Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-34 {color: black;background-color: white;}#sk-container-id-34 pre{padding: 0;}#sk-container-id-34 div.sk-toggleable {background-color: white;}#sk-container-id-34 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-34 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-34 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-34 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-34 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-34 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-34 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-34 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-34 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-34 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-34 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-34 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-34 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-34 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-34 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-34 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-34 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-34 div.sk-item {position: relative;z-index: 1;}#sk-container-id-34 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-34 div.sk-item::before, #sk-container-id-34 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-34 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-34 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-34 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-34 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-34 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-34 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-34 div.sk-label-container {text-align: center;}#sk-container-id-34 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-34 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-34\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;smote&#x27;, SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LGBMClassifier(bagging_fraction=0.30000000000000004,\n",
       "                                bagging_freq=1, boosting_type=&#x27;rf&#x27;,\n",
       "                                feature_fraction=0.30000000000000004,\n",
       "                                lambda_l1=100, lambda_l2=80,\n",
       "                                learning_rate=0.0305180705872894, max_bin=274,\n",
       "                                max_depth=11, min_data_in_leaf=200,\n",
       "                                min_gain_to_split=5.6169036486489725,\n",
       "                                n_estimators=1379, num_leaves=1340,\n",
       "                                random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-133\" type=\"checkbox\" ><label for=\"sk-estimator-id-133\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;smote&#x27;, SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LGBMClassifier(bagging_fraction=0.30000000000000004,\n",
       "                                bagging_freq=1, boosting_type=&#x27;rf&#x27;,\n",
       "                                feature_fraction=0.30000000000000004,\n",
       "                                lambda_l1=100, lambda_l2=80,\n",
       "                                learning_rate=0.0305180705872894, max_bin=274,\n",
       "                                max_depth=11, min_data_in_leaf=200,\n",
       "                                min_gain_to_split=5.6169036486489725,\n",
       "                                n_estimators=1379, num_leaves=1340,\n",
       "                                random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-134\" type=\"checkbox\" ><label for=\"sk-estimator-id-134\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE(k_neighbors=17, random_state=1001)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-135\" type=\"checkbox\" ><label for=\"sk-estimator-id-135\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=0.30000000000000004, bagging_freq=1,\n",
       "               boosting_type=&#x27;rf&#x27;, feature_fraction=0.30000000000000004,\n",
       "               lambda_l1=100, lambda_l2=80, learning_rate=0.0305180705872894,\n",
       "               max_bin=274, max_depth=11, min_data_in_leaf=200,\n",
       "               min_gain_to_split=5.6169036486489725, n_estimators=1379,\n",
       "               num_leaves=1340, random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('smote', SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                ('model',\n",
       "                 LGBMClassifier(bagging_fraction=0.30000000000000004,\n",
       "                                bagging_freq=1, boosting_type='rf',\n",
       "                                feature_fraction=0.30000000000000004,\n",
       "                                lambda_l1=100, lambda_l2=80,\n",
       "                                learning_rate=0.0305180705872894, max_bin=274,\n",
       "                                max_depth=11, min_data_in_leaf=200,\n",
       "                                min_gain_to_split=5.6169036486489725,\n",
       "                                n_estimators=1379, num_leaves=1340,\n",
       "                                random_state=42))])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lgbm_params = {'n_estimators': 976, 'learning_rate': 0.10450965412733053, 'num_leaves': 2060, 'max_depth': 9, 'min_data_in_leaf': 1200, 'max_bin': 226, 'lambda_l1': 95, 'lambda_l2': 70, 'min_gain_to_split': 13.913532191157262, 'bagging_fraction': 0.4, 'bagging_freq': 1, 'feature_fraction': 0.9}\n",
    "lgdm_optimized = construct_model(lgbm, lgbm_params)\n",
    "lgdm_optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "16bb92e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-12T23:43:31.935904Z",
     "start_time": "2023-03-12T23:43:28.635837Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pour le seuil 0.5, le f3_score est : 0.162 et le mean score est : 0.523\n",
      "Accuracy score : 0.884235\n",
      "f3_score : 0.161716 \n",
      "\n",
      "Mean evalation score : 0.522976\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model_evaluation(lgdm_optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a94f97da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T12:34:21.076911Z",
     "start_time": "2023-03-10T12:34:19.955159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pour le seuil 0.2, le f3_score est : 0.511 et le mean score est : 0.582\n",
      "Accuracy score : 0.652706\n",
      "f3_score : 0.511038 \n",
      "\n",
      "Mean evalation score : 0.581872\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model_evaluation(lgdm_optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f563a18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T01:22:41.916026Z",
     "start_time": "2023-03-01T01:22:41.915999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.986 et le mean score est : 0.954\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.977 et le mean score est : 0.926\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.977 et le mean score est : 0.925\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.984 et le mean score est : 0.95\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.965 et le mean score est : 0.887\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.966 et le mean score est : 0.888\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.981 et le mean score est : 0.944\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.967 et le mean score est : 0.904\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.968 et le mean score est : 0.904\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.967 et le mean score est : 0.903\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.966 et le mean score est : 0.899\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.979 et le mean score est : 0.952\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.98 et le mean score est : 0.948\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.959 et le mean score est : 0.883\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.973 et le mean score est : 0.942\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.955 et le mean score est : 0.892\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.962 et le mean score est : 0.897\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.96 et le mean score est : 0.895\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.956 et le mean score est : 0.891\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.961 et le mean score est : 0.896\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.97 et le mean score est : 0.911\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.967 et le mean score est : 0.897\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.967 et le mean score est : 0.906\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.965 et le mean score est : 0.895\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.973 et le mean score est : 0.914\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.972 et le mean score est : 0.912\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.988 et le mean score est : 0.965\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.985 et le mean score est : 0.952\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.963 et le mean score est : 0.884\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.979 et le mean score est : 0.944\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.982 et le mean score est : 0.949\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.969 et le mean score est : 0.911\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.97 et le mean score est : 0.911\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.978 et le mean score est : 0.948\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.956 et le mean score est : 0.881\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.961 et le mean score est : 0.887\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.958 et le mean score est : 0.884\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.955 et le mean score est : 0.879\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.972 et le mean score est : 0.942\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.974 et le mean score est : 0.946\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.962 et le mean score est : 0.902\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.969 et le mean score est : 0.944\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.949 et le mean score est : 0.836\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.951 et le mean score est : 0.881\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.949 et le mean score est : 0.879\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.948 et le mean score est : 0.835\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.95 et le mean score est : 0.878\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.969 et le mean score est : 0.91\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.967 et le mean score est : 0.899\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.973 et le mean score est : 0.913\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.986 et le mean score est : 0.961\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.985 et le mean score est : 0.957\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.981 et le mean score est : 0.94\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.964 et le mean score est : 0.891\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.982 et le mean score est : 0.954\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.982 et le mean score est : 0.956\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.965 et le mean score est : 0.9\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.975 et le mean score est : 0.918\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.956 et le mean score est : 0.887\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.961 et le mean score est : 0.892\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.959 et le mean score est : 0.888\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.973 et le mean score est : 0.946\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.955 et le mean score est : 0.896\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.961 et le mean score est : 0.901\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.955 et le mean score est : 0.894\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.968 et le mean score est : 0.943\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.969 et le mean score est : 0.905\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.951 et le mean score est : 0.838\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.965 et le mean score est : 0.895\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.948 et le mean score est : 0.833\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.948 et le mean score est : 0.835\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.946 et le mean score est : 0.888\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.946 et le mean score est : 0.832\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.948 et le mean score est : 0.889\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.984 et le mean score est : 0.954\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.986 et le mean score est : 0.959\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.98 et le mean score est : 0.94\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.982 et le mean score est : 0.946\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.981 et le mean score est : 0.955\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.963 et le mean score est : 0.9\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.965 et le mean score est : 0.901\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.965 et le mean score est : 0.901\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.972 et le mean score est : 0.915\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.972 et le mean score est : 0.938\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.972 et le mean score est : 0.914\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.97 et le mean score est : 0.943\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.968 et le mean score est : 0.907\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.947 et le mean score est : 0.828\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.948 et le mean score est : 0.886\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.948 et le mean score est : 0.886\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.944 et le mean score est : 0.882\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.964 et le mean score est : 0.9\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.987 et le mean score est : 0.959\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.988 et le mean score est : 0.962\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.98 et le mean score est : 0.938\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.963 et le mean score est : 0.895\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.967 et le mean score est : 0.896\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.967 et le mean score est : 0.897\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.982 et le mean score est : 0.951\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.968 et le mean score est : 0.91\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.968 et le mean score est : 0.909\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.975 et le mean score est : 0.945\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.973 et le mean score est : 0.935\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.959 et le mean score est : 0.889\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.969 et le mean score est : 0.941\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.971 et le mean score est : 0.911\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.952 et le mean score est : 0.888\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.969 et le mean score est : 0.906\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.97 et le mean score est : 0.908\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.966 et le mean score est : 0.902\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.984 et le mean score est : 0.953\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.975 et le mean score est : 0.926\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.975 et le mean score est : 0.924\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.985 et le mean score est : 0.953\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.962 et le mean score est : 0.886\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.962 et le mean score est : 0.882\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.981 et le mean score est : 0.948\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.982 et le mean score est : 0.952\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.966 et le mean score est : 0.906\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.98 et le mean score est : 0.952\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.975 et le mean score est : 0.938\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.957 et le mean score est : 0.886\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.97 et le mean score est : 0.945\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.974 et le mean score est : 0.948\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.967 et le mean score est : 0.903\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.97 et le mean score est : 0.907\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.948 et le mean score est : 0.885\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.965 et le mean score est : 0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.974 et le mean score est : 0.915\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.974 et le mean score est : 0.914\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.987 et le mean score est : 0.962\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.969 et le mean score est : 0.907\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.971 et le mean score est : 0.909\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.971 et le mean score est : 0.906\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.97 et le mean score est : 0.905\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.972 et le mean score est : 0.909\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.977 et le mean score est : 0.937\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.98 et le mean score est : 0.943\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.969 et le mean score est : 0.905\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.982 et le mean score est : 0.958\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.98 et le mean score est : 0.951\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.969 et le mean score est : 0.937\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.971 et le mean score est : 0.941\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.959 et le mean score est : 0.899\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.965 et le mean score est : 0.897\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.969 et le mean score est : 0.903\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.949 et le mean score est : 0.883\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.964 et le mean score est : 0.896\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.967 et le mean score est : 0.901\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.986 et le mean score est : 0.954\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.975 et le mean score est : 0.923\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.982 et le mean score est : 0.951\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.98 et le mean score est : 0.937\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.965 et le mean score est : 0.894\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.979 et le mean score est : 0.947\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.981 et le mean score est : 0.953\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.961 et le mean score est : 0.895\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.974 et le mean score est : 0.919\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.975 et le mean score est : 0.942\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.973 et le mean score est : 0.95\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.953 et le mean score est : 0.89\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.956 et le mean score est : 0.893\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.955 et le mean score est : 0.892\n",
      "\n",
      "Pour le seuil 0.8, le f3_score est : 0.958 et le mean score est : 0.894\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.967 et le mean score est : 0.903\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.95 et le mean score est : 0.841\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.951 et le mean score est : 0.843\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.948 et le mean score est : 0.838\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.965 et le mean score est : 0.897\n",
      "\n",
      "Pour le seuil 0.65, le f3_score est : 0.968 et le mean score est : 0.903\n"
     ]
    }
   ],
   "source": [
    "#optimisation d'hyperparametres du LGBMClassifier\n",
    "param_grid = {\n",
    "    #structural parameter\n",
    "    'num_leaves' :[int(n) for n in np.linspace(start = 20, stop = 3000, num=5)],\n",
    "    'max_depth' :[int(n) for n in np.linspace(start = 3, stop = 12, num=5)],\n",
    "    'min_child_weight' :np.linspace(start = 10, stop = 50, num=5)\n",
    "\n",
    "    #Hyperparameters for better accuracy\n",
    "    'n_estimators': [int(n) for n in np.linspace(start = 100, stop = 500, num=5)],\n",
    "    'learning_rate' : np.linspace(start = 0.01, stop = 0.3, num=5),\n",
    "\n",
    "    #hyperparameters to control overfitting\n",
    "    'lambda_l1' :np.linspace(start = 0, stop = 100, num=5),\n",
    "    'lambda_l2' :np.linspace(start = 0, stop = 100, num=5),\n",
    "    'min_gain_to_split' :np.linspace(start = 0, stop = 15, num=5)\n",
    "    'bagging_fraction' : np.linspace(start = 0, stop = 1, num=5),\n",
    "    'max_bin' : np.linspace(start = 200, stop = 300, num=5)\n",
    "    'feature_fraction' :np.linspace(start = 0, stop = 1, num=5),\n",
    "    #other hyperparameters\n",
    "    'colsample_bytree' :np.linspace(start = 0.5, stop = 0.99, num=5),\n",
    "    'subsample' :np.linspace(start = 0.5, stop = 0.99, num=5),\n",
    "\n",
    "    #'min_split_gain':np.linspace(start = 0.01, stop = 0.05, num=5),\n",
    "    \n",
    "}\n",
    "\n",
    "optimize_model(lgbm, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c67662",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e232caa9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-12T21:13:56.895373Z",
     "start_time": "2023-03-12T21:13:54.060806Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "44a3f55c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-12T21:15:32.312327Z",
     "start_time": "2023-03-12T21:15:06.495187Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;smote&#x27;, SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                (&#x27;model&#x27;, LinearSVC(random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;smote&#x27;, SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                (&#x27;model&#x27;, LinearSVC(random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE(k_neighbors=17, random_state=1001)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('smote', SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                ('model', LinearSVC(random_state=42))])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = LinearSVC(random_state=42)\n",
    "svc_smote = Pipeline([('smote', smote), ('model', svc)])\n",
    "svc_smote.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8209e06f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-12T21:17:19.505392Z",
     "start_time": "2023-03-12T21:17:18.845764Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LinearSVC' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rm/h7csftjd5bs95gx889r84c2r0000gn/T/ipykernel_4554/2338692812.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvc_smote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, owner)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;31m# delegate only on instances, not the classes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;31m# this is to allow access to the docstrings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mattr_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMethodType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mcheck\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# raise original `AttributeError` if `attr` does not exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LinearSVC' object has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "y_pred_proba = svc_smote.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2de732a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T22:22:41.239579Z",
     "start_time": "2023-03-10T22:22:40.865229Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pour le seuil 0.2, le f3_score est : 0.263 et le mean score est : 0.554\n"
     ]
    }
   ],
   "source": [
    "threshold = custom_metric(y_test, y_pred_proba, return_proba=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e4f8ffdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T22:23:58.650532Z",
     "start_time": "2023-03-10T22:22:41.247846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.845734\n",
      "f3_score : 0.262825 \n",
      "\n",
      "Mean evalation score : 0.554279\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(svc_smote, X_test, y_test, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341fd70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kernel parameters selects the type of hyperplane\n",
    "#kernels = [‘linear’, ‘rbf’, ‘poly’]\n",
    "\n",
    "#if non linear hyperplanes\n",
    "gammas = [0.1, 1, 10, 100] #gamma leads to overfitting\n",
    "\n",
    "#It controls the trade off between smooth decision boundary and classifying the training points correctly.\n",
    "#C = = [0.1, 1, 10, 100, 1000]#may lead to overfitting the training data.\n",
    "\n",
    "#when kernel is set to ‘poly’.\n",
    "#degree== [0, 1, 2, 3, 4, 5, 6]#degree=1 is the same as using a ‘linear’ kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7489cc5",
   "metadata": {},
   "source": [
    "### Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24af8665",
   "metadata": {},
   "source": [
    "## StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9f10e8fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-20T21:53:53.778469Z",
     "start_time": "2023-03-20T21:53:53.694975Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fbb40bfe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-12T21:26:18.568161Z",
     "start_time": "2023-03-12T21:26:18.481983Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(bagging_fraction=0.30000000000000004, bagging_freq=1,\n",
       "               feature_fraction=0.30000000000000004, lambda_l1=100,\n",
       "               lambda_l2=80, learning_rate=0.0305180705872894, max_bin=274,\n",
       "               max_depth=11, min_data_in_leaf=200,\n",
       "               min_gain_to_split=5.6169036486489725, n_estimators=1379,\n",
       "               num_leaves=1340, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=0.30000000000000004, bagging_freq=1,\n",
       "               feature_fraction=0.30000000000000004, lambda_l1=100,\n",
       "               lambda_l2=80, learning_rate=0.0305180705872894, max_bin=274,\n",
       "               max_depth=11, min_data_in_leaf=200,\n",
       "               min_gain_to_split=5.6169036486489725, n_estimators=1379,\n",
       "               num_leaves=1340, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.30000000000000004, bagging_freq=1,\n",
       "               feature_fraction=0.30000000000000004, lambda_l1=100,\n",
       "               lambda_l2=80, learning_rate=0.0305180705872894, max_bin=274,\n",
       "               max_depth=11, min_data_in_leaf=200,\n",
       "               min_gain_to_split=5.6169036486489725, n_estimators=1379,\n",
       "               num_leaves=1340, random_state=42)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_params = {'n_estimators': 1379,\n",
    " 'learning_rate': 0.0305180705872894,\n",
    " 'num_leaves': 1340,\n",
    " 'max_depth': 11,\n",
    " 'min_data_in_leaf': 200,\n",
    " 'max_bin': 274,\n",
    " 'lambda_l1': 100,\n",
    " 'lambda_l2': 80,\n",
    " 'min_gain_to_split': 5.6169036486489725,\n",
    " 'bagging_fraction': 0.30000000000000004,\n",
    " 'bagging_freq': 1,\n",
    " 'feature_fraction': 0.30000000000000004}\n",
    "\n",
    "lgbm = LGBMClassifier(**lgbm_params,random_state=42, n_jobs=-1)\n",
    "#lgdm_optimized = construct_model(lgbm, lgbm_params)\n",
    "#lgdm_optimized\n",
    "lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6117efc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-12T21:30:02.378873Z",
     "start_time": "2023-03-12T21:30:02.282970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=90, min_samples_leaf=7, min_samples_split=3,\n",
       "                       n_estimators=690, n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=90, min_samples_leaf=7, min_samples_split=3,\n",
       "                       n_estimators=690, n_jobs=-1, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=90, min_samples_leaf=7, min_samples_split=3,\n",
       "                       n_estimators=690, n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "randomforest_params = {\n",
    "    'n_estimators': 690, \n",
    "    'max_depth': 90, \n",
    "    'min_samples_split': 3, \n",
    "    'min_samples_leaf': 7, \n",
    "    'bootstrap': True\n",
    "}\n",
    "randomforest = RandomForestClassifier(random_state=42, n_jobs=-1, **randomforest_params)\n",
    "randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fe9cd413",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-12T21:35:02.592597Z",
     "start_time": "2023-03-12T21:35:02.502682Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=6.681553108313681e-08, n_jobs=-1, random_state=42,\n",
       "                   tol=0.0002329433780056682)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" checked><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=6.681553108313681e-08, n_jobs=-1, random_state=42,\n",
       "                   tol=0.0002329433780056682)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=6.681553108313681e-08, n_jobs=-1, random_state=42,\n",
       "                   tol=0.0002329433780056682)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logisticregression_params = {\n",
    "    'tol': 0.0002329433780056682, \n",
    "    'C': 6.681553108313681e-08, \n",
    "    'penalty': 'l2'\n",
    "}\n",
    "\n",
    "logisticregression = LogisticRegression(random_state=42, n_jobs=-1, **logisticregression_params)\n",
    "logisticregression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2ab70d68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-12T22:56:05.780733Z",
     "start_time": "2023-03-12T22:56:05.653104Z"
    }
   },
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('logisticregression', logisticregression),\n",
    "    #('RandomForestClassifier', randomforest)\n",
    "    #('LGBMClassifier', lgbm)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5dcbc0f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-12T22:56:06.831598Z",
     "start_time": "2023-03-12T22:56:06.730459Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    n_jobs=-1,\n",
    "    final_estimator=randomforest,\n",
    "    stack_method='predict_proba',\n",
    "    cv=cv,\n",
    "    passthrough=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "02ae0c1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-12T22:56:08.141571Z",
     "start_time": "2023-03-12T22:56:08.019664Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-32 {color: black;background-color: white;}#sk-container-id-32 pre{padding: 0;}#sk-container-id-32 div.sk-toggleable {background-color: white;}#sk-container-id-32 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-32 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-32 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-32 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-32 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-32 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-32 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-32 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-32 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-32 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-32 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-32 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-32 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-32 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-32 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-32 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-32 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-32 div.sk-item {position: relative;z-index: 1;}#sk-container-id-32 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-32 div.sk-item::before, #sk-container-id-32 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-32 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-32 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-32 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-32 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-32 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-32 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-32 div.sk-label-container {text-align: center;}#sk-container-id-32 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-32 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-32\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;smote&#x27;, SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 StackingClassifier(cv=StratifiedKFold(n_splits=5, random_state=1001, shuffle=True),\n",
       "                                    estimators=[(&#x27;logisticregression&#x27;,\n",
       "                                                 LogisticRegression(C=6.681553108313681e-08,\n",
       "                                                                    n_jobs=-1,\n",
       "                                                                    random_state=42,\n",
       "                                                                    tol=0.0002329433780056682))],\n",
       "                                    final_estimator=RandomForestClassifier(max_depth=90,\n",
       "                                                                           min_samples_leaf=7,\n",
       "                                                                           min_samples_split=3,\n",
       "                                                                           n_estimators=690,\n",
       "                                                                           n_jobs=-1,\n",
       "                                                                           random_state=42),\n",
       "                                    n_jobs=-1, passthrough=True,\n",
       "                                    stack_method=&#x27;predict_proba&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-123\" type=\"checkbox\" ><label for=\"sk-estimator-id-123\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;smote&#x27;, SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 StackingClassifier(cv=StratifiedKFold(n_splits=5, random_state=1001, shuffle=True),\n",
       "                                    estimators=[(&#x27;logisticregression&#x27;,\n",
       "                                                 LogisticRegression(C=6.681553108313681e-08,\n",
       "                                                                    n_jobs=-1,\n",
       "                                                                    random_state=42,\n",
       "                                                                    tol=0.0002329433780056682))],\n",
       "                                    final_estimator=RandomForestClassifier(max_depth=90,\n",
       "                                                                           min_samples_leaf=7,\n",
       "                                                                           min_samples_split=3,\n",
       "                                                                           n_estimators=690,\n",
       "                                                                           n_jobs=-1,\n",
       "                                                                           random_state=42),\n",
       "                                    n_jobs=-1, passthrough=True,\n",
       "                                    stack_method=&#x27;predict_proba&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-124\" type=\"checkbox\" ><label for=\"sk-estimator-id-124\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE(k_neighbors=17, random_state=1001)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-125\" type=\"checkbox\" ><label for=\"sk-estimator-id-125\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">model: StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(cv=StratifiedKFold(n_splits=5, random_state=1001, shuffle=True),\n",
       "                   estimators=[(&#x27;logisticregression&#x27;,\n",
       "                                LogisticRegression(C=6.681553108313681e-08,\n",
       "                                                   n_jobs=-1, random_state=42,\n",
       "                                                   tol=0.0002329433780056682))],\n",
       "                   final_estimator=RandomForestClassifier(max_depth=90,\n",
       "                                                          min_samples_leaf=7,\n",
       "                                                          min_samples_split=3,\n",
       "                                                          n_estimators=690,\n",
       "                                                          n_jobs=-1,\n",
       "                                                          random_state=42),\n",
       "                   n_jobs=-1, passthrough=True, stack_method=&#x27;predict_proba&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>logisticregression</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-126\" type=\"checkbox\" ><label for=\"sk-estimator-id-126\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=6.681553108313681e-08, n_jobs=-1, random_state=42,\n",
       "                   tol=0.0002329433780056682)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-127\" type=\"checkbox\" ><label for=\"sk-estimator-id-127\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=90, min_samples_leaf=7, min_samples_split=3,\n",
       "                       n_estimators=690, n_jobs=-1, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('smote', SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                ('model',\n",
       "                 StackingClassifier(cv=StratifiedKFold(n_splits=5, random_state=1001, shuffle=True),\n",
       "                                    estimators=[('logisticregression',\n",
       "                                                 LogisticRegression(C=6.681553108313681e-08,\n",
       "                                                                    n_jobs=-1,\n",
       "                                                                    random_state=42,\n",
       "                                                                    tol=0.0002329433780056682))],\n",
       "                                    final_estimator=RandomForestClassifier(max_depth=90,\n",
       "                                                                           min_samples_leaf=7,\n",
       "                                                                           min_samples_split=3,\n",
       "                                                                           n_estimators=690,\n",
       "                                                                           n_jobs=-1,\n",
       "                                                                           random_state=42),\n",
       "                                    n_jobs=-1, passthrough=True,\n",
       "                                    stack_method='predict_proba'))])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_line_smote = Pipeline([('smote', smote), ('model', classifier)])\n",
    "pipe_line_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8eeeac9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-12T22:58:47.991098Z",
     "start_time": "2023-03-12T22:56:17.621005Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-33 {color: black;background-color: white;}#sk-container-id-33 pre{padding: 0;}#sk-container-id-33 div.sk-toggleable {background-color: white;}#sk-container-id-33 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-33 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-33 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-33 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-33 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-33 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-33 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-33 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-33 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-33 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-33 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-33 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-33 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-33 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-33 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-33 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-33 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-33 div.sk-item {position: relative;z-index: 1;}#sk-container-id-33 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-33 div.sk-item::before, #sk-container-id-33 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-33 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-33 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-33 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-33 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-33 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-33 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-33 div.sk-label-container {text-align: center;}#sk-container-id-33 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-33 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-33\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;smote&#x27;, SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 StackingClassifier(cv=StratifiedKFold(n_splits=5, random_state=1001, shuffle=True),\n",
       "                                    estimators=[(&#x27;logisticregression&#x27;,\n",
       "                                                 LogisticRegression(C=6.681553108313681e-08,\n",
       "                                                                    n_jobs=-1,\n",
       "                                                                    random_state=42,\n",
       "                                                                    tol=0.0002329433780056682))],\n",
       "                                    final_estimator=RandomForestClassifier(max_depth=90,\n",
       "                                                                           min_samples_leaf=7,\n",
       "                                                                           min_samples_split=3,\n",
       "                                                                           n_estimators=690,\n",
       "                                                                           n_jobs=-1,\n",
       "                                                                           random_state=42),\n",
       "                                    n_jobs=-1, passthrough=True,\n",
       "                                    stack_method=&#x27;predict_proba&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-128\" type=\"checkbox\" ><label for=\"sk-estimator-id-128\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;smote&#x27;, SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 StackingClassifier(cv=StratifiedKFold(n_splits=5, random_state=1001, shuffle=True),\n",
       "                                    estimators=[(&#x27;logisticregression&#x27;,\n",
       "                                                 LogisticRegression(C=6.681553108313681e-08,\n",
       "                                                                    n_jobs=-1,\n",
       "                                                                    random_state=42,\n",
       "                                                                    tol=0.0002329433780056682))],\n",
       "                                    final_estimator=RandomForestClassifier(max_depth=90,\n",
       "                                                                           min_samples_leaf=7,\n",
       "                                                                           min_samples_split=3,\n",
       "                                                                           n_estimators=690,\n",
       "                                                                           n_jobs=-1,\n",
       "                                                                           random_state=42),\n",
       "                                    n_jobs=-1, passthrough=True,\n",
       "                                    stack_method=&#x27;predict_proba&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-129\" type=\"checkbox\" ><label for=\"sk-estimator-id-129\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE(k_neighbors=17, random_state=1001)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-130\" type=\"checkbox\" ><label for=\"sk-estimator-id-130\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">model: StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(cv=StratifiedKFold(n_splits=5, random_state=1001, shuffle=True),\n",
       "                   estimators=[(&#x27;logisticregression&#x27;,\n",
       "                                LogisticRegression(C=6.681553108313681e-08,\n",
       "                                                   n_jobs=-1, random_state=42,\n",
       "                                                   tol=0.0002329433780056682))],\n",
       "                   final_estimator=RandomForestClassifier(max_depth=90,\n",
       "                                                          min_samples_leaf=7,\n",
       "                                                          min_samples_split=3,\n",
       "                                                          n_estimators=690,\n",
       "                                                          n_jobs=-1,\n",
       "                                                          random_state=42),\n",
       "                   n_jobs=-1, passthrough=True, stack_method=&#x27;predict_proba&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>logisticregression</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-131\" type=\"checkbox\" ><label for=\"sk-estimator-id-131\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=6.681553108313681e-08, n_jobs=-1, random_state=42,\n",
       "                   tol=0.0002329433780056682)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-132\" type=\"checkbox\" ><label for=\"sk-estimator-id-132\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=90, min_samples_leaf=7, min_samples_split=3,\n",
       "                       n_estimators=690, n_jobs=-1, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('smote', SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                ('model',\n",
       "                 StackingClassifier(cv=StratifiedKFold(n_splits=5, random_state=1001, shuffle=True),\n",
       "                                    estimators=[('logisticregression',\n",
       "                                                 LogisticRegression(C=6.681553108313681e-08,\n",
       "                                                                    n_jobs=-1,\n",
       "                                                                    random_state=42,\n",
       "                                                                    tol=0.0002329433780056682))],\n",
       "                                    final_estimator=RandomForestClassifier(max_depth=90,\n",
       "                                                                           min_samples_leaf=7,\n",
       "                                                                           min_samples_split=3,\n",
       "                                                                           n_estimators=690,\n",
       "                                                                           n_jobs=-1,\n",
       "                                                                           random_state=42),\n",
       "                                    n_jobs=-1, passthrough=True,\n",
       "                                    stack_method='predict_proba'))])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_line_smote.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5ec91de8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-12T22:58:59.566583Z",
     "start_time": "2023-03-12T22:58:57.855926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pour le seuil 0.2, le f3_score est : 0.517 et le mean score est : 0.56\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = pipe_line_smote.predict_proba(X_test)[:,1]\n",
    "threshold_f3 = custom_metric(y_test, y_pred_proba, return_proba=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "032467f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-12T22:59:05.193077Z",
     "start_time": "2023-03-12T22:59:04.113500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.602627\n",
      "f3_score : 0.516562 \n",
      "\n",
      "Mean evalation score : 0.559595\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(pipe_line_smote, X_test, y_test, threshold_f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a3172d35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-12T22:47:31.714291Z",
     "start_time": "2023-03-12T22:47:30.299190Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.602627\n",
      "f3_score : 0.516562 \n",
      "\n",
      "Mean evalation score : 0.559595\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(pipe_line_smote, X_test, y_test, threshold_f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b6c79303",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-12T22:14:09.483973Z",
     "start_time": "2023-03-12T22:14:08.167641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.627341\n",
      "f3_score : 0.472210 \n",
      "\n",
      "Mean evalation score : 0.549776\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(pipe_line_smote, X_test, y_test, threshold_f3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa50766c",
   "metadata": {},
   "source": [
    "### Optimisation & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "bad3f621",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T18:28:30.309442Z",
     "start_time": "2023-03-13T18:28:29.367362Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/03/13 19:28:30 INFO mlflow.tracking.fluent: Experiment with name 'Stacked Models Hyperparameter Tuning' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'544103083895315636'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_id = dict(mlflow.set_experiment(\"Stacked Models Hyperparameter Tuning\"))['experiment_id']\n",
    "experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0297ba73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T03:09:20.604159Z",
     "start_time": "2023-03-13T20:09:34.665149Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-13 21:09:35,327]\u001b[0m A new study created in memory with name: Hyperparameters optimization\u001b[0m\n",
      "\u001b[32m[I 2023-03-13 21:21:59,434]\u001b[0m Trial 0 finished with value: 0.454734718858621 and parameters: {'tol': 0.0006725881035584207, 'C': 0.3987991138958647, 'penalty': 'l1', 'n_estimators': 993, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 7, 'bootstrap': False}. Best is trial 0 with value: 0.454734718858621.\u001b[0m\n",
      "\u001b[32m[I 2023-03-13 21:26:33,001]\u001b[0m Trial 1 finished with value: 0.4561456035261129 and parameters: {'tol': 0.00046616942762632487, 'C': 2.2799099795108338e-10, 'penalty': 'l1', 'n_estimators': 362, 'max_depth': 100, 'min_samples_split': 3, 'min_samples_leaf': 4, 'bootstrap': False}. Best is trial 1 with value: 0.4561456035261129.\u001b[0m\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-03-13 21:33:24,514]\u001b[0m Trial 2 finished with value: 0.4957160791237266 and parameters: {'tol': 0.0005658706084995838, 'C': 4.393304463644752e-09, 'penalty': 'l2', 'n_estimators': 806, 'max_depth': 90, 'min_samples_split': 2, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 2 with value: 0.4957160791237266.\u001b[0m\n",
      "\u001b[32m[I 2023-03-13 21:38:34,847]\u001b[0m Trial 3 finished with value: 0.4757420827993262 and parameters: {'tol': 0.00039664290327965, 'C': 0.01097757626887593, 'penalty': 'l1', 'n_estimators': 248, 'max_depth': 40, 'min_samples_split': 10, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 2 with value: 0.4957160791237266.\u001b[0m\n",
      "\u001b[32m[I 2023-03-13 21:43:09,755]\u001b[0m Trial 4 finished with value: 0.5046308583928854 and parameters: {'tol': 0.0005343623758313446, 'C': 2.2500563555053118e-07, 'penalty': 'l2', 'n_estimators': 418, 'max_depth': 110, 'min_samples_split': 3, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 4 with value: 0.5046308583928854.\u001b[0m\n",
      "\u001b[32m[I 2023-03-13 21:46:51,179]\u001b[0m Trial 5 finished with value: 0.5188447704625043 and parameters: {'tol': 8.800972784927664e-05, 'C': 4.3309735297177795e-05, 'penalty': 'l2', 'n_estimators': 477, 'max_depth': 60, 'min_samples_split': 9, 'min_samples_leaf': 8, 'bootstrap': True}. Best is trial 5 with value: 0.5188447704625043.\u001b[0m\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-03-13 21:52:37,720]\u001b[0m Trial 6 finished with value: 0.5146172241858294 and parameters: {'tol': 0.0006046565175137414, 'C': 2.8614603088446747e-05, 'penalty': 'l2', 'n_estimators': 716, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'bootstrap': True}. Best is trial 5 with value: 0.5188447704625043.\u001b[0m\n",
      "\u001b[32m[I 2023-03-13 21:59:46,971]\u001b[0m Trial 7 finished with value: 0.5089453548630347 and parameters: {'tol': 0.0009074556234075279, 'C': 5.359355142888692e-09, 'penalty': 'l1', 'n_estimators': 977, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 8, 'bootstrap': True}. Best is trial 5 with value: 0.5188447704625043.\u001b[0m\n",
      "\u001b[32m[I 2023-03-13 22:04:33,059]\u001b[0m Trial 8 finished with value: 0.49474060991147634 and parameters: {'tol': 0.0005457271994172791, 'C': 0.001168676564343921, 'penalty': 'l2', 'n_estimators': 571, 'max_depth': 110, 'min_samples_split': 3, 'min_samples_leaf': 6, 'bootstrap': True}. Best is trial 5 with value: 0.5188447704625043.\u001b[0m\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-13 22:11:05,584]\u001b[0m Trial 9 finished with value: 0.3966320576980161 and parameters: {'tol': 0.0008495847734699787, 'C': 0.0006440038025568012, 'penalty': 'l1', 'n_estimators': 973, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 5, 'bootstrap': True}. Best is trial 5 with value: 0.5188447704625043.\u001b[0m\n",
      "\u001b[32m[I 2023-03-13 22:17:31,729]\u001b[0m Trial 10 finished with value: 0.49757764397819226 and parameters: {'tol': 2.63444246011602e-06, 'C': 3.708879088943625e-06, 'penalty': 'l2', 'n_estimators': 544, 'max_depth': 70, 'min_samples_split': 7, 'min_samples_leaf': 10, 'bootstrap': False}. Best is trial 5 with value: 0.5188447704625043.\u001b[0m\n",
      "\u001b[32m[I 2023-03-13 22:22:56,574]\u001b[0m Trial 11 finished with value: 0.5181512401396535 and parameters: {'tol': 0.0002315538176706145, 'C': 1.616877296302631e-05, 'penalty': 'l2', 'n_estimators': 735, 'max_depth': 70, 'min_samples_split': 5, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 5 with value: 0.5188447704625043.\u001b[0m\n",
      "\u001b[32m[I 2023-03-13 22:28:42,770]\u001b[0m Trial 12 finished with value: 0.5123750178494988 and parameters: {'tol': 0.00018596878522303818, 'C': 5.7420165987451845e-06, 'penalty': 'l2', 'n_estimators': 727, 'max_depth': 70, 'min_samples_split': 5, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 5 with value: 0.5188447704625043.\u001b[0m\n",
      "\u001b[32m[I 2023-03-13 22:32:15,759]\u001b[0m Trial 13 finished with value: 0.5213053199150594 and parameters: {'tol': 0.00023664137882829637, 'C': 7.196550900784106e-05, 'penalty': 'l2', 'n_estimators': 459, 'max_depth': 50, 'min_samples_split': 6, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 13 with value: 0.5213053199150594.\u001b[0m\n",
      "\u001b[32m[I 2023-03-13 22:36:06,601]\u001b[0m Trial 14 finished with value: 0.518103692901692 and parameters: {'tol': 7.931522546526424e-07, 'C': 0.00026947634129896857, 'penalty': 'l2', 'n_estimators': 462, 'max_depth': 50, 'min_samples_split': 7, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 13 with value: 0.5213053199150594.\u001b[0m\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-03-13 22:41:00,005]\u001b[0m Trial 15 finished with value: 0.49248277586405154 and parameters: {'tol': 0.00021874895846493058, 'C': 2.231756961892468e-07, 'penalty': 'l2', 'n_estimators': 369, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 8, 'bootstrap': False}. Best is trial 13 with value: 0.5213053199150594.\u001b[0m\n",
      "\u001b[32m[I 2023-03-13 22:43:11,663]\u001b[0m Trial 16 finished with value: 0.4841218747158784 and parameters: {'tol': 0.0003257009558548905, 'C': 0.01000158954147543, 'penalty': 'l2', 'n_estimators': 205, 'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 8, 'bootstrap': True}. Best is trial 13 with value: 0.5213053199150594.\u001b[0m\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-03-13 22:46:54,165]\u001b[0m Trial 17 finished with value: 0.5197477779582982 and parameters: {'tol': 0.00013439807892639643, 'C': 9.599163195123483e-05, 'penalty': 'l2', 'n_estimators': 499, 'max_depth': 80, 'min_samples_split': 6, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 13 with value: 0.5213053199150594.\u001b[0m\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-13 22:55:02,020]\u001b[0m Trial 18 finished with value: 0.45762937701367135 and parameters: {'tol': 0.00034468131560502476, 'C': 0.2888951406493446, 'penalty': 'l2', 'n_estimators': 637, 'max_depth': 80, 'min_samples_split': 6, 'min_samples_leaf': 10, 'bootstrap': False}. Best is trial 13 with value: 0.5213053199150594.\u001b[0m\n",
      "\u001b[32m[I 2023-03-13 22:57:25,417]\u001b[0m Trial 19 finished with value: 0.5161119780243946 and parameters: {'tol': 0.00013759414540686767, 'C': 9.810196472179545e-07, 'penalty': 'l2', 'n_estimators': 304, 'max_depth': 80, 'min_samples_split': 6, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 13 with value: 0.5213053199150594.\u001b[0m\n",
      "\u001b[32m[I 2023-03-13 23:01:24,919]\u001b[0m Trial 20 finished with value: 0.5118895174001783 and parameters: {'tol': 0.0002732473156546263, 'C': 0.0002304229039451588, 'penalty': 'l2', 'n_estimators': 517, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 7, 'bootstrap': True}. Best is trial 13 with value: 0.5213053199150594.\u001b[0m\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2023-03-13 23:04:53,602]\u001b[0m Trial 21 finished with value: 0.516775102579782 and parameters: {'tol': 0.000101403788622337, 'C': 3.643044677616233e-05, 'penalty': 'l2', 'n_estimators': 477, 'max_depth': 60, 'min_samples_split': 8, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 13 with value: 0.5213053199150594.\u001b[0m\n",
      "\u001b[32m[I 2023-03-13 23:09:40,707]\u001b[0m Trial 22 finished with value: 0.5207382561518061 and parameters: {'tol': 0.00010464629154527027, 'C': 6.211714990440504e-05, 'penalty': 'l2', 'n_estimators': 621, 'max_depth': 60, 'min_samples_split': 8, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 13 with value: 0.5213053199150594.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-13 23:14:34,354]\u001b[0m Trial 23 finished with value: 0.4910924100314653 and parameters: {'tol': 0.000145236079433311, 'C': 0.003058303137840073, 'penalty': 'l2', 'n_estimators': 618, 'max_depth': 80, 'min_samples_split': 8, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 13 with value: 0.5213053199150594.\u001b[0m\n",
      "\u001b[32m[I 2023-03-13 23:19:27,428]\u001b[0m Trial 24 finished with value: 0.5202337097628129 and parameters: {'tol': 0.0002667460591128999, 'C': 0.00015231296616623587, 'penalty': 'l2', 'n_estimators': 654, 'max_depth': 60, 'min_samples_split': 6, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 13 with value: 0.5213053199150594.\u001b[0m\n",
      "\u001b[32m[I 2023-03-13 23:24:22,123]\u001b[0m Trial 25 finished with value: 0.5187512670745268 and parameters: {'tol': 0.0002867517624962154, 'C': 0.00010589849572292074, 'penalty': 'l2', 'n_estimators': 649, 'max_depth': 40, 'min_samples_split': 7, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 13 with value: 0.5213053199150594.\u001b[0m\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2023-03-13 23:33:17,890]\u001b[0m Trial 26 finished with value: 0.49245792704576025 and parameters: {'tol': 0.0004056601007986439, 'C': 0.0017581743089473288, 'penalty': 'l1', 'n_estimators': 872, 'max_depth': 60, 'min_samples_split': 5, 'min_samples_leaf': 7, 'bootstrap': True}. Best is trial 13 with value: 0.5213053199150594.\u001b[0m\n",
      "\u001b[32m[I 2023-03-13 23:41:13,206]\u001b[0m Trial 27 finished with value: 0.5007235389422522 and parameters: {'tol': 0.00025556706476494986, 'C': 5.279207132109547e-06, 'penalty': 'l2', 'n_estimators': 687, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 10, 'bootstrap': False}. Best is trial 13 with value: 0.5213053199150594.\u001b[0m\n",
      "\u001b[32m[I 2023-03-13 23:45:58,799]\u001b[0m Trial 28 finished with value: 0.518846729195918 and parameters: {'tol': 0.00021463647649037633, 'C': 0.00026381649948704927, 'penalty': 'l2', 'n_estimators': 614, 'max_depth': 40, 'min_samples_split': 9, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 13 with value: 0.5213053199150594.\u001b[0m\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-13 23:54:32,202]\u001b[0m Trial 29 finished with value: 0.4532619168627766 and parameters: {'tol': 0.00034511059352829686, 'C': 0.010018387383938673, 'penalty': 'l1', 'n_estimators': 792, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 6, 'bootstrap': False}. Best is trial 13 with value: 0.5213053199150594.\u001b[0m\n",
      "\u001b[32m[I 2023-03-13 23:57:45,870]\u001b[0m Trial 30 finished with value: 0.5177525631552636 and parameters: {'tol': 7.650569850006862e-05, 'C': 1.4245538990334303e-05, 'penalty': 'l2', 'n_estimators': 410, 'max_depth': 50, 'min_samples_split': 7, 'min_samples_leaf': 8, 'bootstrap': True}. Best is trial 13 with value: 0.5213053199150594.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 00:02:02,499]\u001b[0m Trial 31 finished with value: 0.5161883063347172 and parameters: {'tol': 0.0001841310151998787, 'C': 0.0002469011786446593, 'penalty': 'l2', 'n_estimators': 552, 'max_depth': 70, 'min_samples_split': 6, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 13 with value: 0.5213053199150594.\u001b[0m\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-03-14 00:05:43,222]\u001b[0m Trial 32 finished with value: 0.5217178797984975 and parameters: {'tol': 0.0001587829180496811, 'C': 0.0001097503859083156, 'penalty': 'l2', 'n_estimators': 504, 'max_depth': 90, 'min_samples_split': 6, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 32 with value: 0.5217178797984975.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 00:10:00,167]\u001b[0m Trial 33 finished with value: 0.5189515643505936 and parameters: {'tol': 0.0004451312407075899, 'C': 6.429135809248252e-05, 'penalty': 'l2', 'n_estimators': 572, 'max_depth': 90, 'min_samples_split': 4, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 32 with value: 0.5217178797984975.\u001b[0m\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-03-14 00:15:13,249]\u001b[0m Trial 34 finished with value: 0.5098779798682856 and parameters: {'tol': 0.00029607027741629746, 'C': 0.0008579853606093125, 'penalty': 'l1', 'n_estimators': 427, 'max_depth': 60, 'min_samples_split': 6, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 32 with value: 0.5217178797984975.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 00:18:03,970]\u001b[0m Trial 35 finished with value: 0.5108591975352068 and parameters: {'tol': 5.056310142734948e-05, 'C': 2.4361197848092426e-06, 'penalty': 'l2', 'n_estimators': 362, 'max_depth': 90, 'min_samples_split': 6, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 32 with value: 0.5217178797984975.\u001b[0m\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-14 00:27:03,276]\u001b[0m Trial 36 finished with value: 0.5033021950223129 and parameters: {'tol': 0.00018340445563839065, 'C': 1.642795316562942e-05, 'penalty': 'l2', 'n_estimators': 784, 'max_depth': 60, 'min_samples_split': 5, 'min_samples_leaf': 10, 'bootstrap': False}. Best is trial 32 with value: 0.5217178797984975.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 00:32:49,441]\u001b[0m Trial 37 finished with value: 0.5069535992462878 and parameters: {'tol': 0.00048419513352969266, 'C': 7.110292685346408e-05, 'penalty': 'l2', 'n_estimators': 679, 'max_depth': 100, 'min_samples_split': 7, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 32 with value: 0.5217178797984975.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 00:37:37,011]\u001b[0m Trial 38 finished with value: 0.4921362670571515 and parameters: {'tol': 0.00039608010160475807, 'C': 0.003964965727406863, 'penalty': 'l1', 'n_estimators': 300, 'max_depth': 40, 'min_samples_split': 8, 'min_samples_leaf': 8, 'bootstrap': True}. Best is trial 32 with value: 0.5217178797984975.\u001b[0m\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-14 00:43:35,661]\u001b[0m Trial 39 finished with value: 0.5124927782775306 and parameters: {'tol': 5.629925939819026e-05, 'C': 1.0921430932750344e-06, 'penalty': 'l2', 'n_estimators': 838, 'max_depth': 20, 'min_samples_split': 10, 'min_samples_leaf': 7, 'bootstrap': True}. Best is trial 32 with value: 0.5217178797984975.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 00:48:36,528]\u001b[0m Trial 40 finished with value: 0.462591641937114 and parameters: {'tol': 0.0001321126294988545, 'C': 0.05455778911874631, 'penalty': 'l2', 'n_estimators': 586, 'max_depth': 50, 'min_samples_split': 6, 'min_samples_leaf': 5, 'bootstrap': True}. Best is trial 32 with value: 0.5217178797984975.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 00:52:26,820]\u001b[0m Trial 41 finished with value: 0.5216476544788312 and parameters: {'tol': 0.00014194238738520783, 'C': 0.00010651344669799637, 'penalty': 'l2', 'n_estimators': 510, 'max_depth': 80, 'min_samples_split': 6, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 32 with value: 0.5217178797984975.\u001b[0m\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2023-03-14 00:56:30,003]\u001b[0m Trial 42 finished with value: 0.5071943014246317 and parameters: {'tol': 0.0002461544035229035, 'C': 0.0006667754641570634, 'penalty': 'l2', 'n_estimators': 511, 'max_depth': 90, 'min_samples_split': 5, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 32 with value: 0.5217178797984975.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 00:59:41,821]\u001b[0m Trial 43 finished with value: 0.5171709782434151 and parameters: {'tol': 0.00018668476994066548, 'C': 3.9023533756181874e-05, 'penalty': 'l2', 'n_estimators': 430, 'max_depth': 70, 'min_samples_split': 6, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 32 with value: 0.5217178797984975.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 01:03:41,443]\u001b[0m Trial 44 finished with value: 0.5197958090913609 and parameters: {'tol': 9.101187648263354e-05, 'C': 1.2276752727587271e-05, 'penalty': 'l2', 'n_estimators': 535, 'max_depth': 110, 'min_samples_split': 7, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 32 with value: 0.5217178797984975.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 01:07:18,071]\u001b[0m Trial 45 finished with value: 0.5102275028721379 and parameters: {'tol': 3.2502176417726044e-05, 'C': 0.0005016285574240206, 'penalty': 'l2', 'n_estimators': 460, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 32 with value: 0.5217178797984975.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 01:12:04,090]\u001b[0m Trial 46 finished with value: 0.5207106328944995 and parameters: {'tol': 0.00010948273843103696, 'C': 0.00018843929798572967, 'penalty': 'l2', 'n_estimators': 658, 'max_depth': 70, 'min_samples_split': 4, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 32 with value: 0.5217178797984975.\u001b[0m\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-14 01:16:31,684]\u001b[0m Trial 47 finished with value: 0.5079324136674371 and parameters: {'tol': 9.340148825995637e-05, 'C': 3.5040551143381445e-05, 'penalty': 'l1', 'n_estimators': 596, 'max_depth': 80, 'min_samples_split': 3, 'min_samples_leaf': 8, 'bootstrap': True}. Best is trial 32 with value: 0.5217178797984975.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 01:21:30,828]\u001b[0m Trial 48 finished with value: 0.4673365869470838 and parameters: {'tol': 3.1702360986203565e-05, 'C': 0.0020107260802443936, 'penalty': 'l2', 'n_estimators': 402, 'max_depth': 70, 'min_samples_split': 2, 'min_samples_leaf': 10, 'bootstrap': False}. Best is trial 32 with value: 0.5217178797984975.\u001b[0m\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-14 01:27:40,245]\u001b[0m Trial 49 finished with value: 0.4882589479503244 and parameters: {'tol': 0.00015984872859983062, 'C': 0.00046633473050138974, 'penalty': 'l2', 'n_estimators': 741, 'max_depth': 90, 'min_samples_split': 4, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 32 with value: 0.5217178797984975.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 01:30:24,673]\u001b[0m Trial 50 finished with value: 0.5214904263462838 and parameters: {'tol': 0.00021418426190477637, 'C': 7.754320057591223e-05, 'penalty': 'l2', 'n_estimators': 313, 'max_depth': 70, 'min_samples_split': 9, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 32 with value: 0.5217178797984975.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 01:33:10,278]\u001b[0m Trial 51 finished with value: 0.5213944736356522 and parameters: {'tol': 0.00021336825458661925, 'C': 7.558297377284024e-05, 'penalty': 'l2', 'n_estimators': 340, 'max_depth': 70, 'min_samples_split': 9, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 32 with value: 0.5217178797984975.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 01:35:26,624]\u001b[0m Trial 52 finished with value: 0.5215192222720231 and parameters: {'tol': 0.00022265838684312983, 'C': 8.209332511190348e-05, 'penalty': 'l2', 'n_estimators': 287, 'max_depth': 80, 'min_samples_split': 9, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 32 with value: 0.5217178797984975.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 01:38:02,858]\u001b[0m Trial 53 finished with value: 0.5236448800212556 and parameters: {'tol': 0.0002168333834926689, 'C': 0.00012720838557589821, 'penalty': 'l2', 'n_estimators': 311, 'max_depth': 80, 'min_samples_split': 9, 'min_samples_leaf': 8, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 01:40:21,376]\u001b[0m Trial 54 finished with value: 0.513718795150387 and parameters: {'tol': 0.0002171075312421685, 'C': 1.985142258716837e-05, 'penalty': 'l2', 'n_estimators': 289, 'max_depth': 80, 'min_samples_split': 9, 'min_samples_leaf': 8, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 01:42:31,599]\u001b[0m Trial 55 finished with value: 0.5169903562139038 and parameters: {'tol': 0.00016767478305152557, 'C': 0.00011104704372284857, 'penalty': 'l2', 'n_estimators': 251, 'max_depth': 100, 'min_samples_split': 9, 'min_samples_leaf': 8, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 01:45:19,126]\u001b[0m Trial 56 finished with value: 0.4960166465624723 and parameters: {'tol': 0.00021003139788908231, 'C': 0.0011119144953732653, 'penalty': 'l2', 'n_estimators': 325, 'max_depth': 90, 'min_samples_split': 10, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 01:47:12,866]\u001b[0m Trial 57 finished with value: 0.5088945019819208 and parameters: {'tol': 0.00030547098326643807, 'C': 7.87828903948379e-06, 'penalty': 'l2', 'n_estimators': 220, 'max_depth': 80, 'min_samples_split': 9, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 01:49:56,900]\u001b[0m Trial 58 finished with value: 0.5115747601497368 and parameters: {'tol': 0.00013835412959965917, 'C': 2.8861997117252254e-05, 'penalty': 'l2', 'n_estimators': 335, 'max_depth': 70, 'min_samples_split': 9, 'min_samples_leaf': 7, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 01:53:09,832]\u001b[0m Trial 59 finished with value: 0.4965698230383122 and parameters: {'tol': 0.000273788999871346, 'C': 0.00012059101540922626, 'penalty': 'l2', 'n_estimators': 263, 'max_depth': 80, 'min_samples_split': 10, 'min_samples_leaf': 9, 'bootstrap': False}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 01:56:53,245]\u001b[0m Trial 60 finished with value: 0.5119399020260377 and parameters: {'tol': 0.0002296772375146499, 'C': 0.0004437387938349645, 'penalty': 'l1', 'n_estimators': 390, 'max_depth': 80, 'min_samples_split': 10, 'min_samples_leaf': 8, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 01:59:39,451]\u001b[0m Trial 61 finished with value: 0.5193388523201402 and parameters: {'tol': 0.00023986060228654418, 'C': 5.550992907277324e-05, 'penalty': 'l2', 'n_estimators': 351, 'max_depth': 90, 'min_samples_split': 8, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 02:01:53,580]\u001b[0m Trial 62 finished with value: 0.5193310333593716 and parameters: {'tol': 0.0001993947695897542, 'C': 0.00018263233362098965, 'penalty': 'l2', 'n_estimators': 270, 'max_depth': 70, 'min_samples_split': 9, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 02:05:10,603]\u001b[0m Trial 63 finished with value: 0.517846739120531 and parameters: {'tol': 0.00015217678697512646, 'C': 8.982017562382839e-06, 'penalty': 'l2', 'n_estimators': 446, 'max_depth': 80, 'min_samples_split': 9, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 02:08:08,315]\u001b[0m Trial 64 finished with value: 0.5220211266901451 and parameters: {'tol': 0.00032127555358762126, 'C': 8.131498815202491e-05, 'penalty': 'l2', 'n_estimators': 386, 'max_depth': 70, 'min_samples_split': 8, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 02:09:57,327]\u001b[0m Trial 65 finished with value: 0.5203928219975131 and parameters: {'tol': 0.00025755844215671496, 'C': 4.296483476606603e-05, 'penalty': 'l2', 'n_estimators': 225, 'max_depth': 70, 'min_samples_split': 8, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 02:13:04,413]\u001b[0m Trial 66 finished with value: 0.5019659797988367 and parameters: {'tol': 0.00032203643825582447, 'C': 0.0003809150372761885, 'penalty': 'l2', 'n_estimators': 375, 'max_depth': 80, 'min_samples_split': 9, 'min_samples_leaf': 6, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 02:15:38,361]\u001b[0m Trial 67 finished with value: 0.5136119896085586 and parameters: {'tol': 0.00017205307905726798, 'C': 2.550056005858908e-05, 'penalty': 'l2', 'n_estimators': 331, 'max_depth': 90, 'min_samples_split': 8, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 02:18:01,302]\u001b[0m Trial 68 finished with value: 0.5197377515716212 and parameters: {'tol': 0.00012088924182023474, 'C': 0.00011447256845071998, 'penalty': 'l2', 'n_estimators': 285, 'max_depth': 80, 'min_samples_split': 9, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-14 02:21:52,222]\u001b[0m Trial 69 finished with value: 0.49776448929167394 and parameters: {'tol': 0.0002845972900397936, 'C': 0.0010187421613309987, 'penalty': 'l2', 'n_estimators': 484, 'max_depth': 60, 'min_samples_split': 10, 'min_samples_leaf': 8, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kone/opt/anaconda3/envs/oc_project_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2023-03-14 02:25:42,717]\u001b[0m Trial 70 finished with value: 0.4904676199114465 and parameters: {'tol': 0.0003495081558562336, 'C': 0.00028271633020246793, 'penalty': 'l2', 'n_estimators': 310, 'max_depth': 70, 'min_samples_split': 7, 'min_samples_leaf': 10, 'bootstrap': False}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 02:28:50,377]\u001b[0m Trial 71 finished with value: 0.5182818728423269 and parameters: {'tol': 0.00020499395906565891, 'C': 7.378500624115612e-05, 'penalty': 'l2', 'n_estimators': 395, 'max_depth': 60, 'min_samples_split': 8, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 02:31:39,365]\u001b[0m Trial 72 finished with value: 0.514929841089263 and parameters: {'tol': 0.00023528383242915176, 'C': 1.7641122906997865e-05, 'penalty': 'l2', 'n_estimators': 351, 'max_depth': 70, 'min_samples_split': 6, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 02:35:15,299]\u001b[0m Trial 73 finished with value: 0.5209528868900202 and parameters: {'tol': 0.0002558186562094545, 'C': 0.00014466058060430233, 'penalty': 'l2', 'n_estimators': 490, 'max_depth': 50, 'min_samples_split': 7, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 02:38:46,460]\u001b[0m Trial 74 finished with value: 0.5186420336230378 and parameters: {'tol': 0.00015624738643552056, 'C': 6.383282989810551e-05, 'penalty': 'l2', 'n_estimators': 457, 'max_depth': 80, 'min_samples_split': 9, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 02:42:07,012]\u001b[0m Trial 75 finished with value: 0.5186236082370136 and parameters: {'tol': 0.00019965003184513065, 'C': 4.808218057989316e-06, 'penalty': 'l2', 'n_estimators': 434, 'max_depth': 90, 'min_samples_split': 6, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 02:45:27,445]\u001b[0m Trial 76 finished with value: 0.5137145486682038 and parameters: {'tol': 0.00031374148649623867, 'C': 0.0003442429397766922, 'penalty': 'l1', 'n_estimators': 375, 'max_depth': 70, 'min_samples_split': 10, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 02:49:24,496]\u001b[0m Trial 77 finished with value: 0.5212381191298358 and parameters: {'tol': 0.00012091317123304426, 'C': 2.7549232738182693e-05, 'penalty': 'l2', 'n_estimators': 530, 'max_depth': 60, 'min_samples_split': 5, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 02:51:37,257]\u001b[0m Trial 78 finished with value: 0.5040570257436728 and parameters: {'tol': 0.00022989078190036833, 'C': 0.0001907860239137164, 'penalty': 'l2', 'n_estimators': 238, 'max_depth': 50, 'min_samples_split': 9, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 02:55:50,860]\u001b[0m Trial 79 finished with value: 0.5171055434634597 and parameters: {'tol': 0.00017932552765122155, 'C': 1.1874740009585946e-05, 'penalty': 'l2', 'n_estimators': 562, 'max_depth': 80, 'min_samples_split': 8, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 02:58:16,231]\u001b[0m Trial 80 finished with value: 0.5172842896403943 and parameters: {'tol': 0.00028138647780254824, 'C': 5.951793376308081e-05, 'penalty': 'l2', 'n_estimators': 317, 'max_depth': 100, 'min_samples_split': 6, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 03:02:11,576]\u001b[0m Trial 81 finished with value: 0.5220419488895706 and parameters: {'tol': 0.00012141897869323287, 'C': 3.055199439795399e-05, 'penalty': 'l2', 'n_estimators': 516, 'max_depth': 60, 'min_samples_split': 5, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 03:06:03,980]\u001b[0m Trial 82 finished with value: 0.5235303788232935 and parameters: {'tol': 7.430017034046849e-05, 'C': 0.00010953943834137898, 'penalty': 'l2', 'n_estimators': 508, 'max_depth': 60, 'min_samples_split': 5, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 03:10:08,638]\u001b[0m Trial 83 finished with value: 0.517742918680305 and parameters: {'tol': 7.961439544405525e-05, 'C': 9.606092619773377e-05, 'penalty': 'l2', 'n_estimators': 510, 'max_depth': 60, 'min_samples_split': 5, 'min_samples_leaf': 8, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-14 03:12:22,008]\u001b[0m Trial 84 finished with value: 0.5027519641982131 and parameters: {'tol': 0.0001306880754066782, 'C': 0.0006991729498056883, 'penalty': 'l2', 'n_estimators': 276, 'max_depth': 70, 'min_samples_split': 5, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 03:14:01,391]\u001b[0m Trial 85 finished with value: 0.5167468252882479 and parameters: {'tol': 6.977639664743653e-05, 'C': 3.214526096853402e-05, 'penalty': 'l2', 'n_estimators': 203, 'max_depth': 60, 'min_samples_split': 5, 'min_samples_leaf': 8, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 03:17:14,725]\u001b[0m Trial 86 finished with value: 0.5146356750932366 and parameters: {'tol': 0.0001137286380565032, 'C': 0.0001967689016641687, 'penalty': 'l2', 'n_estimators': 412, 'max_depth': 70, 'min_samples_split': 4, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 03:24:02,257]\u001b[0m Trial 87 finished with value: 0.5004946375331669 and parameters: {'tol': 0.00015015400166428294, 'C': 4.5221269336407906e-05, 'penalty': 'l2', 'n_estimators': 579, 'max_depth': 60, 'min_samples_split': 5, 'min_samples_leaf': 9, 'bootstrap': False}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 03:28:12,994]\u001b[0m Trial 88 finished with value: 0.5081667735534842 and parameters: {'tol': 9.994534004088746e-05, 'C': 2.0244340211946124e-05, 'penalty': 'l1', 'n_estimators': 545, 'max_depth': 70, 'min_samples_split': 10, 'min_samples_leaf': 8, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 03:30:56,634]\u001b[0m Trial 89 finished with value: 0.516540273238735 and parameters: {'tol': 0.00019984143425003814, 'C': 9.372408359316607e-05, 'penalty': 'l2', 'n_estimators': 343, 'max_depth': 80, 'min_samples_split': 9, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 03:33:29,303]\u001b[0m Trial 90 finished with value: 0.5109584962953555 and parameters: {'tol': 0.00017427282909686766, 'C': 0.0003014147355013122, 'penalty': 'l2', 'n_estimators': 304, 'max_depth': 90, 'min_samples_split': 6, 'min_samples_leaf': 7, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 03:37:08,257]\u001b[0m Trial 91 finished with value: 0.5193316580697418 and parameters: {'tol': 0.0002177630663370541, 'C': 0.00012727674029073654, 'penalty': 'l2', 'n_estimators': 471, 'max_depth': 50, 'min_samples_split': 6, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 03:40:48,323]\u001b[0m Trial 92 finished with value: 0.5131065590833744 and parameters: {'tol': 0.0002459204185328286, 'C': 9.223438767917466e-06, 'penalty': 'l2', 'n_estimators': 500, 'max_depth': 40, 'min_samples_split': 7, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 03:44:47,931]\u001b[0m Trial 93 finished with value: 0.5199634240208337 and parameters: {'tol': 0.00014767912376628076, 'C': 4.735389783005874e-05, 'penalty': 'l2', 'n_estimators': 529, 'max_depth': 60, 'min_samples_split': 6, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 03:48:19,879]\u001b[0m Trial 94 finished with value: 0.5035993515899729 and parameters: {'tol': 0.00018414216763679218, 'C': 0.0006487151707888565, 'penalty': 'l2', 'n_estimators': 441, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 03:51:12,494]\u001b[0m Trial 95 finished with value: 0.5175572073741659 and parameters: {'tol': 0.00027094682234475565, 'C': 7.635032426973402e-05, 'penalty': 'l2', 'n_estimators': 382, 'max_depth': 70, 'min_samples_split': 9, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 03:54:42,369]\u001b[0m Trial 96 finished with value: 0.518610226877765 and parameters: {'tol': 5.812737371477236e-05, 'C': 1.890649416753611e-05, 'penalty': 'l2', 'n_estimators': 474, 'max_depth': 80, 'min_samples_split': 6, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 03:57:59,890]\u001b[0m Trial 97 finished with value: 0.5194953195999584 and parameters: {'tol': 0.0002257503025511581, 'C': 0.00018741040745142148, 'penalty': 'l2', 'n_estimators': 424, 'max_depth': 60, 'min_samples_split': 8, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 04:04:53,903]\u001b[0m Trial 98 finished with value: 0.5160187032842586 and parameters: {'tol': 9.60946854014393e-05, 'C': 0.00029148452347065094, 'penalty': 'l2', 'n_estimators': 918, 'max_depth': 70, 'min_samples_split': 4, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 04:09:20,394]\u001b[0m Trial 99 finished with value: 0.5001819921515386 and parameters: {'tol': 0.00016064445951232103, 'C': 3.998418057313473e-05, 'penalty': 'l2', 'n_estimators': 365, 'max_depth': 80, 'min_samples_split': 3, 'min_samples_leaf': 8, 'bootstrap': False}. Best is trial 53 with value: 0.5236448800212556.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.5236448800212556\n",
      "\n",
      "Optimized parameters: {'tol': 0.0002168333834926689, 'C': 0.00012720838557589821, 'penalty': 'l2', 'n_estimators': 311, 'max_depth': 80, 'min_samples_split': 9, 'min_samples_leaf': 8, 'bootstrap': True}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def stacked_models_objective(trial):\n",
    "    \n",
    "    logistic_params = {\n",
    "        'tol' : trial.suggest_uniform('tol' , 1e-10 , 1e-3),\n",
    "        'C' : trial.suggest_loguniform(\"C\", 1e-10, 1),\n",
    "        'penalty': trial.suggest_categorical('penalty', ['l2', 'l1'])\n",
    "    }\n",
    "    if logistic_params['penalty'] == 'l1':\n",
    "        logistic_params['solver'] = 'saga'\n",
    "    else:\n",
    "        logistic_params['solver'] = 'lbfgs'\n",
    "\n",
    "    logistic_regression = LogisticRegression(\n",
    "        **logistic_params, random_state=42, n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    randomforest_params = {# Number of trees in random forest\n",
    "    'n_estimators': trial.suggest_int(\"n_estimators\", 200, 1000),\n",
    "    # Maximum number of levels in tree\n",
    "    'max_depth': trial.suggest_int(\"max_depth\", 10, 110, step=10),\n",
    "    # Minimum number of samples required to split a node\n",
    "    'min_samples_split': trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    'min_samples_leaf': trial.suggest_int(\"min_samples_leaf\", 2, 10),\n",
    "    # Number of features to consider at every split\n",
    "    #'max_features': trial.suggest_int(\"max_features\", 10, 211),\n",
    "    # Method of selecting samples for training each tree\n",
    "    'bootstrap': trial.suggest_categorical(\"bootstrap\", [True, False])\n",
    "    }\n",
    "\n",
    "    randomforest = RandomForestClassifier( \n",
    "        **randomforest_params, n_jobs=-1, random_state=42\n",
    "    )\n",
    "    \n",
    "    estimators = [('logisticregression', logistic_regression)]\n",
    "    \n",
    "    classifier = StackingClassifier(\n",
    "        estimators=estimators,\n",
    "        n_jobs=-1,\n",
    "        final_estimator=randomforest,\n",
    "        stack_method='predict_proba',\n",
    "        cv=cv,\n",
    "        passthrough=True\n",
    "    )\n",
    "    \n",
    "    stacked_smote = Pipeline([('smote', smote), ('model', classifier)])\n",
    "    \n",
    "    scores = cross_val_score(\n",
    "        stacked_smote, X_train, y_train, cv=cv, scoring=custom_score, n_jobs=-1\n",
    "                             \n",
    "    )\n",
    "    \n",
    "    params = {**logistic_params, **randomforest_params}\n",
    "    mlflow_hyperparameter_tuning(experiment_id, params, scores)\n",
    "    \n",
    "    return scores.mean()\n",
    "\n",
    "stacked_best_params = udf.tune(stacked_models_objective, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6fd2214e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T18:48:32.419940Z",
     "start_time": "2023-03-14T18:48:30.921871Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tol': 0.0002168333834926689,\n",
       " 'C': 0.00012720838557589821,\n",
       " 'penalty': 'l2',\n",
       " 'n_estimators': 311,\n",
       " 'max_depth': 80,\n",
       " 'min_samples_split': 9,\n",
       " 'min_samples_leaf': 8,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "07a0109b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T18:53:15.423680Z",
     "start_time": "2023-03-14T18:53:15.250930Z"
    }
   },
   "outputs": [],
   "source": [
    "logisticregression_params = {\n",
    "    'tol': 0.0002168333834926689,\n",
    "     'C': 0.00012720838557589821,\n",
    "     'penalty': 'l2'\n",
    "}\n",
    "\n",
    "logisticregression = LogisticRegression(random_state=42, n_jobs=-1, **logisticregression_params)\n",
    "\n",
    "randomforest_params = {\n",
    "     'n_estimators': 311,\n",
    "     'max_depth': 80,\n",
    "     'min_samples_split': 9,\n",
    "     'min_samples_leaf': 8,\n",
    "     'bootstrap': True\n",
    "}\n",
    "randomforest = RandomForestClassifier(random_state=42, n_jobs=-1, **randomforest_params)\n",
    "\n",
    "estimators = [\n",
    "    ('logisticregression', logisticregression),\n",
    "]\n",
    "\n",
    "classifier = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    n_jobs=-1,\n",
    "    final_estimator=randomforest,\n",
    "    stack_method='predict_proba',\n",
    "    cv=cv,\n",
    "    passthrough=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "32f78c63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T18:53:20.169009Z",
     "start_time": "2023-03-14T18:53:19.956296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-35 {color: black;background-color: white;}#sk-container-id-35 pre{padding: 0;}#sk-container-id-35 div.sk-toggleable {background-color: white;}#sk-container-id-35 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-35 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-35 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-35 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-35 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-35 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-35 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-35 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-35 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-35 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-35 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-35 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-35 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-35 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-35 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-35 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-35 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-35 div.sk-item {position: relative;z-index: 1;}#sk-container-id-35 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-35 div.sk-item::before, #sk-container-id-35 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-35 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-35 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-35 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-35 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-35 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-35 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-35 div.sk-label-container {text-align: center;}#sk-container-id-35 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-35 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-35\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;smote&#x27;, SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 StackingClassifier(cv=StratifiedKFold(n_splits=5, random_state=1001, shuffle=True),\n",
       "                                    estimators=[(&#x27;logisticregression&#x27;,\n",
       "                                                 LogisticRegression(C=0.00012720838557589821,\n",
       "                                                                    n_jobs=-1,\n",
       "                                                                    random_state=42,\n",
       "                                                                    tol=0.0002168333834926689))],\n",
       "                                    final_estimator=RandomForestClassifier(max_depth=80,\n",
       "                                                                           min_samples_leaf=8,\n",
       "                                                                           min_samples_split=9,\n",
       "                                                                           n_estimators=311,\n",
       "                                                                           n_jobs=-1,\n",
       "                                                                           random_state=42),\n",
       "                                    n_jobs=-1, passthrough=True,\n",
       "                                    stack_method=&#x27;predict_proba&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-136\" type=\"checkbox\" ><label for=\"sk-estimator-id-136\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;smote&#x27;, SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 StackingClassifier(cv=StratifiedKFold(n_splits=5, random_state=1001, shuffle=True),\n",
       "                                    estimators=[(&#x27;logisticregression&#x27;,\n",
       "                                                 LogisticRegression(C=0.00012720838557589821,\n",
       "                                                                    n_jobs=-1,\n",
       "                                                                    random_state=42,\n",
       "                                                                    tol=0.0002168333834926689))],\n",
       "                                    final_estimator=RandomForestClassifier(max_depth=80,\n",
       "                                                                           min_samples_leaf=8,\n",
       "                                                                           min_samples_split=9,\n",
       "                                                                           n_estimators=311,\n",
       "                                                                           n_jobs=-1,\n",
       "                                                                           random_state=42),\n",
       "                                    n_jobs=-1, passthrough=True,\n",
       "                                    stack_method=&#x27;predict_proba&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-137\" type=\"checkbox\" ><label for=\"sk-estimator-id-137\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE(k_neighbors=17, random_state=1001)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-138\" type=\"checkbox\" ><label for=\"sk-estimator-id-138\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">model: StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(cv=StratifiedKFold(n_splits=5, random_state=1001, shuffle=True),\n",
       "                   estimators=[(&#x27;logisticregression&#x27;,\n",
       "                                LogisticRegression(C=0.00012720838557589821,\n",
       "                                                   n_jobs=-1, random_state=42,\n",
       "                                                   tol=0.0002168333834926689))],\n",
       "                   final_estimator=RandomForestClassifier(max_depth=80,\n",
       "                                                          min_samples_leaf=8,\n",
       "                                                          min_samples_split=9,\n",
       "                                                          n_estimators=311,\n",
       "                                                          n_jobs=-1,\n",
       "                                                          random_state=42),\n",
       "                   n_jobs=-1, passthrough=True, stack_method=&#x27;predict_proba&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>logisticregression</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-139\" type=\"checkbox\" ><label for=\"sk-estimator-id-139\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.00012720838557589821, n_jobs=-1, random_state=42,\n",
       "                   tol=0.0002168333834926689)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-140\" type=\"checkbox\" ><label for=\"sk-estimator-id-140\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=80, min_samples_leaf=8, min_samples_split=9,\n",
       "                       n_estimators=311, n_jobs=-1, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('smote', SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                ('model',\n",
       "                 StackingClassifier(cv=StratifiedKFold(n_splits=5, random_state=1001, shuffle=True),\n",
       "                                    estimators=[('logisticregression',\n",
       "                                                 LogisticRegression(C=0.00012720838557589821,\n",
       "                                                                    n_jobs=-1,\n",
       "                                                                    random_state=42,\n",
       "                                                                    tol=0.0002168333834926689))],\n",
       "                                    final_estimator=RandomForestClassifier(max_depth=80,\n",
       "                                                                           min_samples_leaf=8,\n",
       "                                                                           min_samples_split=9,\n",
       "                                                                           n_estimators=311,\n",
       "                                                                           n_jobs=-1,\n",
       "                                                                           random_state=42),\n",
       "                                    n_jobs=-1, passthrough=True,\n",
       "                                    stack_method='predict_proba'))])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_line_smote = Pipeline([('smote', smote), ('model', classifier)])\n",
    "pipe_line_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0d71dddf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T18:56:01.718380Z",
     "start_time": "2023-03-14T18:54:29.349170Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-36 {color: black;background-color: white;}#sk-container-id-36 pre{padding: 0;}#sk-container-id-36 div.sk-toggleable {background-color: white;}#sk-container-id-36 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-36 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-36 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-36 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-36 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-36 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-36 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-36 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-36 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-36 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-36 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-36 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-36 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-36 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-36 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-36 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-36 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-36 div.sk-item {position: relative;z-index: 1;}#sk-container-id-36 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-36 div.sk-item::before, #sk-container-id-36 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-36 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-36 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-36 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-36 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-36 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-36 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-36 div.sk-label-container {text-align: center;}#sk-container-id-36 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-36 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-36\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;smote&#x27;, SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 StackingClassifier(cv=StratifiedKFold(n_splits=5, random_state=1001, shuffle=True),\n",
       "                                    estimators=[(&#x27;logisticregression&#x27;,\n",
       "                                                 LogisticRegression(C=0.00012720838557589821,\n",
       "                                                                    n_jobs=-1,\n",
       "                                                                    random_state=42,\n",
       "                                                                    tol=0.0002168333834926689))],\n",
       "                                    final_estimator=RandomForestClassifier(max_depth=80,\n",
       "                                                                           min_samples_leaf=8,\n",
       "                                                                           min_samples_split=9,\n",
       "                                                                           n_estimators=311,\n",
       "                                                                           n_jobs=-1,\n",
       "                                                                           random_state=42),\n",
       "                                    n_jobs=-1, passthrough=True,\n",
       "                                    stack_method=&#x27;predict_proba&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-141\" type=\"checkbox\" ><label for=\"sk-estimator-id-141\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;smote&#x27;, SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 StackingClassifier(cv=StratifiedKFold(n_splits=5, random_state=1001, shuffle=True),\n",
       "                                    estimators=[(&#x27;logisticregression&#x27;,\n",
       "                                                 LogisticRegression(C=0.00012720838557589821,\n",
       "                                                                    n_jobs=-1,\n",
       "                                                                    random_state=42,\n",
       "                                                                    tol=0.0002168333834926689))],\n",
       "                                    final_estimator=RandomForestClassifier(max_depth=80,\n",
       "                                                                           min_samples_leaf=8,\n",
       "                                                                           min_samples_split=9,\n",
       "                                                                           n_estimators=311,\n",
       "                                                                           n_jobs=-1,\n",
       "                                                                           random_state=42),\n",
       "                                    n_jobs=-1, passthrough=True,\n",
       "                                    stack_method=&#x27;predict_proba&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-142\" type=\"checkbox\" ><label for=\"sk-estimator-id-142\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE(k_neighbors=17, random_state=1001)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-143\" type=\"checkbox\" ><label for=\"sk-estimator-id-143\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">model: StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(cv=StratifiedKFold(n_splits=5, random_state=1001, shuffle=True),\n",
       "                   estimators=[(&#x27;logisticregression&#x27;,\n",
       "                                LogisticRegression(C=0.00012720838557589821,\n",
       "                                                   n_jobs=-1, random_state=42,\n",
       "                                                   tol=0.0002168333834926689))],\n",
       "                   final_estimator=RandomForestClassifier(max_depth=80,\n",
       "                                                          min_samples_leaf=8,\n",
       "                                                          min_samples_split=9,\n",
       "                                                          n_estimators=311,\n",
       "                                                          n_jobs=-1,\n",
       "                                                          random_state=42),\n",
       "                   n_jobs=-1, passthrough=True, stack_method=&#x27;predict_proba&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>logisticregression</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-144\" type=\"checkbox\" ><label for=\"sk-estimator-id-144\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.00012720838557589821, n_jobs=-1, random_state=42,\n",
       "                   tol=0.0002168333834926689)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-145\" type=\"checkbox\" ><label for=\"sk-estimator-id-145\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=80, min_samples_leaf=8, min_samples_split=9,\n",
       "                       n_estimators=311, n_jobs=-1, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('smote', SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                ('model',\n",
       "                 StackingClassifier(cv=StratifiedKFold(n_splits=5, random_state=1001, shuffle=True),\n",
       "                                    estimators=[('logisticregression',\n",
       "                                                 LogisticRegression(C=0.00012720838557589821,\n",
       "                                                                    n_jobs=-1,\n",
       "                                                                    random_state=42,\n",
       "                                                                    tol=0.0002168333834926689))],\n",
       "                                    final_estimator=RandomForestClassifier(max_depth=80,\n",
       "                                                                           min_samples_leaf=8,\n",
       "                                                                           min_samples_split=9,\n",
       "                                                                           n_estimators=311,\n",
       "                                                                           n_jobs=-1,\n",
       "                                                                           random_state=42),\n",
       "                                    n_jobs=-1, passthrough=True,\n",
       "                                    stack_method='predict_proba'))])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_line_smote.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "21207a5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T18:59:38.376471Z",
     "start_time": "2023-03-14T18:59:36.615441Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pour le seuil 0.2, le f3_score est : 0.528 et le mean score est : 0.581\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = pipe_line_smote.predict_proba(X_test)[:,1]\n",
    "threshold_f3 = custom_metric(y_test, y_pred_proba, return_proba=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2e5fe32d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T18:59:43.269519Z",
     "start_time": "2023-03-14T18:59:41.798809Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.634105\n",
      "f3_score : 0.527867 \n",
      "\n",
      "Mean evalation score : 0.580986\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(pipe_line_smote, X_test, y_test, threshold_f3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eba79af",
   "metadata": {},
   "source": [
    "## Test de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6e8f2485",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-20T22:04:34.510219Z",
     "start_time": "2023-03-20T22:04:34.278952Z"
    }
   },
   "outputs": [],
   "source": [
    "#RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "randomforest_params = {\n",
    "    'n_estimators': 882, \n",
    "    'max_depth': 20, \n",
    "    'min_samples_split': 6,\n",
    "    'min_samples_leaf': 10, \n",
    "    'bootstrap': True\n",
    "    }\n",
    "\n",
    "forest = RandomForestClassifier(**randomforest_params)\n",
    "forest_smote = Pipeline([('smote', smote), ('model', forest)])\n",
    "#models[\"RandomForestClassifier\"] = forest_smote\n",
    "\n",
    "#Staking models logistic_regression + RandomForest\n",
    "#LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_params = {\n",
    "    'tol': 0.0002329433780056682, \n",
    "    'C': 6.681553108313681e-08, \n",
    "    'penalty': 'l2',\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "    }\n",
    "logistic_regression = LogisticRegression(**logistic_params)\n",
    "\n",
    "estimators_0 = [\n",
    "    ('LogisticRegression', logistic_regression)\n",
    "]\n",
    "classifier_0 = StackingClassifier(\n",
    "    estimators=estimators_0,\n",
    "    n_jobs=-1,\n",
    "    final_estimator=forest,\n",
    "    stack_method='predict_proba',\n",
    "    cv=cv,\n",
    "    passthrough=True\n",
    ")\n",
    "\n",
    "clf_smote = Pipeline([('smote', smote), ('model', classifier_0)])\n",
    "\n",
    "scoring = {\n",
    "    'f3_score': make_scorer(udf.f3_score, needs_proba=True),\n",
    "    'accuracy': make_scorer(udf.custom_accuracy_score, needs_proba=True),\n",
    "    'recall_score': make_scorer(udf.custom_recall_score, needs_proba=True),\n",
    "    'preciion_score': make_scorer(udf.custom_precision_score, needs_proba=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "19d49af8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T17:41:38.237000Z",
     "start_time": "2023-03-21T16:30:46.144501Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;smote&#x27;, SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 StackingClassifier(cv=StratifiedKFold(n_splits=5,\n",
       "        random_state=RandomState(MT19937) at 0x7FE8D8A34440, shuffle=False),\n",
       "                                    estimators=[(&#x27;LogisticRegression&#x27;,\n",
       "                                                 LogisticRegression(C=6.681553108313681e-08,\n",
       "                                                                    n_jobs=-1,\n",
       "                                                                    random_state=42,\n",
       "                                                                    tol=0.0002329433780056682))],\n",
       "                                    final_estimator=RandomForestClassifier(max_depth=20,\n",
       "                                                                           min_samples_leaf=10,\n",
       "                                                                           min_samples_split=6,\n",
       "                                                                           n_estimators=882),\n",
       "                                    n_jobs=-1, passthrough=True,\n",
       "                                    stack_method=&#x27;predict_proba&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;smote&#x27;, SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 StackingClassifier(cv=StratifiedKFold(n_splits=5,\n",
       "        random_state=RandomState(MT19937) at 0x7FE8D8A34440, shuffle=False),\n",
       "                                    estimators=[(&#x27;LogisticRegression&#x27;,\n",
       "                                                 LogisticRegression(C=6.681553108313681e-08,\n",
       "                                                                    n_jobs=-1,\n",
       "                                                                    random_state=42,\n",
       "                                                                    tol=0.0002329433780056682))],\n",
       "                                    final_estimator=RandomForestClassifier(max_depth=20,\n",
       "                                                                           min_samples_leaf=10,\n",
       "                                                                           min_samples_split=6,\n",
       "                                                                           n_estimators=882),\n",
       "                                    n_jobs=-1, passthrough=True,\n",
       "                                    stack_method=&#x27;predict_proba&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE(k_neighbors=17, random_state=1001)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">model: StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(cv=StratifiedKFold(n_splits=5,\n",
       "        random_state=RandomState(MT19937) at 0x7FE8D8A34440, shuffle=False),\n",
       "                   estimators=[(&#x27;LogisticRegression&#x27;,\n",
       "                                LogisticRegression(C=6.681553108313681e-08,\n",
       "                                                   n_jobs=-1, random_state=42,\n",
       "                                                   tol=0.0002329433780056682))],\n",
       "                   final_estimator=RandomForestClassifier(max_depth=20,\n",
       "                                                          min_samples_leaf=10,\n",
       "                                                          min_samples_split=6,\n",
       "                                                          n_estimators=882),\n",
       "                   n_jobs=-1, passthrough=True, stack_method=&#x27;predict_proba&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>LogisticRegression</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=6.681553108313681e-08, n_jobs=-1, random_state=42,\n",
       "                   tol=0.0002329433780056682)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=20, min_samples_leaf=10, min_samples_split=6,\n",
       "                       n_estimators=882)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('smote', SMOTE(k_neighbors=17, random_state=1001)),\n",
       "                ('model',\n",
       "                 StackingClassifier(cv=StratifiedKFold(n_splits=5,\n",
       "        random_state=RandomState(MT19937) at 0x7FE8D8A34440, shuffle=False),\n",
       "                                    estimators=[('LogisticRegression',\n",
       "                                                 LogisticRegression(C=6.681553108313681e-08,\n",
       "                                                                    n_jobs=-1,\n",
       "                                                                    random_state=42,\n",
       "                                                                    tol=0.0002329433780056682))],\n",
       "                                    final_estimator=RandomForestClassifier(max_depth=20,\n",
       "                                                                           min_samples_leaf=10,\n",
       "                                                                           min_samples_split=6,\n",
       "                                                                           n_estimators=882),\n",
       "                                    n_jobs=-1, passthrough=True,\n",
       "                                    stack_method='predict_proba'))])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_smote.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "da1e1188",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T18:02:42.772297Z",
     "start_time": "2023-03-21T18:02:15.051645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pour le seuil 0.2, le f3_score est : 0.532 et le mean score est : 0.587\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = clf_smote.predict_proba(X_test)[:,1]\n",
    "threshold_f3 = custom_metric(y_test, y_pred_proba, return_proba=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "86d7ca55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T18:05:17.976463Z",
     "start_time": "2023-03-21T18:04:46.962282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.641349\n",
      "f3_score : 0.532339 \n",
      "\n",
      "Mean evalation score : 0.586844\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(clf_smote, X_test, y_test, threshold_f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41900c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "'/Users/kone/Desktop/Oc_Formation/Projets/Projet7/openclassrooms_projects7/model_and_data/test_df.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b5fdb38b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T18:06:19.799058Z",
     "start_time": "2023-03-21T18:06:14.499236Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>...</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Refused_MIN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Sent proposal_MIN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Sent proposal_MAX</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Signed_MAX</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Signed_SUM</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_MIN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_MAX</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_MEAN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_SUM</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_VAR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100001</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.075102</td>\n",
       "      <td>-0.451695</td>\n",
       "      <td>-0.146668</td>\n",
       "      <td>-0.734183</td>\n",
       "      <td>-0.161753</td>\n",
       "      <td>-0.052189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.045826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100005</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>-0.934825</td>\n",
       "      <td>-0.671813</td>\n",
       "      <td>1.079459</td>\n",
       "      <td>-0.464475</td>\n",
       "      <td>-1.089349</td>\n",
       "      <td>-1.173430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.045826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100013</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.577530</td>\n",
       "      <td>0.159595</td>\n",
       "      <td>2.943833</td>\n",
       "      <td>-0.127871</td>\n",
       "      <td>-0.916815</td>\n",
       "      <td>-1.084148</td>\n",
       "      <td>0.797684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.045826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100028</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.192118</td>\n",
       "      <td>2.424820</td>\n",
       "      <td>1.511669</td>\n",
       "      <td>0.399884</td>\n",
       "      <td>0.472288</td>\n",
       "      <td>0.038503</td>\n",
       "      <td>0.847643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.045826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100038</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.807294</td>\n",
       "      <td>0.065770</td>\n",
       "      <td>0.342157</td>\n",
       "      <td>-0.783588</td>\n",
       "      <td>0.686772</td>\n",
       "      <td>-0.102803</td>\n",
       "      <td>0.279926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.045826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 374 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            CODE_GENDER  FLAG_OWN_CAR  FLAG_OWN_REALTY  CNT_CHILDREN  \\\n",
       "SK_ID_CURR                                                             \n",
       "100001                1             0                0     -0.577530   \n",
       "100005                0             0                0     -0.577530   \n",
       "100013                0             1                0     -0.577530   \n",
       "100028                1             0                0      2.192118   \n",
       "100038                0             1                1      0.807294   \n",
       "\n",
       "            AMT_CREDIT  AMT_ANNUITY  REGION_POPULATION_RELATIVE  DAYS_BIRTH  \\\n",
       "SK_ID_CURR                                                                    \n",
       "100001       -0.075102    -0.451695                   -0.146668   -0.734183   \n",
       "100005       -0.934825    -0.671813                    1.079459   -0.464475   \n",
       "100013        0.159595     2.943833                   -0.127871   -0.916815   \n",
       "100028        2.424820     1.511669                    0.399884    0.472288   \n",
       "100038        0.065770     0.342157                   -0.783588    0.686772   \n",
       "\n",
       "            DAYS_EMPLOYED  DAYS_REGISTRATION  ...  \\\n",
       "SK_ID_CURR                                    ...   \n",
       "100001          -0.161753          -0.052189  ...   \n",
       "100005          -1.089349          -1.173430  ...   \n",
       "100013          -1.084148           0.797684  ...   \n",
       "100028           0.038503           0.847643  ...   \n",
       "100038          -0.102803           0.279926  ...   \n",
       "\n",
       "            CC_NAME_CONTRACT_STATUS_Refused_MIN  \\\n",
       "SK_ID_CURR                                        \n",
       "100001                                      0.0   \n",
       "100005                                      0.0   \n",
       "100013                                      0.0   \n",
       "100028                                      0.0   \n",
       "100038                                      0.0   \n",
       "\n",
       "            CC_NAME_CONTRACT_STATUS_Sent proposal_MIN  \\\n",
       "SK_ID_CURR                                              \n",
       "100001                                            0.0   \n",
       "100005                                            0.0   \n",
       "100013                                            0.0   \n",
       "100028                                            0.0   \n",
       "100038                                            0.0   \n",
       "\n",
       "            CC_NAME_CONTRACT_STATUS_Sent proposal_MAX  \\\n",
       "SK_ID_CURR                                              \n",
       "100001                                            0.0   \n",
       "100005                                            0.0   \n",
       "100013                                            0.0   \n",
       "100028                                            0.0   \n",
       "100038                                            0.0   \n",
       "\n",
       "            CC_NAME_CONTRACT_STATUS_Signed_MAX  \\\n",
       "SK_ID_CURR                                       \n",
       "100001                                     0.0   \n",
       "100005                                     0.0   \n",
       "100013                                     0.0   \n",
       "100028                                     0.0   \n",
       "100038                                     0.0   \n",
       "\n",
       "            CC_NAME_CONTRACT_STATUS_Signed_SUM  \\\n",
       "SK_ID_CURR                                       \n",
       "100001                               -0.045826   \n",
       "100005                               -0.045826   \n",
       "100013                               -0.045826   \n",
       "100028                               -0.045826   \n",
       "100038                               -0.045826   \n",
       "\n",
       "            CC_NAME_CONTRACT_STATUS_nan_MIN  CC_NAME_CONTRACT_STATUS_nan_MAX  \\\n",
       "SK_ID_CURR                                                                     \n",
       "100001                                  0.0                              0.0   \n",
       "100005                                  0.0                              0.0   \n",
       "100013                                  0.0                              0.0   \n",
       "100028                                  0.0                              0.0   \n",
       "100038                                  0.0                              0.0   \n",
       "\n",
       "            CC_NAME_CONTRACT_STATUS_nan_MEAN  CC_NAME_CONTRACT_STATUS_nan_SUM  \\\n",
       "SK_ID_CURR                                                                      \n",
       "100001                                   0.0                              0.0   \n",
       "100005                                   0.0                              0.0   \n",
       "100013                                   0.0                              0.0   \n",
       "100028                                   0.0                              0.0   \n",
       "100038                                   0.0                              0.0   \n",
       "\n",
       "            CC_NAME_CONTRACT_STATUS_nan_VAR  \n",
       "SK_ID_CURR                                   \n",
       "100001                                  0.0  \n",
       "100005                                  0.0  \n",
       "100013                                  0.0  \n",
       "100028                                  0.0  \n",
       "100038                                  0.0  \n",
       "\n",
       "[5 rows x 374 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(Path(PROJECT_ROOT + '/model_and_data/test_df.csv'), index_col=[0])\n",
    "#data.set_index('SK_ID_CURR', inplace=True)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "11e4e310",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T18:07:07.768893Z",
     "start_time": "2023-03-21T18:06:48.422426Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_proba = clf_smote.predict_proba(test_df)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "24a4cc12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T18:08:32.067135Z",
     "start_time": "2023-03-21T18:08:31.945488Z"
    }
   },
   "outputs": [],
   "source": [
    "label_pred_threshold = np.where(y_pred_proba >= 0.2, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fc671573",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T18:10:19.368543Z",
     "start_time": "2023-03-21T18:10:19.003215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1118314048476198 0\n",
      "0.5850502145937753 1\n",
      "0.09357003943795922 0\n",
      "0.2282706785301131 1\n",
      "0.33975209730633915 1\n",
      "0.1956492622838609 0\n",
      "0.03879165884658396 0\n",
      "0.15526735849897955 0\n",
      "0.05757501125705644 0\n",
      "0.24384417314380577 1\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for proba, label in zip(y_pred_proba, label_pred_threshold):\n",
    "    i += 1\n",
    "    print(proba, label)\n",
    "    \n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "55f7ed22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T18:12:21.381435Z",
     "start_time": "2023-03-21T18:12:21.289894Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18867"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(label_pred_threshold).count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a124b5a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T18:12:41.339456Z",
     "start_time": "2023-03-21T18:12:41.254157Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29877"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(label_pred_threshold).count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d45ffeca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T18:13:13.929485Z",
     "start_time": "2023-03-21T18:13:13.844989Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48744"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(label_pred_threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d904d3fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T18:15:36.650237Z",
     "start_time": "2023-03-21T18:15:36.439790Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bc07546e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T18:21:16.494802Z",
     "start_time": "2023-03-21T18:21:16.141505Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7717293214698869"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - 0.2282706785301131"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "eb57e51b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T18:20:23.332992Z",
     "start_time": "2023-03-21T18:20:23.262928Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8447326415010205"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - 0.15526735849897955"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b3c91cc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T18:28:23.147189Z",
     "start_time": "2023-03-21T18:28:13.027935Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(clf_smote, open(Path(PROJECT_ROOT + '/model_and_data/model.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309e7d97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc5d340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edae5b91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "308px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
